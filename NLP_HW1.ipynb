{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAhmadS/NLP_HW1/blob/main/NLP_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvVmtJhaLMx_"
      },
      "source": [
        "#**Natural Language Processing-Homework1**\n",
        "\n",
        "####**Student name** : Amirahmad Shafiee<br/>**Student number** : 99104027<br/>**Chosen task** : classification\n",
        "In this notebook we aim to do common but rather essential preprocess actions on some text chosen from the persian literature world. After doing so, an NLP task would be operated on the processed text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVCuqcZ0MmIi",
        "outputId": "31624995-03c2-4dd8-e032-ed23c47c5177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3kFSCcFM7j6",
        "outputId": "e8ac1f47-d103-437b-dabd-b60ba5d8e740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1Ikn75GANDVFyb0klJe4-EBQJikt4_Ob_/NLP\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldv2jmur72rm"
      },
      "source": [
        "##Essential packages and data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr1hjArriwYv"
      },
      "source": [
        "The data we tend to use in this notebook will be the texts extracted from philosophers books on ethics, like : \n",
        ">**Immanuel Kant's** \"Critique of Pure Reason\"<br/>\n",
        ">**Friedrich Neitzsche's**\"Human all too human\"<br/>\n",
        ">**Georg Wilhelm Friedrich Hegel's**\"Phenomenology of spirit\"<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fggNKpn4nr-"
      },
      "outputs": [],
      "source": [
        "!gdown https://rauterberg.employee.id.tue.nl/lecturenotes/DDM110%20CAS/Kant-1781%20Critique%20of%20Pure%20Reason.pdf\n",
        "!gdown http://www.faculty.umb.edu/gary_zabel/Courses/Marxist_Philosophy/Hegel_and_Feuerbach_files/Hegel-Phenomenology-of-Spirit.pdf\n",
        "!gdown https://drive.google.com/file/d/1x4cM62wac-nEU8X_rEyYLLsWOX67Kqmr/view?usp=share_link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l0jWZyKjOui"
      },
      "source": [
        "Our data comes in the pdf form. So we need the primary text extractors compatible with pdf format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NW6Arfgd6UFV"
      },
      "outputs": [],
      "source": [
        "!pip install -q openpyxl==3.0.10\n",
        "!pip install -q PyPDF2==3.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CZqxQvPq7_P7"
      },
      "outputs": [],
      "source": [
        "import random \n",
        "import tqdm\n",
        "import nltk, re\n",
        "from nltk import word_tokenize, sent_tokenize, WhitespaceTokenizer, FreqDist, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "import itertools\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPLBijV-khFZ",
        "outputId": "db92af59-08de-40ce-c425-3999e17cbca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_smO9LWLc3R"
      },
      "source": [
        "##Section A: Extracting data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJW-OM3VWD-6"
      },
      "outputs": [],
      "source": [
        "mask_list1 = np.concatenate((np.arange(36),np.array([529]),np.arange(530,631)))\n",
        "with open('pdf_mask_list_heg.npy','wb') as f:\n",
        "  np.save(f,mask_list1)\n",
        "\n",
        "mask_list2 = np.concatenate((np.arange(103),np.array([129,156,625]),np.arange(705,785)))\n",
        "with open('pdf_mask_list_kan.npy','wb') as f:\n",
        "  np.save(f,mask_list2)\n",
        "\n",
        "mask_list3 = np.concatenate((np.arange(30),np.array([230,231,232,233,325]),np.arange(421,425)))\n",
        "with open('pdf_mask_list_nei.npy','wb') as f:\n",
        "  np.save(f,mask_list3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lIH0GSflq7vR"
      },
      "outputs": [],
      "source": [
        "name_list=[\"heg\",\"kan\",\"nei\"]\n",
        "address_list=[\"Hegel-Phenomenology-of-Spirit.pdf\",\"Kant-1781%20Critique%20of%20Pure%20Reason.pdf\",\"Human, All Too Human_ A Book for Free Spirits - PART I + PART II - Friedrich Nietzsche - PDF.pdf\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUk6XvkY6lLt"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "  reader = PdfReader(address_list[i])\n",
        "  number_of_pages = len(reader.pages)\n",
        "\n",
        "  with open(f'pdf_mask_list_{name_list[i]}.npy','rb') as f:\n",
        "    mask_list = np.load(f)\n",
        "    text_pages_index = np.delete(np.arange(number_of_pages),mask_list)\n",
        "\n",
        "  text = \"\"\n",
        "  for ind in text_pages_index:\n",
        "    text+=reader.pages[int(ind)].extract_text()\n",
        "\n",
        "  with open(f'final_text_{name_list[i]}.txt','wb') as f:\n",
        "    pickle.dump(text,f)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XA4bpKhtSdgK"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "for x in name_list:\n",
        "  with open(f'final_text_{x}.txt','rb') as f:\n",
        "    text = pickle.load(f)\n",
        "    texts.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1vunFgSITsAH"
      },
      "outputs": [],
      "source": [
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "sentences = [sent_detector.tokenize(text) for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srawgE3j_Z0U",
        "outputId": "e8142030-c1d5-4fff-a81f-e44154ba5a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-605b0474b0a1>:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data = data.append(sentences[i],ignore_index = True)\n",
            "<ipython-input-9-605b0474b0a1>:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  labels = labels.astype(np.int)\n"
          ]
        }
      ],
      "source": [
        "data = pd.DataFrame()\n",
        "labels=np.array([])\n",
        "labels_auth = []\n",
        "for i in range(3):\n",
        "  data = data.append(sentences[i],ignore_index = True)\n",
        "  labels = np.concatenate((labels, (i*np.ones(len(sentences[i])))))\n",
        "\n",
        "labels = labels.astype(np.int)\n",
        "labels_auth = [name_list[i] for i in labels]\n",
        "data.rename(columns = {0 : \"sentences\"}, inplace=True)\n",
        "data[\"labels\"] = labels\n",
        "data[\"author\"] = labels_auth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UE00NsgzUkom",
        "outputId": "7bf53953-b59a-44fc-934c-3f0cbefc208f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentences  labels author\n",
              "18896  It is precisely this dubiety that makes the Fr...       2    nei\n",
              "381                            rigid, dead propositions.       0    heg\n",
              "8474                d Object \\n195 Doctrine of Elements.       1    kan\n",
              "18912  - The florid style in art is the consequence o...       2    nei\n",
              "9445                                                 II.       1    kan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b911bec-3fd4-4502-8d86-5e3b1b3310ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18896</th>\n",
              "      <td>It is precisely this dubiety that makes the Fr...</td>\n",
              "      <td>2</td>\n",
              "      <td>nei</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>rigid, dead propositions.</td>\n",
              "      <td>0</td>\n",
              "      <td>heg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8474</th>\n",
              "      <td>d Object \\n195 Doctrine of Elements.</td>\n",
              "      <td>1</td>\n",
              "      <td>kan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18912</th>\n",
              "      <td>- The florid style in art is the consequence o...</td>\n",
              "      <td>2</td>\n",
              "      <td>nei</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9445</th>\n",
              "      <td>II.</td>\n",
              "      <td>1</td>\n",
              "      <td>kan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b911bec-3fd4-4502-8d86-5e3b1b3310ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b911bec-3fd4-4502-8d86-5e3b1b3310ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b911bec-3fd4-4502-8d86-5e3b1b3310ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POGtw5EP67Gs",
        "outputId": "0a1b0db7-558a-4b06-dcf0-50205385f2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heg text consists of 1251449 characters, in other words the volume of the text is about 1.25 megs\n",
            "also 7317 sentences have been spotted\n",
            "kan text consists of 1642328 characters, in other words the volume of the text is about 1.64 megs\n",
            "also 8148 sentences have been spotted\n",
            "nei text consists of 1102859 characters, in other words the volume of the text is about 1.10 megs\n",
            "also 5997 sentences have been spotted\n"
          ]
        }
      ],
      "source": [
        "for txt,x,sen in zip(texts,name_list,sentences):\n",
        "  print(f\"{x} text consists of {len(txt)} characters, in other words the volume of the text is about {len(txt)/1e6:.2f} megs\\nalso {len(sen)} sentences have been spotted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "bPkCdEDF0s7s"
      },
      "outputs": [],
      "source": [
        "class distributions:\n",
        "\n",
        "  def minmax(data, col_end = 'sentence_len_by_words', col_beg = 'sentences'):\n",
        "    data[col_end] = data[col_beg].apply(lambda t: len(word_tokenize(t)))\n",
        "\n",
        "    min_max_len = data[col_end].min(), data[col_end].max()\n",
        "    print(f'Min: {min_max_len[0]} \\tMax: {min_max_len[1]}')\n",
        "\n",
        "    return\n",
        "\n",
        "  def word_freq(data, col_end = \"sentence_len_by_words\"):\n",
        "\n",
        "      fig = go.Figure()\n",
        "\n",
        "      fig.add_trace(go.Histogram(\n",
        "          x=data[col_end]\n",
        "      ))\n",
        "\n",
        "      fig.update_layout(\n",
        "          title_text='Distribution of word counts within data',\n",
        "          xaxis_title_text='Word Count',\n",
        "          yaxis_title_text='Frequency',\n",
        "          bargap=0.2,\n",
        "          bargroupgap=0.2)\n",
        "\n",
        "      fig.show()\n",
        "\n",
        "      return\n",
        "\n",
        "  def data_gl_than(data, less_than=25.0, greater_than=3.0, col='sentence_len_by_words'):\n",
        "      data_length = data[col].values\n",
        "\n",
        "      data_glt = sum([1 for length in data_length if greater_than < length <= less_than])\n",
        "\n",
        "      data_glt_rate = (data_glt / len(data_length)) * 100\n",
        "\n",
        "      print(f'sentences with word length of greater than {greater_than} and less than {less_than} includes {data_glt_rate:.2f}% of the whole!')\n",
        "\n",
        "      return\n",
        "\n",
        "  def full_df_run(data, col_begin = 'sentences', minmax = True, freq = True, gl = True):\n",
        "    if minmax :\n",
        "      distributions.minmax(data)\n",
        "    if freq:\n",
        "      distributions.word_freq(data)\n",
        "    if gl:\n",
        "      distributions.data_gl_than(data)\n",
        "\n",
        "\n",
        "  def word_and_freq(data, col = \"tokenized_sents\"):\n",
        "    tokenized_sent = data[col].values\n",
        "    total_len = 0\n",
        "    for i in range(len(tokenized_sent)):\n",
        "      total_len += len(tokenized_sent[i])\n",
        "\n",
        "    mp_freqdist = FreqDist(itertools.chain(*tokenized_sent))\n",
        "    top20words=mp_freqdist.most_common(20)\n",
        "    print ('%-16s' % 'word', '%-16s' % 'Frequency','%-16s' %  '% of the total')\n",
        "    for topword in top20words:\n",
        "        percent=(topword[1]/total_len)*100\n",
        "        print ('%-16s' % topword[0], '%-16s' % topword[1],'%-16s' %  percent)\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distributions.full_df_run(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "i-2RSVgnVH2S",
        "outputId": "4bfb7035-74fb-4121-cd02-d7d7c21387c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min: 1 \tMax: 340\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"eb6c40c3-5daa-4e7e-beb8-b99e8e978fe0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eb6c40c3-5daa-4e7e-beb8-b99e8e978fe0\")) {                    Plotly.newPlot(                        \"eb6c40c3-5daa-4e7e-beb8-b99e8e978fe0\",                        [{\"x\":[7,42,36,54,62,64,57,4,38,2,50,41,24,58,19,47,8,3,25,44,2,24,42,68,42,44,29,25,62,37,2,89,33,33,2,17,38,25,52,61,2,64,30,70,46,2,94,27,27,53,85,68,2,67,15,20,26,79,28,39,18,20,45,16,11,2,18,47,72,29,73,67,3,23,34,13,70,5,23,32,2,25,16,29,28,19,39,28,45,35,38,58,21,54,34,2,25,33,27,29,62,33,21,58,31,51,42,40,17,27,2,38,40,55,49,55,50,61,3,2,39,36,45,34,51,2,46,49,25,41,2,52,34,36,65,33,25,11,2,6,15,37,11,53,66,32,43,3,21,40,35,30,67,36,12,41,2,17,32,40,17,46,58,14,2,30,25,14,29,17,65,20,28,10,61,96,2,68,10,30,27,71,11,52,2,42,81,27,20,19,54,32,2,22,16,18,15,26,46,31,32,51,21,30,22,20,20,63,63,56,27,2,23,16,3,33,92,2,40,32,28,46,55,44,42,34,28,38,38,2,32,11,18,72,93,51,42,8,12,2,17,7,28,29,35,34,66,2,17,46,37,22,35,2,34,40,21,28,36,30,62,33,17,33,15,72,14,27,30,2,65,33,52,70,21,51,42,50,12,33,2,31,81,25,2,36,17,22,4,21,38,30,33,19,12,22,63,31,21,40,32,31,47,32,10,21,24,43,20,2,65,44,15,34,2,43,22,18,55,35,28,7,12,17,23,20,55,24,33,36,18,7,10,40,2,42,24,38,20,2,47,17,34,40,2,48,45,46,22,19,22,35,19,41,30,13,13,5,36,57,2,24,28,28,14,61,2,40,63,25,32,36,2,55,7,14,38,29,28,33,18,5,70,59,16,24,40,13,2,24,25,20,83,48,38,38,12,46,2,60,28,27,54,24,19,38,14,12,37,47,2,19,3,29,17,28,9,2,31,28,33,29,39,27,50,11,43,53,33,2,32,2,73,2,38,58,53,29,43,25,44,46,22,3,45,7,72,113,37,54,38,36,25,52,52,31,68,63,36,2,38,61,2,13,48,10,47,14,30,46,37,34,42,20,67,13,32,8,32,34,61,24,2,6,23,23,14,43,8,88,49,25,61,68,2,42,25,12,18,24,37,17,38,21,16,18,77,20,2,24,42,43,56,2,43,23,29,34,18,11,36,22,2,34,2,30,7,6,9,57,2,45,20,11,12,54,37,25,25,28,20,8,44,47,50,25,42,37,54,22,2,11,50,27,15,24,22,34,31,58,11,80,30,24,24,93,2,87,13,46,52,1,2,36,39,4,46,83,24,90,2,32,52,10,31,9,38,2,43,33,22,25,26,12,27,21,21,48,25,11,19,45,56,34,30,33,50,16,6,46,46,44,2,25,47,20,34,94,26,55,28,2,83,60,50,67,2,33,66,21,36,63,52,94,12,27,26,2,61,42,43,22,31,17,58,18,7,78,111,48,40,96,21,22,37,29,19,42,48,2,73,22,42,22,46,83,45,49,56,36,62,17,36,67,44,36,44,2,53,19,35,32,79,2,20,62,45,11,2,175,39,54,33,40,22,74,43,11,33,45,33,20,2,111,2,25,54,21,81,33,86,31,44,52,46,31,75,2,24,36,49,33,45,48,55,2,40,29,39,11,25,32,17,31,7,27,59,71,67,3,33,41,55,43,2,24,51,43,18,37,2,24,33,22,43,2,23,29,6,47,28,37,31,21,15,26,18,57,2,72,41,39,60,49,16,33,54,30,78,2,38,35,23,10,27,18,21,39,13,18,19,2,28,29,26,58,23,46,31,47,46,31,21,44,30,31,30,2,32,2,38,19,26,13,72,22,17,40,24,14,3,63,34,20,30,16,100,60,17,27,42,2,36,16,54,44,17,6,2,58,86,17,35,2,45,36,2,17,43,8,8,5,16,30,24,2,10,32,49,36,6,56,38,17,2,17,10,12,45,70,2,19,9,33,37,19,2,32,83,2,36,45,19,10,27,45,50,19,19,41,9,28,4,71,30,18,16,31,39,74,2,87,42,7,9,30,2,63,7,47,5,68,66,2,52,35,37,21,18,18,2,9,17,34,31,11,38,2,36,29,20,50,38,47,24,43,27,26,21,25,2,42,15,22,51,80,2,34,39,57,30,23,11,56,22,19,22,38,4,28,54,67,21,3,49,47,28,49,8,53,48,9,28,47,42,38,88,5,46,3,11,24,17,32,36,50,37,57,36,46,9,3,35,30,14,43,6,38,4,54,24,26,34,18,51,16,57,33,19,77,24,20,33,25,3,41,57,93,39,37,25,3,29,92,29,41,64,3,30,26,22,32,37,20,62,3,12,30,15,37,17,21,25,17,52,23,64,56,22,50,13,38,3,26,29,16,28,36,27,52,12,19,57,42,2,55,46,31,43,56,2,27,28,55,20,31,16,27,45,16,25,25,46,2,39,20,29,22,35,29,29,33,36,2,65,47,71,2,17,26,19,42,31,26,23,24,41,20,20,28,2,39,36,40,50,33,9,17,49,34,2,49,59,56,2,33,53,2,23,43,30,12,2,51,69,5,2,35,81,27,36,2,28,24,23,31,31,11,10,59,74,3,54,45,66,75,52,79,49,46,39,73,49,16,26,80,2,12,40,65,22,36,31,23,42,53,2,18,53,29,29,36,2,34,40,4,53,28,26,27,50,72,13,13,18,47,31,37,53,12,36,9,27,9,51,40,53,9,28,43,34,34,57,25,52,24,28,118,46,2,47,56,96,15,22,36,43,19,14,24,2,66,34,32,34,15,39,46,19,42,2,39,95,57,68,8,80,41,62,14,102,2,26,41,11,55,39,54,19,42,47,60,29,39,2,41,63,42,2,50,39,26,18,33,20,32,20,13,33,57,51,34,19,24,2,101,2,70,2,23,22,37,104,74,34,42,12,94,31,2,44,30,8,71,12,26,39,31,33,26,17,41,30,16,35,13,35,46,26,51,78,27,7,25,87,29,17,42,2,23,28,29,15,14,15,22,31,36,41,13,69,33,18,58,45,2,20,39,33,45,49,70,11,2,73,30,52,60,24,22,49,17,39,20,35,13,47,7,39,21,17,2,27,29,20,92,27,23,73,29,2,49,40,36,26,54,57,7,44,41,54,29,17,2,35,42,26,19,24,29,14,37,4,41,40,29,2,37,33,65,21,23,20,28,90,49,2,30,37,18,38,33,12,45,18,2,44,40,25,20,39,25,71,70,35,2,74,70,62,28,40,81,51,63,40,40,73,2,83,18,47,45,22,13,34,15,22,2,32,47,14,32,69,23,25,32,18,21,2,71,17,106,30,36,17,24,21,26,41,61,72,22,16,2,23,45,43,15,32,82,71,50,80,41,26,29,5,22,45,48,26,39,32,53,16,23,63,35,64,70,52,18,80,4,6,19,13,58,32,16,26,25,94,64,39,2,15,18,30,48,47,25,15,7,30,76,40,6,74,26,16,6,38,23,31,5,35,11,55,40,69,21,38,2,35,10,60,56,36,45,40,2,32,35,36,26,28,2,41,13,19,72,32,19,48,20,50,14,16,36,18,41,17,23,32,42,57,23,2,45,33,47,15,2,25,27,38,2,61,55,18,40,42,28,37,56,28,45,26,9,2,21,6,31,26,21,29,32,45,2,7,29,45,18,13,51,54,14,31,18,43,30,23,2,17,53,2,8,17,44,2,19,68,2,52,25,61,13,39,20,2,39,2,40,30,46,48,50,9,3,28,39,12,2,21,11,24,14,17,42,69,25,40,56,2,59,23,19,32,25,34,80,33,56,34,2,33,40,33,49,69,41,2,18,21,38,14,5,65,10,3,21,20,24,35,65,61,55,87,29,13,20,45,16,2,44,20,13,23,34,25,24,37,13,2,23,47,16,17,17,2,16,21,62,2,14,22,29,15,27,43,29,37,24,24,27,2,56,15,44,19,25,28,26,37,30,2,44,35,18,35,22,43,40,41,35,27,67,35,44,60,20,47,30,86,55,49,66,17,146,56,40,58,2,28,37,2,24,19,9,37,16,12,14,91,37,40,2,31,29,14,26,18,21,36,86,25,44,24,9,29,20,49,3,20,21,28,7,28,13,41,66,43,90,39,2,23,48,89,2,40,56,58,12,30,31,39,26,2,26,22,73,40,16,65,63,47,36,12,37,44,21,20,32,31,42,53,2,11,20,25,46,13,33,24,47,2,62,47,29,24,2,39,27,42,29,3,67,17,89,2,33,42,24,13,6,49,3,28,24,15,26,18,34,30,15,56,3,28,69,42,73,28,4,32,47,67,72,14,40,45,3,64,57,7,29,2,71,25,34,21,32,34,2,69,9,51,40,39,3,84,47,43,75,93,39,50,30,57,18,45,60,15,2,31,53,6,15,52,8,48,71,4,2,104,2,48,22,41,62,29,46,3,19,61,52,11,43,78,2,34,53,34,44,49,33,17,40,35,68,38,42,29,18,17,35,29,2,27,11,2,38,27,31,64,109,2,33,26,42,4,35,55,36,2,23,37,27,30,15,10,29,87,2,56,31,12,125,31,30,31,34,28,59,27,28,36,81,26,25,30,65,2,4,12,22,11,32,29,58,61,42,2,26,46,58,19,4,58,91,2,19,31,33,70,33,9,24,59,40,12,41,46,33,43,9,2,39,25,25,36,18,17,42,45,28,9,31,9,4,34,2,9,21,39,82,33,37,18,8,56,12,42,52,49,37,2,38,13,31,21,32,44,9,45,16,13,22,22,30,48,2,56,32,4,4,48,76,2,15,17,69,28,29,57,24,5,74,39,100,59,5,2,57,22,72,2,4,54,35,21,33,12,6,4,23,9,23,2,60,41,58,50,2,5,22,38,31,57,39,73,10,27,27,14,36,24,19,2,55,7,38,48,38,19,2,28,68,69,42,38,50,61,42,41,18,29,2,23,45,47,33,67,46,34,36,63,24,28,29,51,47,4,23,2,30,78,56,64,25,42,2,50,26,9,38,44,68,2,37,30,46,28,15,41,36,70,30,12,2,65,10,4,35,67,42,141,32,44,28,2,50,10,32,23,18,65,82,26,36,23,40,100,51,27,2,4,20,2,30,80,2,25,59,28,46,2,21,22,98,2,39,61,43,64,53,62,87,21,44,74,4,27,36,43,38,27,2,33,33,39,53,33,25,2,2,51,49,48,35,38,30,67,28,40,2,21,53,35,10,42,20,11,20,28,2,11,4,21,11,27,25,14,42,44,45,50,19,40,23,57,13,2,37,42,24,42,42,22,53,23,9,32,23,97,2,100,11,4,27,2,83,31,61,55,17,21,2,17,44,2,64,39,19,29,24,34,2,28,21,52,50,70,2,10,66,2,43,51,4,16,10,46,25,2,89,2,64,55,17,53,29,11,28,35,76,27,78,3,27,21,21,61,75,19,87,4,49,36,8,73,19,47,63,2,76,39,2,80,2,33,37,36,52,2,56,57,35,61,20,48,3,4,3,43,36,67,48,48,40,20,88,41,2,100,22,31,20,2,18,27,96,36,2,22,81,31,45,4,10,45,59,50,2,22,7,23,20,9,51,26,4,14,40,25,2,72,48,51,2,104,30,67,19,88,24,4,27,40,53,8,73,2,56,2,50,15,57,2,44,24,68,44,74,43,89,28,54,28,33,28,2,40,4,48,57,47,2,33,59,33,18,2,22,52,37,14,2,51,56,46,21,17,91,39,38,22,18,7,34,65,30,21,9,4,45,2,66,16,71,59,25,42,73,57,91,36,47,57,2,32,26,18,15,49,36,34,11,16,27,16,4,14,37,23,45,60,32,43,2,66,35,22,39,68,48,9,17,52,55,70,15,24,43,2,79,27,2,39,4,20,90,35,67,39,2,52,67,44,17,22,91,2,97,2,78,39,41,89,44,4,31,2,14,6,43,37,37,31,3,2,30,30,21,17,84,34,47,2,30,6,45,33,36,44,39,27,38,26,10,24,23,17,2,27,26,16,4,36,31,2,18,30,111,64,69,2,104,2,37,57,30,34,38,2,33,28,40,2,31,79,63,4,4,49,53,44,28,31,75,2,115,64,29,45,2,31,14,74,26,14,5,67,18,2,50,41,32,27,4,46,53,35,62,47,50,59,43,58,34,4,45,40,20,41,121,38,83,50,30,15,4,30,21,107,2,16,78,2,36,46,33,2,28,24,66,52,9,55,4,57,34,54,38,19,63,89,27,4,50,21,4,65,64,32,31,2,46,30,20,52,46,50,168,32,18,30,2,23,34,26,70,18,37,4,21,70,47,25,2,39,26,36,44,11,22,27,76,21,15,79,3,32,109,22,50,2,75,25,12,86,3,4,32,27,13,10,46,18,15,29,100,68,27,43,20,47,90,2,45,26,36,13,18,62,49,2,53,22,44,12,30,13,4,29,73,57,27,38,2,22,25,17,57,2,20,58,18,18,12,31,70,79,2,57,38,6,31,41,69,30,46,11,4,74,29,39,43,3,15,28,2,39,81,70,71,31,83,52,20,2,28,46,46,81,81,17,4,16,41,46,39,3,49,16,13,29,34,17,24,2,12,15,15,35,2,18,11,29,16,39,34,60,88,2,89,64,60,72,4,39,2,32,93,55,43,99,14,36,47,40,27,34,47,33,2,30,24,42,24,45,35,40,2,74,45,4,60,43,17,41,22,53,62,49,105,2,58,18,46,2,28,13,31,48,56,34,54,163,2,30,4,29,29,23,49,56,75,77,46,28,2,28,123,62,25,42,42,2,12,42,23,18,29,13,34,51,2,24,4,39,14,57,20,13,54,20,35,24,78,2,32,17,11,41,6,9,33,16,40,29,19,19,40,18,79,23,2,14,12,45,54,68,14,3,4,14,1,2,76,45,76,55,26,61,77,38,23,12,19,13,53,15,11,35,30,42,2,25,27,30,28,47,82,3,4,63,2,23,71,91,35,43,2,71,62,54,3,23,6,36,45,31,41,57,43,34,66,38,24,8,4,33,2,13,20,33,25,2,49,2,28,45,29,30,2,65,39,20,49,41,33,2,21,37,23,65,3,53,23,2,76,26,37,41,17,4,21,35,24,67,42,12,97,65,2,24,69,33,50,48,39,11,21,50,5,75,40,58,21,55,3,4,43,17,38,23,2,12,55,40,27,33,22,41,18,30,44,2,9,9,29,54,16,53,43,11,20,16,40,53,75,18,38,28,8,63,2,50,37,43,13,20,2,24,57,48,24,38,54,29,2,16,31,26,22,2,12,29,34,36,2,38,28,2,50,31,68,20,4,10,24,88,2,29,61,25,32,22,38,23,2,28,58,35,7,65,39,2,13,17,30,20,54,74,42,24,43,16,55,13,3,4,3,34,36,56,26,49,60,30,2,95,24,80,59,2,23,35,35,27,39,20,3,49,57,65,21,37,4,33,28,2,55,61,27,44,8,40,48,39,44,31,33,6,32,21,33,118,36,10,2,15,33,49,63,50,30,4,12,2,47,25,55,73,11,25,41,47,32,37,25,36,26,19,67,72,2,34,44,2,27,41,45,33,47,33,21,4,15,2,25,27,34,22,46,24,50,26,15,2,52,26,26,65,30,33,6,25,42,104,2,32,13,58,52,15,55,19,33,48,27,4,17,65,88,29,37,35,47,2,55,26,39,44,77,51,57,24,2,41,34,33,64,24,80,2,30,8,4,53,98,40,26,35,30,18,51,67,2,43,37,84,2,39,33,49,24,63,22,65,2,47,30,2,4,15,23,30,25,41,47,56,64,33,32,46,22,45,29,31,2,35,25,47,34,7,46,25,25,2,16,14,37,27,2,51,7,4,42,40,46,143,2,31,26,46,68,24,2,29,33,90,90,3,45,24,31,57,36,55,44,4,5,32,16,23,53,4,70,51,44,57,15,29,56,58,26,43,30,15,30,2,59,27,18,11,34,24,2,24,56,22,61,14,27,4,9,15,26,58,19,37,26,57,59,43,2,40,60,27,40,24,22,31,16,13,17,40,75,70,31,6,70,23,4,21,2,44,53,26,23,77,43,2,84,18,21,35,21,44,2,70,22,41,43,24,39,2,58,55,57,48,4,18,42,19,44,57,2,39,37,25,75,38,17,3,42,64,77,73,51,41,25,3,97,20,34,2,21,45,2,4,31,44,70,51,87,2,39,60,38,64,28,2,26,36,27,41,42,39,39,2,29,15,22,52,51,50,56,6,4,17,55,2,43,31,18,80,53,84,18,34,105,39,30,27,39,33,2,31,58,100,26,29,42,19,4,42,4,61,25,74,46,28,45,2,5,16,44,30,39,16,2,42,44,21,21,71,43,75,36,39,2,37,38,20,2,13,9,4,53,55,2,8,20,22,7,49,27,54,33,29,36,17,43,58,44,39,16,19,47,2,12,59,35,6,11,49,77,44,17,4,21,56,40,25,2,28,21,38,30,28,5,2,60,2,34,8,17,8,45,65,19,39,40,19,49,31,56,20,60,2,14,23,17,12,20,11,2,4,26,2,20,43,52,45,27,34,34,98,3,27,19,40,27,28,9,30,28,31,4,25,33,25,2,41,17,33,57,2,86,2,4,3,33,43,33,91,2,79,19,59,2,40,43,58,34,21,25,52,44,2,13,86,12,19,6,12,23,3,40,33,4,22,27,34,73,36,44,32,48,40,19,38,25,20,4,3,3,34,30,38,28,30,28,25,41,32,8,31,27,2,24,42,4,31,48,33,43,33,25,2,16,11,19,24,46,40,53,19,15,21,4,63,16,51,2,23,37,44,2,10,22,49,116,2,45,4,4,19,2,4,5,16,22,48,34,23,2,43,19,18,57,56,49,5,4,10,12,66,56,42,2,26,78,33,20,53,2,25,28,4,24,33,2,18,62,2,29,32,35,40,10,80,3,83,11,38,49,65,71,13,43,34,46,61,54,39,4,46,4,51,39,2,40,52,57,28,39,127,58,57,41,112,41,2,17,71,32,10,4,49,18,2,17,30,17,23,2,34,20,30,19,41,61,23,34,10,67,52,21,28,2,25,51,28,17,52,57,35,36,12,4,56,2,21,18,20,40,78,45,45,18,66,45,96,62,32,61,21,24,30,41,18,24,37,41,5,2,4,25,31,21,27,2,34,23,46,49,28,2,22,24,94,41,59,19,36,54,2,48,27,63,33,34,54,25,21,19,4,8,74,62,2,24,32,53,35,63,29,85,15,8,5,5,27,25,10,17,12,55,60,2,31,23,2,46,97,16,24,4,5,28,26,47,87,28,27,45,62,63,2,52,71,42,31,59,43,19,59,81,2,84,4,3,62,32,55,10,16,39,66,47,22,86,4,99,31,41,26,2,30,39,36,16,31,59,59,58,48,4,32,2,41,53,37,43,29,14,33,18,47,46,33,2,29,2,13,36,21,20,38,78,37,43,2,31,28,26,16,23,76,10,41,28,105,69,54,41,2,32,25,25,30,41,25,15,36,40,32,71,25,2,54,27,36,40,33,27,4,23,26,53,55,42,20,78,47,55,39,29,41,53,27,28,19,51,12,2,32,45,28,32,43,25,2,4,6,49,30,3,48,27,42,21,41,2,16,8,25,2,16,15,19,43,16,32,55,54,2,40,77,21,19,45,32,51,30,30,4,28,7,41,31,46,3,52,71,39,17,28,20,23,40,54,25,2,15,30,20,26,27,50,18,9,34,30,28,2,21,18,30,26,22,12,4,26,44,4,3,26,33,47,37,56,67,47,14,26,35,20,18,13,2,25,36,2,27,26,10,36,2,22,42,47,62,27,34,9,4,53,141,31,48,72,29,36,43,2,7,10,37,52,47,19,54,2,37,33,22,19,20,47,53,25,8,4,18,2,13,23,51,43,23,25,22,53,82,20,90,2,19,15,46,31,7,33,22,46,32,19,17,18,42,53,24,34,50,5,43,39,133,58,28,70,58,2,47,45,49,11,64,2,34,13,32,38,32,12,40,47,13,31,4,18,48,39,9,2,45,35,12,24,16,14,26,30,39,44,34,35,2,37,17,40,31,15,36,55,35,51,2,51,19,45,37,50,2,4,3,23,14,8,36,41,38,52,22,2,74,22,18,41,40,27,24,10,2,38,13,47,58,2,15,129,2,41,45,44,21,4,11,25,61,11,23,2,59,29,47,2,30,38,15,32,35,35,2,21,22,54,22,32,11,82,35,2,32,18,67,2,64,25,28,3,4,3,32,51,29,24,37,40,2,18,62,17,36,4,83,24,30,48,40,61,38,2,28,26,53,60,99,42,27,3,13,4,82,50,27,29,42,9,45,30,18,4,32,9,66,99,61,27,39,30,69,2,23,60,27,80,20,4,21,34,6,28,5,72,46,15,2,2,61,73,37,10,12,4,26,27,19,61,4,11,43,44,46,6,20,3,34,32,8,44,21,4,3,38,20,45,4,8,27,24,30,24,46,32,12,3,15,30,97,2,39,22,18,47,14,4,94,17,32,24,86,47,19,2,50,53,20,71,4,18,35,25,31,22,60,66,30,21,74,50,40,33,64,63,43,44,48,37,27,27,22,36,2,45,17,4,90,56,53,34,3,71,42,21,34,20,57,9,4,2,91,2,120,60,7,35,32,44,2,14,52,25,4,32,71,2,25,60,61,45,49,39,51,50,40,33,42,23,28,2,6,15,26,17,5,50,27,30,47,64,18,16,4,15,18,70,41,22,36,2,68,2,41,10,15,59,37,40,9,3,11,34,67,14,64,19,41,57,19,37,53,20,45,4,13,27,40,40,11,23,22,3,36,63,76,2,31,10,47,3,26,24,56,59,2,61,39,31,2,37,40,42,2,60,26,4,23,32,64,71,63,2,42,40,17,2,12,38,41,22,2,24,34,18,22,48,49,54,53,42,15,8,19,4,31,8,11,48,27,26,4,23,24,2,4,31,28,30,2,34,82,40,73,2,16,77,49,48,44,22,36,2,9,82,59,29,45,2,17,3,5,11,13,12,12,15,49,24,62,59,2,14,21,19,22,35,28,58,21,4,18,15,64,54,2,45,41,34,32,22,52,32,31,29,5,4,12,16,25,62,53,2,27,25,23,2,35,29,53,2,2,30,33,40,7,4,26,21,20,41,19,31,20,19,32,41,30,24,58,40,60,25,4,39,2,43,62,47,21,28,40,17,45,38,36,15,33,67,18,9,21,19,2,47,22,31,26,12,2,32,34,34,67,31,22,11,32,8,4,38,9,43,83,2,30,52,28,2,16,19,46,29,23,47,24,5,12,20,75,2,69,26,74,26,19,56,46,21,13,30,39,58,105,24,57,44,83,2,18,46,10,63,68,2,57,68,15,66,86,84,4,13,33,2,12,55,9,8,9,16,11,28,36,14,37,28,41,54,2,51,47,12,24,44,35,29,75,2,30,23,12,21,16,32,95,15,34,31,4,11,46,2,42,9,54,27,82,18,52,37,27,23,9,37,48,26,3,24,33,50,2,26,75,7,11,89,2,52,57,23,4,62,18,2,24,34,9,14,57,73,16,2,26,30,46,33,22,17,30,64,52,10,43,52,26,2,53,44,43,27,59,4,10,49,11,43,7,45,2,39,97,15,31,16,59,2,16,88,14,59,5,22,35,56,24,35,2,47,51,99,17,33,23,14,2,44,29,43,2,33,64,31,38,57,68,2,30,47,44,65,14,42,31,59,33,2,6,34,13,4,33,11,34,45,32,30,3,52,36,8,53,52,2,33,49,38,26,5,22,2,43,36,18,42,13,2,45,37,13,24,42,2,30,23,4,31,53,40,32,103,42,32,81,96,4,27,54,22,19,51,53,2,68,36,28,4,48,77,15,4,12,64,60,13,167,35,3,62,35,55,27,32,31,46,20,22,20,4,17,11,74,43,13,2,9,8,33,25,58,4,44,2,23,76,50,31,10,82,43,39,2,9,52,40,40,68,2,21,64,41,68,62,2,61,33,4,18,40,2,78,67,2,26,42,27,29,76,53,61,67,33,2,41,46,39,33,2,40,55,40,44,4,21,23,58,37,29,2,29,20,26,52,45,71,63,2,25,25,25,21,27,48,57,2,35,86,48,2,46,23,4,70,86,39,85,47,85,50,38,47,79,26,33,15,29,25,13,2,15,39,49,40,15,2,4,9,3,25,17,46,48,17,16,50,2,13,17,73,70,67,3,31,19,14,26,2,8,9,28,21,19,22,77,16,73,2,23,15,28,4,18,28,2,37,10,55,55,51,2,17,33,62,37,53,40,19,11,40,4,36,14,85,38,20,5,25,4,16,10,50,32,35,19,18,4,28,23,38,23,62,16,31,31,45,37,21,33,30,12,23,24,7,50,35,71,3,37,2,39,24,22,24,20,40,2,55,31,40,4,10,45,42,2,23,23,50,67,30,3,21,24,25,34,83,4,41,24,53,8,2,37,48,34,2,23,24,20,42,11,2,12,53,18,18,9,4,33,41,2,31,52,44,17,7,40,47,11,77,4,52,24,8,33,10,15,18,16,69,3,39,64,17,4,22,8,27,2,20,17,47,45,3,45,43,41,7,48,25,26,38,20,36,2,23,23,60,37,53,21,12,2,52,35,28,24,58,82,30,43,57,23,2,33,31,21,4,31,15,36,19,40,92,41,7,21,2,25,18,29,30,32,63,3,33,39,30,24,47,2,25,49,10,24,4,26,13,62,31,20,31,11,19,4,16,40,36,13,53,15,38,57,31,27,8,36,22,36,31,51,2,22,25,20,30,17,40,27,2,35,28,41,8,18,47,26,31,16,6,4,34,2,19,24,9,4,9,66,50,33,10,20,34,41,36,8,4,55,21,33,47,13,2,44,48,31,18,15,56,21,2,76,52,54,10,25,4,4,12,9,11,50,16,40,28,68,3,62,27,53,152,38,55,48,43,20,46,26,5,22,76,23,30,26,4,15,99,33,2,48,36,21,23,48,26,52,35,33,15,39,15,2,56,56,22,2,17,27,37,55,38,16,62,16,29,37,4,42,46,25,22,38,50,2,55,2,31,33,57,96,80,12,2,43,11,48,53,30,2,34,28,26,37,33,55,20,4,24,2,22,29,37,36,20,31,41,40,46,23,68,35,2,38,23,65,42,36,22,2,49,50,41,52,49,18,4,48,57,2,21,20,40,39,22,60,50,15,4,21,49,40,51,30,24,2,16,22,82,53,36,49,57,53,12,23,4,12,17,42,11,2,78,34,53,71,15,28,38,35,61,27,23,26,55,2,53,71,20,35,61,29,21,13,30,2,11,4,14,29,37,2,27,36,77,30,58,44,47,23,31,2,35,29,70,2,55,22,32,49,3,17,38,51,2,14,23,48,24,2,37,4,39,26,50,43,17,25,32,46,75,18,2,32,23,44,26,15,38,15,11,19,40,29,30,23,38,50,2,30,52,23,2,32,24,8,4,12,36,27,56,79,21,57,38,17,78,2,40,8,113,24,31,2,126,46,52,80,21,4,8,89,21,39,38,2,44,61,10,34,59,3,56,8,11,29,83,2,54,63,54,64,2,61,75,9,57,24,2,32,71,53,34,36,37,43,2,21,32,17,18,54,2,26,65,27,40,37,48,23,62,2,22,25,40,34,4,16,53,39,53,30,21,77,78,47,62,57,6,2,30,66,34,37,60,96,15,2,25,13,26,9,75,4,10,143,43,30,32,71,41,2,69,17,108,32,2,5,20,31,13,38,47,38,34,33,2,32,31,22,17,4,32,35,45,3,26,38,32,35,51,9,23,6,25,23,21,98,27,28,15,8,11,60,21,45,77,4,3,3,75,2,25,53,45,28,39,2,23,44,25,19,64,26,2,42,35,8,48,2,35,46,27,2,15,10,37,45,44,19,4,68,2,40,43,71,28,55,7,38,20,44,2,54,30,32,19,24,60,34,33,43,13,27,12,37,2,61,16,29,28,4,21,69,37,50,29,25,2,9,16,14,49,35,53,21,91,49,28,63,2,52,22,34,13,45,47,18,47,31,4,17,29,48,20,2,22,16,28,34,27,39,26,8,62,39,2,4,31,38,28,30,67,59,52,19,47,35,84,50,7,4,26,53,45,37,67,39,23,28,2,5,46,45,51,43,2,27,44,27,33,30,10,64,73,2,52,24,32,4,25,2,26,22,24,37,7,41,19,24,46,88,62,5,57,7,27,26,108,6,43,2,72,28,84,2,40,35,40,27,30,44,43,2,37,61,47,48,4,59,20,57,32,53,66,2,20,59,11,2,35,7,54,4,13,69,2,54,23,39,15,44,4,2,8,28,37,2,25,10,137,37,2,30,40,56,69,77,75,4,6,34,64,42,38,2,11,61,18,67,35,40,17,31,2,35,39,20,16,35,2,7,15,65,2,24,13,45,22,5,51,77,3,4,3,24,62,47,32,35,25,23,55,63,2,76,25,41,57,23,25,11,31,67,52,2,20,32,36,38,77,2,11,2,4,45,13,55,52,18,30,27,22,32,3,17,63,38,24,43,26,57,4,172,41,106,42,3,8,37,84,53,2,37,12,72,2,59,49,22,43,41,14,8,71,23,4,14,11,17,11,73,69,31,20,32,49,4,28,3,35,58,16,22,40,16,25,25,51,4,29,39,18,41,34,65,2,22,31,56,44,26,50,54,26,69,2,7,38,4,4,52,64,15,29,41,80,32,82,43,10,40,39,32,47,2,24,35,23,72,73,2,69,71,4,13,2,14,35,43,32,2,72,55,15,30,36,34,65,2,38,22,39,62,45,58,54,40,35,8,21,24,44,4,17,50,48,44,38,2,28,19,20,40,48,2,22,42,47,41,32,24,84,43,36,36,61,24,5,11,35,44,15,24,4,31,45,50,78,16,26,26,20,32,40,55,94,83,2,57,50,33,51,59,2,58,36,10,48,86,33,67,2,46,49,57,102,117,2,39,17,40,43,2,26,26,88,19,4,30,24,2,21,43,39,51,44,20,29,2,32,58,22,2,5,6,3,2,27,40,2,26,52,70,21,3,20,31,35,38,45,52,29,4,8,63,2,55,47,58,55,51,23,61,69,54,2,45,60,88,92,2,29,40,19,36,4,7,62,47,27,2,50,2,22,16,43,39,35,69,2,38,14,67,36,5,52,159,2,60,36,49,4,5,35,53,74,2,35,21,12,36,17,71,53,36,40,26,6,62,32,44,20,14,46,2,39,104,48,4,13,43,57,24,19,22,28,79,3,41,40,36,20,29,29,19,27,55,2,40,26,25,26,29,28,35,55,48,63,4,10,19,28,158,2,32,20,113,73,8,41,2,58,22,38,48,44,34,2,77,26,73,6,4,39,2,40,13,25,7,31,34,55,11,23,43,9,2,40,23,15,44,62,80,2,30,27,30,57,10,11,16,23,35,33,18,6,42,49,8,4,39,36,49,38,22,19,2,17,12,42,39,49,20,30,11,30,3,57,11,15,70,23,7,41,53,43,56,2,19,44,38,31,15,4,3,18,18,25,13,94,2,27,19,49,28,46,92,2,62,29,2,20,23,29,49,58,14,16,51,23,61,37,60,6,3,24,15,23,19,35,52,61,2,78,68,31,2,49,22,34,43,15,33,41,26,18,2,38,38,43,39,2,10,30,14,20,43,4,7,80,31,76,50,52,2,43,25,47,18,9,63,39,11,2,97,2,26,7,101,49,2,72,35,15,4,27,41,58,124,33,7,68,43,83,112,46,23,58,76,7,39,2,17,51,19,24,4,26,51,66,34,28,17,29,42,2,47,28,34,13,44,44,35,52,45,11,2,16,60,12,28,64,49,66,4,43,16,63,27,74,44,68,59,35,53,48,48,19,27,48,45,46,19,2,13,9,24,43,49,13,2,27,33,81,12,96,3,47,2,42,33,31,26,68,36,18,2,14,31,30,68,24,23,38,19,31,2,11,40,28,13,44,2,4,55,39,31,43,59,31,15,45,53,38,2,43,25,28,32,19,119,2,63,55,35,7,37,7,39,35,4,13,58,32,37,35,63,23,48,43,14,51,4,4,4,57,50,96,19,43,18,31,18,33,19,4,36,2,36,24,40,20,24,33,22,102,2,11,22,17,20,25,39,50,18,39,2,47,13,16,135,2,44,6,50,9,33,39,13,4,18,2,42,26,53,20,47,15,59,71,2,38,33,11,38,83,2,54,62,47,13,24,24,29,17,33,58,47,4,23,2,86,35,22,52,33,99,42,23,60,5,51,38,70,33,50,2,36,43,65,2,63,32,16,20,13,14,4,9,27,2,43,18,25,36,10,13,14,7,48,2,30,57,33,11,2,20,37,25,63,92,42,30,20,51,5,47,85,10,2,56,23,35,2,4,41,15,24,55,32,26,28,28,2,87,16,21,52,32,47,56,75,70,32,38,43,33,77,55,23,4,17,2,100,44,40,39,131,2,35,13,13,25,23,61,24,37,40,7,30,55,17,23,61,2,26,36,20,2,12,4,28,32,39,41,2,43,45,37,6,54,42,29,31,44,18,26,54,38,89,19,11,62,13,23,21,53,64,12,42,48,17,52,13,31,10,35,130,72,24,57,38,11,57,52,25,26,231,53,45,44,51,32,17,39,5,35,50,70,123,54,40,70,57,45,89,84,12,37,80,13,81,62,49,9,32,19,23,133,106,63,61,79,20,40,57,11,32,7,30,58,132,17,67,70,43,141,71,34,57,31,70,34,50,64,96,61,12,93,46,31,137,42,74,28,111,70,131,5,58,26,95,92,61,23,101,29,103,26,31,17,5,30,46,38,80,46,59,67,18,60,201,92,51,67,52,110,49,74,50,51,152,84,29,29,40,66,40,44,153,105,82,40,20,115,34,90,85,145,10,16,55,13,64,99,23,39,20,69,125,57,30,26,22,13,149,161,122,118,58,112,54,207,44,33,83,112,271,74,20,123,40,81,56,104,97,141,266,61,147,14,95,99,102,100,42,54,48,73,102,57,92,140,140,76,113,5,37,28,110,51,22,58,34,75,84,76,21,66,10,6,6,23,49,73,92,25,25,21,19,10,2,10,2,4,17,13,24,19,36,37,51,96,55,99,97,57,39,16,4,27,27,25,22,24,34,20,32,41,51,36,28,27,28,81,75,50,24,42,15,45,101,17,71,38,12,59,13,14,33,41,101,56,32,68,69,13,36,29,36,67,47,22,37,9,48,177,10,29,18,32,14,17,16,67,14,64,30,5,20,16,64,61,38,10,75,63,79,164,6,17,8,100,33,101,58,58,34,62,26,32,93,25,49,22,61,33,44,43,5,53,13,110,21,68,41,46,41,26,17,9,25,40,11,25,34,27,19,37,3,20,22,26,53,46,46,68,28,60,29,163,28,14,45,58,69,4,31,6,7,33,57,99,16,63,97,58,37,15,12,15,18,54,23,28,26,20,24,33,21,34,40,50,36,24,9,27,29,72,14,13,22,16,32,80,18,10,42,43,15,42,103,20,17,51,20,14,12,9,14,17,35,12,11,43,24,61,60,33,50,67,75,13,25,11,23,13,15,7,17,37,37,131,65,15,7,44,40,19,13,20,11,17,9,14,27,19,79,34,43,43,55,46,62,73,39,63,15,88,16,16,45,18,78,28,36,26,68,2,62,25,26,26,30,2,29,25,155,3,30,37,21,44,36,248,7,33,62,39,84,21,37,101,93,67,24,45,121,124,50,74,19,18,40,16,15,19,15,64,64,45,10,76,42,28,17,14,19,34,15,61,77,130,30,50,54,8,44,29,29,6,17,20,13,91,55,57,34,113,15,26,46,21,58,47,62,32,45,17,87,23,32,49,24,16,90,23,21,29,10,7,34,17,17,30,62,23,32,15,67,35,16,42,30,38,6,53,65,72,36,10,37,43,39,11,30,94,17,7,7,95,96,3,23,113,34,35,18,30,31,35,37,34,10,2,14,54,32,35,34,2,3,53,6,18,25,49,11,27,33,50,28,37,93,51,24,10,12,11,23,33,16,3,87,63,33,22,14,18,38,64,63,23,14,39,34,29,3,19,46,23,23,34,33,28,16,44,39,21,24,17,35,72,16,60,42,61,27,21,35,14,3,78,24,23,28,15,24,7,10,24,27,29,20,25,51,30,43,16,40,4,5,3,14,13,30,14,47,7,55,45,31,19,28,42,81,28,15,24,52,3,55,62,45,65,42,26,48,43,28,28,43,20,55,43,56,83,14,8,6,13,28,13,10,54,13,17,11,45,19,68,21,15,20,26,19,18,3,90,66,24,117,70,49,21,45,36,57,19,192,92,78,30,35,45,23,87,3,15,36,108,25,41,10,14,51,27,30,68,68,21,15,44,51,82,203,23,10,94,43,21,5,3,71,115,45,22,67,76,64,43,27,4,61,25,28,31,19,137,153,7,24,69,23,66,42,22,33,58,25,14,11,51,59,12,47,25,32,62,23,32,12,68,35,16,43,32,40,6,59,89,72,11,40,42,40,10,36,19,75,17,7,69,95,4,7,73,32,21,28,67,36,34,26,73,12,65,21,104,18,17,5,3,17,30,39,17,18,37,31,46,31,49,18,45,50,28,10,40,73,20,37,23,52,65,33,23,33,38,65,60,18,3,18,28,147,43,114,9,28,23,29,15,34,7,15,7,10,26,26,27,21,26,49,12,22,21,14,13,30,12,58,29,34,41,15,9,5,3,118,44,54,45,31,19,27,40,81,28,17,23,11,93,65,45,62,42,26,47,43,28,28,42,22,29,3,39,90,81,14,8,6,14,32,75,13,17,11,45,19,21,8,44,42,68,23,114,43,27,50,20,46,36,9,3,67,190,92,21,48,10,30,35,21,16,4,57,106,24,40,7,14,53,25,31,70,64,25,7,3,15,22,48,51,82,205,23,10,101,24,18,4,42,71,119,45,42,67,44,31,64,26,3,35,66,26,27,31,19,92,46,150,2,78,6,60,29,74,82,101,68,27,39,43,72,7,3,98,2,109,3,62,22,100,70,53,18,20,41,154,2,71,51,21,223,3,83,6,27,112,5,78,33,7,31,11,32,17,44,31,18,12,19,24,5,2,2,7,45,13,19,10,29,32,28,62,22,53,29,10,99,49,33,38,32,32,30,12,37,42,17,80,121,2,4,18,22,52,11,7,2,2,22,38,46,110,83,52,35,26,79,59,38,2,11,55,43,20,123,22,80,40,47,38,5,7,2,2,5,29,29,101,67,96,89,13,95,41,85,11,45,14,41,32,19,48,29,76,42,2,2,12,53,14,114,32,20,2,18,2,20,2,20,73,19,31,54,32,9,7,7,10,156,13,29,35,10,11,2,9,2,32,19,29,34,35,8,6,11,9,56,75,22,74,49,46,26,18,14,14,10,16,23,15,22,22,21,68,91,13,54,31,15,6,21,22,101,31,2,2,2,5,5,20,24,14,30,51,11,6,57,20,14,15,4,8,21,38,35,53,4,95,2,41,33,70,42,23,6,44,54,35,21,5,2,2,2,2,4,30,77,70,46,34,42,14,16,129,31,36,45,35,26,4,28,71,2,85,14,14,42,44,21,61,44,71,16,22,28,10,2,2,2,5,50,65,29,45,59,50,37,6,32,25,77,25,12,92,48,31,17,62,15,18,22,50,45,43,64,41,9,2,2,2,5,41,88,14,40,41,41,23,11,18,9,15,64,87,17,38,21,7,75,72,26,31,36,48,7,2,2,2,4,2,23,67,50,25,32,48,35,88,83,10,7,3,12,6,17,23,58,9,71,17,23,14,38,18,59,25,39,80,24,59,34,8,2,2,2,5,92,132,87,3,67,121,6,28,106,60,9,17,30,44,70,16,165,2,2,2,2,3,2,3,108,38,40,61,40,84,26,14,23,9,52,6,3,15,17,2,2,2,3,3,39,52,74,85,61,58,42,15,90,6,70,46,61,39,55,39,32,33,73,101,18,7,2,2,2,3,3,60,56,76,50,62,59,21,39,100,38,4,156,21,98,32,77,34,26,27,74,25,11,9,6,9,2,2,2,2,2,3,11,58,23,19,65,49,47,29,64,93,31,74,8,63,21,31,31,53,39,30,34,59,28,136,17,7,3,2,3,3,29,118,40,12,60,41,14,73,63,28,5,4,27,40,33,43,48,25,89,86,54,81,21,2,2,2,3,3,33,38,89,141,2,10,87,14,48,4,21,90,23,39,9,2,9,71,80,138,18,2,2,2,2,2,2,2,23,38,95,52,77,15,67,10,32,52,30,4,68,14,26,75,23,36,24,42,173,21,44,16,2,2,2,2,2,2,2,33,47,39,29,34,36,10,82,64,23,26,41,14,43,17,4,32,76,145,19,21,31,94,39,38,87,2,2,2,3,3,62,14,45,25,35,54,51,68,34,62,54,73,37,29,72,71,30,37,8,15,35,50,42,19,2,2,2,3,3,27,32,120,39,41,31,21,63,44,50,30,48,110,32,33,49,54,33,20,52,28,33,47,11,2,2,2,2,2,2,2,9,36,25,95,50,39,102,73,33,59,41,40,34,34,80,72,18,63,89,64,8,2,2,2,3,3,13,28,74,14,29,49,59,62,77,62,21,40,18,36,23,30,49,64,29,68,48,23,76,92,8,59,6,25,2,2,2,3,3,63,11,13,16,20,23,65,42,31,30,22,41,49,49,44,38,36,4,64,35,61,19,33,7,37,59,37,31,47,33,29,2,2,2,3,3,43,24,74,21,40,53,190,13,81,5,2,2,2,3,3,2,56,31,15,89,8,48,3,9,54,15,26,101,46,6,2,29,24,81,11,33,23,34,54,179,74,43,5,2,2,2,3,3,2,10,35,133,39,36,40,56,21,37,30,91,2,84,11,14,40,44,51,32,73,66,71,16,18,2,2,2,3,3,2,33,37,71,64,3,8,69,22,27,69,50,2,13,44,59,74,81,18,140,18,12,2,2,2,3,2,2,2,11,88,53,84,3,22,122,47,24,5,17,4,2,12,3,40,43,80,84,52,65,99,6,33,7,2,2,2,3,3,2,112,3,19,16,112,48,33,48,37,30,55,10,2,45,8,26,49,36,26,42,16,67,16,76,80,37,2,2,2,3,3,2,59,8,17,58,52,140,93,52,16,22,4,2,161,18,73,154,108,22,2,2,2,3,3,2,31,135,8,109,66,27,92,41,12,2,81,230,56,10,75,12,39,20,13,2,2,2,3,3,2,78,39,199,15,41,32,102,13,15,2,12,18,59,65,43,43,53,48,77,53,48,7,2,2,2,2,2,2,2,2,58,41,50,63,67,36,48,48,58,31,10,2,18,42,96,8,54,52,19,19,23,33,129,21,5,2,2,2,3,3,2,33,27,43,13,30,22,10,17,58,40,191,26,6,4,2,45,40,150,182,6,69,2,2,2,3,3,2,33,26,55,14,44,101,31,59,29,54,43,2,2,2,3,3,45,10,46,20,47,38,57,101,50,36,55,28,98,19,93,28,59,104,57,61,8,26,11,2,2,2,3,91,86,92,34,35,61,27,33,18,65,46,14,2,2,2,3,2,2,51,46,53,44,26,8,15,30,31,26,38,94,105,83,54,48,22,68,30,32,37,31,51,50,46,49,5,2,2,2,3,2,2,68,112,46,30,40,72,15,26,85,47,10,26,28,49,85,40,20,47,31,18,46,60,11,113,5,2,2,2,3,2,2,59,57,58,96,39,45,24,23,124,20,96,37,24,22,24,64,42,53,34,13,67,21,73,88,59,78,75,88,5,2,2,2,3,2,2,22,36,35,88,39,57,39,21,91,41,23,12,73,16,40,62,30,51,42,22,18,41,68,40,16,26,27,14,2,2,2,3,2,2,64,42,41,45,98,18,77,51,43,86,4,54,61,33,88,21,86,87,46,17,2,2,2,3,2,2,29,37,61,55,41,63,45,39,89,15,58,6,13,14,4,5,8,6,29,92,15,25,11,23,3,2,7,3,4,2,16,7,12,56,9,2,2,2,3,2,2,119,3,78,95,129,3,33,36,67,13,39,163,12,42,5,18,29,31,52,63,9,26,34,13,2,2,2,3,2,2,51,45,79,15,21,28,48,48,13,99,35,32,31,45,21,16,46,58,36,26,18,36,7,73,39,64,100,27,5,5,2,2,2,3,2,2,3,60,56,31,15,55,78,88,64,19,10,24,58,46,68,8,27,51,31,66,68,33,15,71,21,19,2,2,2,3,2,2,49,40,26,46,11,53,51,35,55,2,62,57,28,118,8,13,149,58,47,100,56,98,8,58,2,2,2,3,2,2,34,37,163,84,10,52,103,75,65,20,8,47,56,39,27,62,44,45,3,24,15,19,7,2,2,2,3,2,2,59,72,81,45,40,59,42,6,79,42,22,10,38,4,22,65,58,37,49,59,85,33,9,21,102,25,2,2,2,3,2,2,3,47,64,177,76,32,102,89,7,8,3,8,82,73,46,23,25,9,23,21,43,34,14,44,50,17,51,26,23,5,2,2,2,3,2,2,33,43,9,48,40,46,42,67,53,24,42,28,36,65,29,20,11,74,48,67,44,11,48,89,18,72,6,16,15,23,2,2,2,3,2,2,46,12,35,60,45,44,29,120,30,22,21,30,53,29,6,23,4,112,16,13,19,15,62,103,16,50,26,13,50,25,24,2,2,2,3,2,2,16,35,3,40,104,56,9,29,9,37,56,19,12,8,101,84,67,9,22,55,16,57,120,13,2,2,2,3,2,2,15,58,22,22,79,64,80,19,8,75,14,42,57,12,9,39,23,51,35,38,38,23,43,52,59,50,68,32,2,2,2,3,2,2,38,84,59,30,105,82,69,53,15,72,109,40,30,66,80,16,7,27,37,2,2,2,3,2,2,63,54,86,80,113,17,46,62,51,107,21,35,40,34,17,33,30,12,78,59,49,9,2,2,2,3,2,2,40,81,43,13,50,21,13,45,39,42,31,37,28,17,41,24,16,18,6,28,44,97,35,34,36,35,42,14,48,49,56,54,7,2,2,2,3,2,2,27,30,28,14,114,42,47,75,41,81,31,33,11,6,26,40,42,31,21,73,26,20,59,64,16,61,58,41,41,6,2,2,2,3,2,2,66,24,36,112,4,16,32,79,57,14,21,9,4,28,78,53,56,62,15,41,65,29,53,27,41,42,9,30,14,2,2,2,3,2,2,66,63,51,20,68,26,28,20,33,114,38,20,4,67,48,8,59,78,32,34,9,38,82,41,14,7,2,2,2,3,2,2,74,33,52,56,44,61,95,37,7,37,74,8,50,53,9,3,20,2,20,2,118,45,70,21,29,25,22,30,14,2,2,2,3,2,2,45,42,58,57,58,25,4,20,20,3,29,30,10,12,8,25,3,23,22,7,72,11,6,18,117,43,154,16,37,59,64,67,2,2,2,3,2,2,18,82,60,153,57,41,27,52,61,16,69,82,121,18,71,33,51,46,26,2,2,2,3,2,2,31,50,27,43,26,166,18,63,50,38,30,12,9,56,26,67,3,22,63,61,24,84,54,9,2,2,2,3,2,2,24,113,21,117,28,44,92,23,14,25,30,4,33,129,33,47,32,73,44,40,19,11,17,5,2,2,2,3,2,2,94,9,21,31,82,92,73,44,24,50,9,6,32,33,8,128,71,49,40,52,36,11,15,51,63,20,32,5,2,2,2,3,2,2,46,51,28,45,169,42,51,98,57,27,79,46,40,35,63,33,22,47,47,42,35,29,14,19,2,2,2,3,2,2,60,105,34,65,52,24,35,20,45,72,18,8,27,108,34,74,49,83,79,79,15,57,10,2,2,2,3,2,2,5,18,183,47,74,28,68,31,54,22,26,4,188,33,25,14,39,32,12,5,3,9,25,10,21,21,31,35,20,13,37,48,13,36,78,114,36,34,104,100,19,11,12,24,43,20,16,2,2,2,3,2,93,65,105,60,96,19,43,49,29,52,40,57,32,31,22,20,52,46,31,46,59,139,37,7,2,2,2,3,2,71,61,137,38,23,36,73,4,22,22,20,53,25,11,62,95,134,157,61,32,44,7,2,2,2,2,2,2,66,64,50,96,54,91,56,35,15,2,9,11,23,145,63,12,46,3,49,42,34,18,30,24,29,30,29,7,2,2,2,3,2,31,57,73,122,58,11,6,25,83,25,19,12,46,25,32,58,3,6,8,34,56,120,98,118,11,63,47,30,7,2,2,2,3,2,35,78,26,67,29,40,48,128,47,34,29,4,47,78,115,51,31,74,22,7,93,19,6,16,66,5,2,2,2,2,2,2,49,40,36,52,39,66,70,87,33,36,29,6,9,6,4,64,66,29,62,39,29,55,55,61,26,66,10,8,20,2,2,2,3,2,14,44,98,51,14,32,28,90,56,32,30,49,26,4,16,79,32,21,73,16,79,116,35,34,13,48,29,103,93,60,66,106,61,39,2,2,2,3,2,2,25,66,43,37,57,32,31,22,18,50,78,44,58,145,40,23,36,56,96,110,25,80,9,2,2,2,3,2,2,112,61,31,44,82,68,129,4,27,37,12,48,51,43,34,35,57,75,98,17,53,5,2,2,2,3,2,2,19,213,34,143,18,51,24,174,119,49,208,5,2,2,2,3,2,2,10,39,36,50,45,66,70,88,32,35,52,6,9,6,15,40,64,31,61,38,29,56,55,92,44,11,8,13,9,2,2,2,3,2,2,7,25,72,46,98,40,15,33,28,90,56,32,30,60,79,33,81,23,17,40,56,55,12,36,3,35,64,53,27,24,63,22,173,50,15,66,12,20,20,31,6,9,2,2,2,3,2,110,21,30,117,56,105,113,33,9,32,2,4,128,8,34,91,27,19,16,22,32,3,4,31,55,26,46,18,2,2,2,3,2,17,42,16,31,28,46,34,56,31,97,41,94,36,17,6,29,24,76,18,51,78,48,27,40,21,40,31,6,7,2,2,2,3,2,37,48,33,101,29,21,73,40,126,15,18,5,44,94,28,10,14,58,101,40,148,31,2,2,2,3,2,10,24,14,60,42,32,120,32,60,80,24,13,28,59,44,76,13,5,37,19,71,19,124,27,81,2,2,2,3,2,18,14,70,99,74,177,83,46,64,39,104,38,75,62,26,49,12,2,2,2,2,2,2,21,42,90,17,54,134,48,33,74,47,30,110,43,52,46,112,53,41,31,41,27,5,2,2,2,3,2,53,188,50,45,70,33,69,8,70,79,57,27,59,45,79,28,84,7,2,2,2,2,2,2,25,37,26,47,174,32,137,23,20,44,9,5,8,9,10,8,53,8,26,37,31,65,19,29,30,39,19,19,13,70,18,47,16,116,123,12,111,31,110,27,12,9,2,2,2,2,8,9,37,21,39,33,20,30,19,72,138,155,12,5,49,23,65,135,103,56,25,7,2,2,2,2,29,47,34,24,15,27,43,27,31,44,42,52,45,51,24,84,100,41,9,15,31,51,57,86,20,12,12,5,2,2,2,2,11,56,50,17,24,25,28,109,3,38,43,9,53,11,84,17,153,34,34,35,52,28,13,8,34,30,2,2,2,2,34,78,59,30,39,42,38,11,25,147,101,56,12,23,47,14,25,39,80,22,65,53,26,58,14,47,114,130,67,25,97,5,2,2,2,2,27,69,84,14,24,64,50,50,31,64,45,70,4,62,53,114,69,45,50,53,160,2,2,2,2,33,126,32,36,91,43,81,31,17,11,3,43,13,17,31,64,25,18,18,55,28,73,36,18,112,48,2,2,2,2,24,38,22,20,22,57,71,78,91,65,82,38,32,65,13,21,41,42,113,49,50,36,24,47,7,2,2,2,2,9,28,96,40,25,14,24,30,30,70,61,36,59,30,17,20,71,30,63,41,13,38,70,46,14,23,22,12,15,30,22,39,5,2,2,2,2,107,157,117,32,97,66,10,51,52,16,82,94,44,49,12,40,41,16,2,2,2,2,52,100,89,23,9,21,107,21,17,8,26,26,9,13,4,23,55,26,47,129,23,18,36,52,57,21,19,41,28,5,2,2,2,2,28,96,134,41,42,31,50,61,58,26,56,9,2,2,2,2,19,10,71,20,100,12,12,36,49,41,16,110,25,11,11,16,25,15,10,44,17,16,12,63,21,14,2,2,2,2,2,2,9,35,19,14,77,64,43,88,75,52,46,52,17,22,22,50,80,30,7,83,115,20,35,7,2,2,2,2,33,103,37,48,120,34,77,41,24,14,4,25,23,30,74,129,78,26,30,23,4,10,20,22,5,2,2,2,2,23,22,58,12,28,33,26,19,62,50,45,21,35,50,35,15,9,6,29,123,92,5,19,14,12,57,4,46,53,2,2,2,2,8,18,36,7,67,35,10,11,26,66,27,50,29,27,19,94,24,22,21,35,144,33,44,34,29,42,56,57,31,9,7,2,2,2,2,26,140,14,73,103,27,57,42,10,45,50,7,4,45,41,21,41,50,17,41,26,99,47,69,92,7,2,2,2,2,57,37,100,102,6,21,6,14,60,20,57,11,37,39,75,15,47,41,59,119,38,98,68,2,2,2,2,50,59,75,35,61,68,44,143,47,14,81,77,40,10,10,31,56,24,40,37,29,12,2,2,2,2,53,50,58,26,61,25,45,66,142,12,4,24,43,25,40,61,68,31,135,52,73,14,2,2,2,2,81,16,53,109,100,30,51,47,19,42,19,127,78,28,44,22,23,55,39,42,52,63,18,2,2,2,2,52,117,62,119,14,121,45,30,7,52,108,98,35,47,73,107,25,23,103,89,71,64,64,54,34,4,44,59,41,17,74,58,103,40,102,9,2,2,2,2,2,2,2,129,42,61,144,102,83,59,28,46,158,54,46,18,11,13,22,62,31,2,2,2,2,2,40,58,34,55,89,58,101,92,31,48,35,157,70,17,80,35,18,53,2,2,2,2,2,13,22,24,35,78,40,18,50,64,98,50,28,26,51,109,166,43,26,10,109,2,2,2,2,2,2,2,6,11,2,9,2,9,29,46,10,39,98,39,46,20,47,23,26,12,62,4,16,19,50,43,31,31,38,42,39,49,29,30,53,68,3,61,7,2,2,2,2,2,67,40,26,70,23,85,57,32,109,42,15,15,7,4,20,56,115,9,18,19,65,46,9,2,2,2,2,2,52,21,89,96,61,43,37,20,32,54,35,22,14,10,17,13,2,2,2,2,2,2,2,11,60,48,72,55,68,138,51,48,130,71,66,82,17,41,20,15,27,51,13,9,2,2,2,2,2,2,2,22,112,67,109,84,48,65,19,10,92,103,151,36,151,24,32,14,5,2,2,2,2,2,2,2,42,89,31,39,94,61,130,46,118,6,139,67,128,2,5,19,58,60,7,2,2,2,2,2,2,2,51,14,41,25,76,57,58,81,192,16,36,50,52,60,32,30,155,64,53,56,2,2,2,2,2,2,2,158,69,50,109,98,136,91,9,37,42,64,79,17,43,2,2,2,2,2,2,2,33,121,13,20,132,41,63,76,96,40,115,56,80,18,43,56,31,2,2,2,2,2,2,2,7,138,86,59,63,43,91,2,2,2,2,2,2,2,20,113,24,47,109,95,13,74,30,74,78,42,48,86,27,49,53,75,7,24,10,2,2,2,2,2,2,2,63,12,26,40,33,50,26,26,35,47,45,186,43,52,18,87,18,47,25,24,21,119,119,7,2,2,2,2,2,2,2,42,2,13,2,26,59,58,45,21,78,71,13,6,12,12,52,38,12,25,96,67,51,79,15,43,52,8,2,2,2,2,2,2,2,33,51,43,16,11,99,74,64,11,21,50,17,12,17,22,12,62,31,19,108,18,14,2,8,2,23,112,30,10,2,2,2,2,2,2,2,19,124,45,51,62,34,29,78,37,48,8,41,56,37,45,51,34,55,41,17,36,48,23,54,115,13,74,18,9,35,9,36,63,30,36,24,57,42,28,37,29,5,2,2,2,2,2,2,2,55,26,28,8,63,36,33,45,35,27,50,68,37,7,5,45,59,18,76,69,24,22,36,45,41,5,2,2,2,2,2,2,2,4,45,40,75,32,33,35,6,44,7,46,121,35,17,37,11,103,45,26,22,53,58,34,42,133,12,12,43,14,39,13,11,11,7,72,89,48,31,2,2,2,2,2,2,2,8,61,33,18,8,57,11,52,19,11,54,17,39,46,83,2,105,52,58,135,27,11,2,2,2,2,2,2,2,37,49,37,43,10,7,38,70,75,57,51,18,83,67,41,35,32,26,34,38,16,37,50,50,48,22,40,72,38,102,53,51,22,26,80,5,2,2,2,2,2,2,2,9,76,50,75,51,75,64,114,2,44,39,52,63,86,39,38,7,2,2,2,2,2,2,2,8,27,66,88,81,18,14,71,60,58,61,28,24,30,17,14,36,5,64,50,8,23,13,62,34,123,49,59,23,12,21,18,10,5,2,2,2,2,2,2,2,59,26,8,56,38,37,84,60,47,61,29,7,95,65,52,36,42,5,33,58,38,34,2,2,2,2,2,2,2,16,44,78,15,19,14,78,21,59,26,15,49,40,34,9,62,17,17,114,53,75,89,147,17,112,163,33,108,15,62,57,7,2,2,2,2,2,2,2,6,58,37,21,44,75,32,92,71,22,70,5,114,39,14,67,37,43,43,147,36,4,2,2,2,2,2,2,2,163,174,91,64,33,19,4,107,94,7,22,74,183,27,10,2,2,2,2,2,2,2,42,13,53,13,52,37,112,25,69,37,34,41,81,45,43,90,25,26,58,106,17,14,2,2,2,2,2,2,2,37,96,119,64,20,80,19,32,72,30,81,136,49,31,36,50,35,125,14,2,2,2,2,2,2,2,6,43,148,30,104,31,46,34,136,21,60,14,55,61,62,35,9,59,13,36,49,11,2,2,2,2,2,2,2,22,67,55,72,72,5,62,41,32,42,31,66,21,19,20,40,14,22,11,62,17,67,18,32,42,62,31,20,2,2,2,2,2,2,2,26,19,37,52,21,5,31,35,40,42,33,30,80,40,40,9,22,16,6,8,28,68,7,34,61,52,43,52,92,40,5,2,2,2,2,2,2,2,53,39,45,29,65,33,20,35,34,34,69,103,10,31,60,33,33,56,161,57,17,40,60,2,2,2,2,2,2,2,5,33,110,84,19,46,66,34,81,15,12,41,100,39,25,9,64,31,54,135,58,2,2,2,2,2,2,2,42,54,15,35,111,39,55,44,56,72,27,11,94,24,15,13,62,36,49,44,59,53,50,22,28,39,2,2,2,2,2,2,2,71,51,49,23,83,27,68,37,69,56,44,4,59,86,53,8,18,33,25,27,7,47,37,132,46,14,2,2,2,2,2,2,2,23,120,70,41,7,139,30,89,61,16,14,81,55,13,26,36,10,76,39,2,2,2,2,2,2,2,29,102,46,35,53,136,28,42,28,20,60,42,60,69,72,50,20,25,42,86,40,82,7,2,2,2,2,2,2,2,18,27,163,46,98,102,10,10,19,58,53,77,62,66,25,52,61,13,2,2,2,2,2,2,2,31,37,87,30,52,91,18,31,60,48,34,31,19,58,15,18,296,14,23,81,61,21,7,2,2,2,2,2,2,2,26,79,2,17,26,21,21,85,55,30,46,75,13,30,9,39,24,19,157,33,40,148,74,21,36,2,2,2,2,2,2,2,69,35,31,41,59,111,25,77,19,90,55,42,139,38,79,114,2,2,2,2,2,2,2,21,43,21,143,2,20,24,28,65,73,28,4,42,38,113,61,49,4,20,40,16,127,51,14,2,2,2,2,2,2,2,20,85,41,38,50,75,169,38,28,38,22,16,48,51,31,31,69,46,23,19,16,81,37,34,16,8,2,2,2,2,2,2,2,35,68,28,79,46,24,80,35,71,44,21,39,11,6,10,57,64,114,98,41,18,33,65,11,32,14,2,2,2,2,2,2,2,17,163,65,21,70,20,60,29,25,75,93,34,56,82,70,50,118,7,38,2,2,2,2,2,2,2,8,18,14,30,96,61,43,25,18,46,44,41,44,36,7,11,17,193,129,74,100,37,2,2,2,2,2,2,2,24,77,29,63,47,52,63,31,23,66,12,44,18,17,34,16,32,34,17,8,21,51,20,34,58,17,22,189,5,2,2,2,2,2,2,2,44,49,64,22,120,46,180,5,29,19,4,70,65,14,14,8,119,75,78,39,61,14,2,2,2,2,2,2,2,39,52,45,54,64,28,30,18,29,100,32,13,14,142,77,71,275,2,2,2,2,2,2,2,32,136,64,68,18,154,55,15,30,44,58,60,42,84,10,47,121,17,2,2,2,2,2,2,2,85,27,43,86,78,44,16,51,34,51,42,30,47,56,87,50,5,2,2,2,2,2,2,2,70,24,44,15,35,74,74,85,36,97,16,54,148,78,51,11,15,51,42,47,2,2,2,2,2,2,2,13,19,73,66,30,46,144,91,46,5,26,55,28,101,16,38,21,39,55,28,75,7,23,2,2,2,2,2,2,2,65,61,49,61,37,176,16,48,34,13,70,58,39,54,40,76,46,45,159,8,2,2,2,2,2,2,2,135,38,87,66,45,17,100,73,8,67,92,41,114,21,156,11,2,2,2,2,2,2,2,96,24,20,18,38,11,20,39,110,26,47,19,108,4,3,43,69,122,12,8,42,51,91,98,53,2,2,2,2,2,2,2,72,76,37,37,30,99,68,47,24,30,54,23,23,48,17,93,21,16,50,45,47,29,94,2,2,2,2,2,2,2,10,57,44,78,56,49,49,22,42,48,28,55,30,126,32,28,27,15,34,43,11,25,43,33,28,34,46,60,2,2,2,2,2,2,2,15,49,24,63,36,42,68,25,52,40,17,26,23,58,30,63,26,20,10,24,16,13,44,3,69,45,12,17,50,27,53,43,37,20,7,2,2,2,2,2,2,2,8,54,26,50,11,28,84,36,29,105,42,23,62,175,17,36,90,52,74,59,5,2,2,2,2,2,2,2,105,26,20,18,26,43,56,49,63,44,60,29,21,83,42,28,79,33,74,10,46,57,41,57,28,5,2,2,2,2,2,2,2,12,6,63,30,30,69,81,30,23,41,63,63,22,73,55,48,34,14,23,82,151,52,57,2,2,2,2,2,2,2,21,41,60,34,33,31,26,41,69,45,29,53,41,104,19,81,39,39,35,30,22,71,35,43,6,24,2,2,2,2,2,2,2,105,31,97,35,78,31,35,47,14,23,20,11,254,79,23,13,151,2,2,2,2,2,2,2,89,86,11,32,28,17,20,96,50,44,33,34,109,119,21,29,36,91,10,15,24,36,2,2,2,2,2,2,2,21,36,24,106,112,81,58,61,19,9,44,54,173,37,115,70,39,19,2,2,2,2,2,2,2,27,56,101,49,61,43,13,10,16,18,47,52,53,21,45,88,108,83,15,34,46,23,2,2,2,2,2,2,2,33,30,48,39,38,70,50,26,15,87,97,4,32,17,31,44,48,92,59,87,44,27,31,44,15,2,2,2,2,2,2,2,7,107,92,70,38,78,39,47,37,35,24,54,62,34,49,59,17,83,17,169,2,2,2,2,2,2,2,27,48,50,92,49,165,27,31,53,4,115,38,67,19,9,23,26,142,36,47,93,52,56,70,46,99,128,103,12,28,12,2,2,2,2,2,2,2,6,37,38,39,18,112,30,54,101,12,72,27,21,27,147,75,40,13,26,61,48,45,2,2,2,2,2,2,2,12,66,14,37,9,67,65,131,50,43,71,29,25,67,32,43,38,37,96,34,26,7,2,2,2,2,2,2,2,5,48,65,51,52,126,33,46,52,80,36,146,41,112,17,102,17,29,16,40,6,7,2,2,2,2,2,2,2,14,58,22,49,50,64,83,16,66,17,29,39,68,83,28,203,60,45,10,7,2,2,2,2,2,2,2,19,56,13,27,120,37,114,61,27,28,34,36,93,72,235,21,2,2,2,2,2,2,2,86,37,35,43,33,10,16,37,22,36,54,15,13,70,4,41,113,41,32,16,73,41,67,38,2,2,2,2,2,2,2,230,80,83,94,16,91,23,60,24,90,22,27,72,94,2,2,2,2,2,2,2,43,31,52,92,86,7,81,90,44,6,122,93,54,36,68,56,39,51,39,2,2,2,2,2,2,2,38,108,170,130,32,26,25,68,36,17,90,29,133,8,145,33,2,2,2,2,2,2,2,59,83,55,62,52,47,42,62,49,38,105,49,123,117,17,20,48,22,39,11,2,2,2,2,2,2,2,84,87,37,65,52,155,16,28,45,12,6,36,18,28,84,242,15,38,57,2,2,2,2,2,2,2,39,58,64,47,53,37,50,14,10,109,21,18,68,20,63,150,85,39,50,60,32,18,11,5,2,2,2,2,2,2,2,54,78,62,40,118,75,88,31,8,35,68,125,67,42,3,23,29,21,6,43,78,2,2,2,2,2,2,2,43,36,11,70,28,19,48,89,40,48,76,20,10,16,33,52,24,95,29,61,53,23,17,15,4,126,28,5,2,2,2,2,2,2,2,19,69,33,15,34,116,63,172,23,87,32,142,120,19,64,35,13,2,2,2,2,2,2,2,94,22,125,152,72,145,71,98,80,29,163,26,9,98,51,60,73,21,23,37,27,48,78,59,69,13,103,47,12,78,11,2,3,69,13,18,32,53,51,34,65,59,85,90,31,37,16,30,14,35,38,28,20,32,29,84,33,25,12,2,3,19,43,10,9,52,84,189,50,14,47,39,9,51,25,37,103,51,40,37,40,22,86,26,16,5,2,2,2,56,31,68,23,23,34,42,31,35,38,33,49,32,32,94,43,118,52,36,108,142,45,7,2,2,2,51,74,108,41,14,19,20,65,26,85,26,49,31,8,198,12,106,2,29,20,109,3,9,3,26,21,9,2,3,20,35,39,15,76,25,35,64,44,30,127,34,70,131,28,96,41,8,42,28,55,15,11,13,17,17,2,3,7,42,42,44,56,16,2,3,15,34,28,53,68,15,74,66,26,34,2,21,17,11,34,39,82,62,53,68,52,54,2,2,2,60,19,27,47,62,30,21,111,24,38,43,23,45,34,10,49,60,16,34,34,54,21,58,37,74,2,3,18,22,38,45,42,82,91,103,32,102,68,15,27,31,35,22,64,71,12,41,21,46,11,33,26,16,5,2,3,29,55,23,73,17,29,30,23,13,36,65,71,105,63,53,51,24,17,37,48,60,53,27,41,16,28,46,23,2,3,48,78,150,47,77,84,52,31,51,31,17,45,61,33,100,65,31,59,2,2,2,8,77,95,39,56,54,51,96,21,21,68,58,75,97,32,82,45,38,86,47,25,2,2,2,75,13,32,33,27,48,89,94,78,16,15,31,18,40,45,65,49,27,53,111,45,25,5,30,24,2,3,43,132,27,22,16,17,45,198,21,18,75,49,25,69,53,108,68,40,44,2,2,2,7,19,45,82,31,9,24,27,26,61,109,25,67,66,69,74,125,47,39,24,126,2,3,32,82,23,53,68,39,23,50,40,14,79,54,157,98,68,50,13,23,30,2,2,2,26,58,95,61,32,62,33,65,61,82,79,67,27,44,68,88,47,22,27,2,2,2,16,38,55,33,41,39,47,32,74,32,6,54,82,10,38,12,13,12,21,6,62,35,30,52,116,24,79,29,72,28,2,3,39,149,127,35,17,59,28,48,28,26,10,61,41,15,58,22,30,25,30,73,36,31,39,35,7,2,3,68,71,114,88,51,73,115,129,44,46,19,35,80,50,22,91,12,5,2,2,2,31,56,74,43,69,47,49,17,24,23,29,65,34,73,25,43,16,33,144,19,30,94,42,88,12,5,2,2,2,21,44,40,22,183,47,67,93,32,17,22,26,42,56,86,13,55,16,29,46,83,60,50,22,14,22,25,24,33,25,16,34,34,56,21,55,21,53,45,39,73,19,52,7,25,15,5,2,2,2,97,114,59,42,9,122,36,26,31,52,41,67,31,95,53,8,79,74,66,16,2,2,2,27,190,58,6,46,28,71,80,27,24,5,3,5,2,5,7,90,33,7,40,21,32,38,46,41,42,32,19,12,2,2,2,35,63,118,54,93,4,19,87,24,50,92,33,9,22,32,90,104,56,79,7,2,2,2,82,60,42,80,35,24,19,65,40,36,137,25,101,80,12,35,24,31,88,41,34,2,2,2,119,53,58,60,14,79,94,54,32,17,109,26,22,70,74,92,115,2,2,2,75,68,191,92,77,79,23,143,104,88,26,9,19,24,9,2,2,2,43,22,28,20,19,13,46,13,30,16,54,23,32,30,61,51,17,16,58,33,22,22,19,22,26,24,5,17,35,68,142,37,12,5,56,14,5,2,2,2,19,85,41,45,103,51,34,88,58,40,11,35,77,123,42,40,54,45,24,63,37,25,30,7,2,2,2,15,38,65,43,23,8,20,52,29,98,23,53,33,19,40,20,66,73,30,21,15,2,66,121,56,63,47,71,152,54,27,28,83,81,18,51,24,99,41,11,2,26,41,127,11,45,68,28,71,38,42,48,42,29,38,28,63,33,23,24,62,43,20,29,46,18,2,144,29,44,18,27,67,39,56,45,47,92,156,23,17,5,7,2,6,22,43,111,65,2,34,52,69,112,39,122,13,2,15,2,26,52,9,6,7,3,10,15,37,31,14,3,2,4,2,4,2,4,83,21,28,26,34,37,38,33,109,13,2,100,20,79,40,49,93,86,46,45,65,35,29,76,38,51,52,90,32,30,37,23,2,24,18,38,61,38,12,34,2,29,18,148,5,19,21,47,26,33,20,14,2,25,42,40,2,33,8,87,32,96,32,20,11,43,7,31,10,6,2,29,10,4,2,41,34,31,4,2,45,39,2,1,89,2,7,57,25,175,15,86,214,1,198,61,99,5,7,161,43,44,34,105,3,3,30,69,29,38,50,32,8,6,11,9,16,6,20,30,181,41,63,18,80,19,35,30,19,13,11,8,29,24,11,17,4,19,19,20,52,70,22,54,15,3,7,4,15,16,13,17,27,55,34,98,73,34,38,25,172,23,28,35,8,14,40,157,16,39,17,65,41,121,88,11,37,28,31,82,58,38,40,81,20,20,6,46,51,44,45,104,23,25,105,9,74,38,6,33,16,47,28,13,40,4,23,48,47,13,55,44,16,6,29,33,6,26,53,57,4,22,36,68,22,35,35,71,6,61,38,40,6,62,51,48,25,25,25,59,41,50,107,62,55,16,180,67,17,69,26,77,55,27,47,13,57,44,37,21,38,32,77,92,59,54,29,17,37,40,22,9,58,45,75,7,104,122,31,71,82,84,70,117,87,40,4,68,29,73,6,80,97,27,25,22,27,66,18,34,29,83,38,47,44,56,37,20,93,87,67,26,6,79,64,67,44,6,52,40,46,30,35,24,9,98,103,13,68,74,33,5,40,21,12,28,68,37,29,7,19,9,65,5,25,42,64,32,30,22,11,31,6,47,81,56,44,14,5,70,38,22,61,22,50,47,58,13,19,38,11,34,45,32,46,17,6,9,7,55,120,11,88,8,107,52,25,10,22,42,30,7,21,26,27,40,38,69,5,31,45,48,26,4,16,67,48,54,33,14,44,29,8,47,27,67,72,19,59,28,35,83,28,38,10,15,4,10,13,24,15,35,28,39,67,30,92,42,24,79,79,37,57,15,95,33,73,16,67,66,38,59,4,30,24,34,95,106,50,41,3,47,65,75,42,88,77,85,32,44,23,86,41,79,86,42,112,41,27,70,22,38,28,74,36,85,46,4,39,28,62,49,46,26,33,27,25,9,29,4,26,16,18,37,8,49,39,18,37,16,36,35,45,53,37,42,34,33,52,5,11,58,8,24,24,15,28,54,38,27,15,19,18,11,18,26,55,28,37,36,61,20,29,40,67,3,32,35,5,35,11,3,69,56,42,22,21,47,7,97,40,64,113,44,47,54,43,16,34,61,10,59,70,25,32,70,26,8,17,59,59,13,14,6,23,23,37,46,43,15,15,11,21,39,50,67,18,102,47,33,50,37,8,60,26,65,47,47,57,8,42,25,27,28,8,22,48,31,40,13,19,72,71,21,5,15,15,12,8,58,83,6,6,27,74,7,23,53,60,34,5,50,5,49,32,50,31,51,6,34,41,33,6,15,8,26,5,34,49,30,61,44,43,53,29,29,25,40,41,3,13,29,42,3,12,25,29,31,103,26,7,55,23,35,5,66,23,75,4,23,5,32,28,13,4,10,10,26,37,15,20,16,30,4,11,49,6,46,50,48,28,9,52,52,9,20,66,76,32,20,52,56,5,10,26,5,14,30,7,10,31,3,46,27,58,83,103,55,5,28,4,7,40,5,81,18,27,32,3,39,8,123,11,22,8,73,20,41,25,14,23,9,52,94,62,44,7,44,70,56,5,28,79,32,28,10,28,22,66,58,81,51,125,72,42,5,19,66,21,32,16,58,74,24,40,40,33,30,67,46,41,13,9,38,31,63,43,40,25,37,23,30,51,31,40,30,62,69,38,47,53,4,20,26,16,60,22,27,51,35,68,19,77,21,17,8,27,18,7,51,32,25,39,45,7,39,24,17,11,37,29,39,32,57,25,79,33,28,3,63,42,18,24,21,48,14,71,26,25,80,15,39,5,54,50,50,34,52,61,43,42,73,25,44,60,42,104,48,16,69,47,30,63,21,36,40,45,17,15,66,17,35,114,63,76,59,87,5,78,28,93,41,47,75,38,5,98,119,57,72,8,46,94,73,106,102,25,49,85,79,45,62,39,9,32,12,48,57,60,28,65,117,14,36,61,40,52,21,34,31,43,24,51,24,18,46,36,50,34,40,61,19,34,82,37,78,62,27,49,92,11,8,100,26,21,9,52,132,13,6,30,34,18,57,20,68,72,6,30,46,40,5,82,61,7,33,38,48,5,23,5,31,5,5,46,23,4,27,51,12,4,29,50,18,31,6,15,84,13,28,5,97,8,45,37,50,30,5,55,12,5,39,4,26,10,43,104,62,4,126,47,74,39,19,45,55,13,10,39,98,16,43,45,95,49,56,56,30,90,44,58,87,15,48,70,64,90,48,51,33,96,49,90,77,72,68,37,17,7,58,54,99,56,27,20,70,91,46,36,34,23,91,6,48,49,37,43,35,28,69,50,61,53,41,27,32,42,125,33,20,54,44,61,34,74,21,61,38,70,71,40,30,84,66,26,29,48,57,57,24,69,23,35,60,116,102,243,56,28,66,41,42,33,27,61,37,131,85,53,16,58,96,41,49,94,5,51,64,94,22,7,42,41,11,62,89,12,22,5,11,43,77,44,5,37,12,18,29,58,9,124,40,15,5,28,12,16,56,76,13,5,51,74,45,26,4,49,26,18,25,9,38,25,16,5,28,40,35,39,93,18,17,5,16,46,46,7,33,62,38,51,4,46,60,50,42,26,73,39,74,30,31,10,30,28,42,85,42,9,91,77,42,57,29,22,18,7,27,31,18,17,35,51,26,5,9,14,96,41,160,39,13,28,38,11,56,65,63,38,81,58,48,90,73,38,175,5,61,17,4,75,36,37,8,81,11,36,43,52,6,108,14,75,50,82,52,22,17,16,9,37,37,34,64,51,25,18,18,45,102,52,3,17,17,43,6,85,5,31,65,70,6,19,8,74,32,7,116,19,21,5,57,29,49,3,18,5,30,10,12,16,5,21,27,9,39,28,5,20,5,14,6,32,8,103,42,18,5,46,52,26,29,33,16,7,57,32,39,8,84,16,31,5,50,27,10,24,71,33,16,10,7,32,26,46,33,5,33,52,27,7,65,7,40,74,26,32,61,9,42,55,20,8,56,4,33,33,35,51,7,58,92,62,87,5,74,4,38,15,19,13,26,31,41,41,39,20,9,25,10,35,19,22,113,24,16,5,8,31,98,11,5,44,101,3,80,29,69,30,51,48,5,71,26,22,41,40,55,103,25,7,62,76,9,57,32,20,9,61,27,51,100,11,23,44,35,44,12,16,69,48,37,53,33,21,30,29,16,44,31,8,76,6,67,71,22,6,68,39,45,42,17,91,45,47,53,34,123,66,106,6,164,82,63,49,66,134,34,160,108,92,18,48,58,40,47,11,6,39,30,82,44,34,53,13,50,30,31,37,51,46,14,15,14,38,59,35,81,41,39,47,29,26,25,43,7,46,47,75,33,24,33,39,39,35,89,44,33,11,11,55,77,41,37,34,40,54,23,53,16,85,26,26,28,69,9,15,55,28,87,6,49,25,13,13,35,8,89,53,48,16,25,11,49,6,104,43,9,20,57,26,17,37,52,18,28,39,46,28,9,14,47,20,28,96,51,58,49,31,57,8,41,37,89,73,35,73,19,5,125,16,74,83,50,66,38,9,98,52,57,6,70,11,27,83,7,18,29,39,13,31,20,31,5,17,44,24,4,41,74,58,39,63,7,53,280,7,76,56,85,41,9,64,21,36,45,44,16,6,59,62,22,10,43,31,54,24,31,13,50,58,17,30,24,3,48,69,25,11,22,37,33,51,23,39,20,46,67,34,5,23,40,51,57,45,100,16,5,16,43,31,32,29,55,89,28,7,56,40,54,13,32,5,16,16,11,26,30,21,59,8,42,32,25,32,45,62,6,48,51,5,12,182,45,32,97,30,8,11,35,52,33,11,26,31,30,19,80,34,44,24,20,27,61,67,34,29,14,44,11,16,33,8,12,23,33,38,37,21,20,10,15,40,18,30,31,46,42,39,61,107,15,11,37,45,89,54,17,16,27,26,40,4,19,46,8,73,56,48,43,5,41,30,43,37,40,41,7,46,54,67,19,25,5,35,68,34,20,129,34,9,97,5,30,35,21,6,59,73,30,7,16,46,47,7,27,29,116,81,22,68,47,43,14,19,6,62,71,29,10,59,14,62,51,36,20,6,64,127,22,33,45,36,7,22,97,35,49,5,36,19,90,20,6,60,59,45,25,7,38,68,11,32,12,8,31,61,7,44,37,38,4,25,91,25,41,94,35,22,35,17,44,52,61,6,11,59,5,60,32,13,18,33,55,12,45,28,22,40,4,47,69,4,36,35,5,67,4,57,6,94,37,19,49,14,21,40,73,49,3,19,14,35,47,28,26,36,18,26,27,41,38,36,30,38,22,46,84,19,16,12,29,3,28,4,36,5,18,28,2,28,6,25,17,58,5,31,6,23,5,23,5,23,13,33,6,31,30,9,22,3,18,4,22,8,20,11,5,46,53,3,27,5,22,5,19,26,5,26,3,43,4,23,24,3,52,6,22,10,21,6,29,5,27,3,36,6,27,3,24,4,40,26,5,30,6,28,8,30,10,31,31,6,16,17,30,7,50,33,4,63,8,50,54,63,8,68,8,95,4,27,14,21,4,53,10,17,81,5,5,4,101,5,72,24,17,34,5,45,64,23,57,16,18,27,22,35,80,71,5,4,63,4,44,24,7,71,9,41,8,10,14,59,6,33,52,7,38,12,6,17,27,35,5,18,29,37,21,4,63,36,52,30,6,60,29,90,25,39,7,14,24,46,10,51,27,25,6,38,49,64,5,21,42,64,8,34,74,54,60,75,23,39,51,4,74,28,71,13,33,36,33,3,59,40,14,31,53,60,83,44,51,52,15,17,26,62,41,90,89,24,35,35,41,14,7,10,36,5,22,6,30,5,40,4,15,5,12,25,5,18,6,16,16,4,23,7,26,4,24,3,19,5,30,3,18,6,14,7,14,6,35,22,5,20,7,32,26,26,14,3,15,5,43,4,25,5,18,30,7,17,9,40,52,3,21,46,35,22,50,16,49,19,17,19,23,4,52,41,5,21,23,28,18,46,16,95,8,28,23,34,26,37,44,5,94,3,36,31,46,46,42,22,15,26,16,7,84,80,6,54,54,6,78,23,5,73,6,41,49,50,38,5,57,34,4,32,26,54,14,49,29,10,102,68,61,68,34,42,46,44,83,35,25,7,29,5,47,63,15,32,16,43,36,25,5,29,74,20,4,46,46,54,4,41,44,5,29,3,38,95,3,73,31,5,53,71,28,4,58,66,21,44,9,27,13,6,68,44,40,63,100,64,74,100,15,40,5,55,56,83,5,45,62,3,61,50,26,4,77,70,30,5,33,46,17,3,17,39,36,34,10,66,15,66,51,34,49,6,30,7,26,34,42,37,45,29,67,37,13,7,106,8,65,55,53,70,29,25,13,13,6,32,36,30,33,5,49,53,40,31,7,15,51,32,72,23,53,10,34,24,19,36,6,19,80,47,34,29,30,23,5,106,58,7,105,56,5,36,29,37,67,41,8,16,36,26,28,31,38,13,23,21,43,33,16,35,4,77,9,42,53,115,38,68,6,28,13,8,57,3,34,5,34,5,22,7,52,5,38,18,77,42,6,61,86,81,62,42,20,14,73,37,78,68,75,73,139,95,56,35,33,34,50,53,56,50,60,49,46,41,77,42,28,33,65,41,8,29,59,66,106,70,37,43,11,26,37,14,62,83,9,87,94,107,105,46,26,32,74,102,43,8,60,103,4,30,132,15,31,64,73,8,9,22,21,14,40,50,11,43,53,86,56,14,8,42,93,59,42,8,132,49,145,85,8,18,5,31,5,29,25,58,5,41,5,17,26,6,50,3,35,29,5,25,9,5,37,5,22,11,37,5,14,26,5,25,3,17,39,5,22,10,32,5,5,12,7,16,3,22,5,24,6,26,24,20,7,61,5,35,7,17,44,11,19,14,8,38,4,21,4,18,3,16,19,24,5,19,22,6,27,12,31,4,32,28,22,5,34,7,20,4,28,5,38,5,56,7,17,5,41,27,4,16,6,25,8,37,4,5,30,7,15,16,21,22,3,25,6,36,5,19,6,24,6,19,7,20,9,29,17,4,46,12,6,36,3,16,5,25,6,38,6,22,6,6,13,3,20,7,6,41,7,41,4,17,19,17,17,5,27,6,37,5,30,4,18,4,17,43,25,9,17,23,35,3,22,3,14,6,21,5,44,6,25,24,24,4,28,16,9,6,48,4,20,32,3,31,9,30,24,5,17,11,53,6,57,13,4,12,16,26,55,14,7,27,36,23,7,52,38,35,51,57,27,14,34,28,67,12,5,25,73,52,20,91,4,77,5,59,131,7,36,16,26,32,5,28,35,20,28,35,73,38,35,6,83,56,5,47,28,5,46,6,6,25,15,19,19,23,46,69,6,22,14,28,13,63,70,53,38,12,38,5,19,15,42,6,88,5,27,26,4,54,39,66,5,68,95,30,7,85,50,25,36,6,80,62,52,5,42,50,6,38,50,10,22,89,5,50,8,49,28,7,33,23,3,50,5,93,36,38,11,44,29,12,49,39,8,39,26,36,32,59,4,43,59,27,4,33,30,22,26,19,28,62,11,143,5,66,70,47,55,27,76,10,33,34,30,27,25,14,35,19,28,40,21,57,24,82,26,19,34,17,20,23,54,48,74,8,88,78,26,76,72,171,23,30,64,89,61,39,26,74,68,30,67,77,34,30,45,44,41,40,40,32,43,46,86,39,23,49,35,40,34,37,47,4,39,56,77,22,61,128,56,34,40,14,1,1,55,86,121,129,135,10,6,42,40,46,90,80,63,56,38,14,24,29,32,9,38,134,6,2,31,14,47,40,67,75,118,15,26,8,13,99,31,10,36,77,16,24,58,30,169,106,52,30,28,8,34,18,38,99,37,64,27,17,18,11,29,21,16,45,8,50,3,32,27,66,5,84,8,73,57,19,194,4,15,5,66,24,17,26,4,15,33,8,69,21,7,52,44,7,29,64,7,98,6,41,19,49,44,3,62,14,18,67,58,6,23,37,6,55,30,22,6,41,21,5,40,35,7,18,52,10,43,7,76,62,44,21,98,44,13,59,44,68,49,65,44,89,47,21,32,37,74,18,3,38,35,38,32,13,39,50,10,37,65,33,27,59,32,7,103,33,57,6,8,65,66,14,45,44,91,102,129,57,74,35,17,11,106,82,32,24,28,3,38,7,28,7,11,22,20,19,55,43,47,5,56,8,31,9,27,8,58,7,28,8,63,44,30,55,5,23,27,30,8,31,8,32,5,41,180,55,36,6,32,5,23,58,8,70,93,58,7,44,9,40,6,5,13,51,10,49,18,5,37,4,36,4,20,38,45,4,20,14,6,41,33,7,30,13,4,26,54,5,40,46,30,5,16,5,45,6,68,3,43,40,9,57,23,6,42,32,3,25,34,7,36,4,46,5,33,19,15,5,34,11,32,25,65,3,30,22,29,5,15,22,36,12,66,10,16,26,12,43,64,91,60,40,6,73,39,63,78,13,8,68,48,6,44,48,60,55,12,35,24,16,25,42,4,21,28,24,23,42,71,54,52,18,69,12,51,134,40,37,73,59,8,106,72,25,30,20,17,2,9,38,32,12,5,13,26,24,40,66,19,49,17,18,16,15,54,32,57,9,89,118,78,123,51,6,13,17,11,67,8,70,27,34,4,5,57,5,37,5,54,51,5,35,4,23,32,16,5,32,7,47,10,45,69,9,35,37,17,22,7,46,45,38,35,33,60,29,45,52,53,34,16,34,64,37,47,41,69,60,37,35,4,31,62,18,6,56,8,46,62,3,26,14,6,57,30,10,69,46,12,24,16,58,88,81,28,5,24,17,5,50,31,4,16,66,10,93,7,48,42,12,107,108,28,34,12,44,72,26,36,12,7,58,5,26,78,8,45,11,101,10,22,6,33,13,41,21,72,72,25,11,59,53,41,72,5,28,5,19,10,33,33,5,52,5,14,5,16,4,56,67,91,55,26,61,340,6,33,25,7,107,26,9,83,9,129,5,88,5,54,5,5,63,46,8,82,10,16,34,32,17,12,7,23,47,5,36,7,34,67,16,4,16,10,49,19,5,47,77,18,33,36,5,50,55,14,5,6,43,27,18,12,34,6,59,25,5,48,4,36,7,67,8,23,20,54,42,33,3,40,14,42,22,199,10,88,63,86,77,50,35,78,21,16,40,44,161,14,68,10,90,40,35,26,31,17,78,102,148,52,22,117,62,6,45,65,128,6,82,65,79,10,25,71,81,28,45,51,44,5,19,45,109,51,7,73,95,16,12,93,33,29,55,5,71,40,85,26,11,13,119,31,74,43,27,158,4,126,14,39,8,30,68,17,117,20,42,8,80,43,67,5,83,10,5,50,66,38,142,7,63,49,22,12,20,18,7,52,50,13,6,28,7,39,8,62,10,37,7,59,5,30,4,47,9,64,5,62,7,5,46,44,44,14,5,62,13,7,67,5,34,36,25,19,8,50,77,23,7,79,7,25,7,49,72,19,41,26,4,53,68,54,24,21,7,53,39,6,37,11,73,26,5,32,6,67,6,33,34,21,9,66,9,40,53,5,11,54,73,48,50,55,45,5,84,57,53,12,52,36,29,34,14,98,6,34,100,15,19,69,22,76,75,63,57,29,35,34,29,38,18,78,170,22,7,54,47,119,29,33,36,59,105,53,5,37,76,34,11,40,80,53,94,26,10,35,17,123,7,50,14,57,46,46,38,55,79,70,35,135,72,27,24,5,49,40,33,38,60,65,46,67,61,50,5,54,111,37,4,45,18,30,42,12,7,52,30,9,28,7,60,90,10,40,9,112,6,50,13,9,12,3,35,7,63,10,11,79,5,49,7,37,6,33,9,37,44,7,38,7,25,6,33,10,35,4,25,3,19,3,24,86,26,6,40,23,4,26,5,5,31,5,59,12,8,59,9,55,33,7,17,12,48,3,20,33,24,4,15,6,36,5,22,9,54,85,19,18,45,52,13,37,77,7,63,6,49,25,19,7,48,31,3,42,48,20,8,67,31,13,6,28,13,45,8,53,3,32,4,21,65,45,4,33,37,21,39,7,24,58,11,9,67,7,54,5,96,20,66,5,72,43,6,27,16,5,41,6,22,30,38,9,60,21,7,75,39,20,78,35,17,73,45,15,48,9,41,5,59,10,53,43,24,11,39,139,11,4,96,5,41,81,4,37,7,33,5,18,45,33,44,83,8,29,12,7,19,6,18,4,42,4,13,17,4,56,24,4,73,9,23,73,70,45,23,72,19,7,14,58,59,72,43,72,85,40,31,82,70,94,130,74,9,102,6,44,11,47,1,32,26,9,17,60,48,28,21,28,11,20,26,40,32,66,15,6,5,79,27,86,54,13,61,41,3,32,37,11,29,67,59,45,8,55,41,5,43,5,29,7,97,6,17,11,9,32,30,44,58,71,6,15,21,5,70,7,23,17,9,83,20,57,46,25,56,5,48,23,18,5,24,17,8,17,3,8,117,26,26,10,5,52,4,44,5,126,3,16,29,7,5,36,25,9,121,7,28,5,36,6,36,6,60,6,29,7,21,13,49,12,38,26,21,39,35,5,20,4,22,82,24,35,15,3,18,42,28,23,5,47,38,3,28,16,16,37,7,17,3,17,6,11,10,38,40,26,42,15,5,35,24,46,3,18,8,3,36,21,49,11,6,28,33,29,24,5,29,43,11,29,4,18,6,12,26,3,60,41,7,33,10,55,30,7,35,8,21,10,54,59,6,11,10,28,21,42,30,17,9,24,18,38,11,9,44,32,38,50,31,24,33,9,3,20,19,31,23,26,47,31,19,15,11,29,36,42,14,25,26,14,36,20,25,30,6,5,27,14,22,8,9,17,33,17,28,11,14,8,4,9,14,35,7,41,46,43,8,19,13,28,29,38,6,25,36,66,146,8,80,40,8,113,59,107,73,50,46,29,66,53,6,64,54,46,37,17,24,25,64,24,29,39,10,42,37,5,35,46,70,14,6,38,95,25,46,25,47,27,68,6,44,35,21,23,5,107,106,7,19,20,74,34,23,46,20,47,6,10,141,90,25,5,18,6,41,13,72,36,44,62,14,54,26,37,7,16,30,74,37,26,34,48,27,21,31,29,64,29,37,53,102,45,91,12,43,22,2,8,9,5,12,11,3,17,36,39,27,6,142,39,6,51,2,29,5,58,40,43,28,33,60,41,24,44,93,62,23,65,46,75,35,78,14,46,25,78,49,22,15,15,17,25,2,28,17,49,55,33,6,36,26,32,16,35,35,22,31,11,60,40,68,39,57,24,78,24,8,49,45,44,17,5,90,37,35,17,28,53,28,27,10,59,61,20,77,29,7,34,59,43,58,54,50,24,9,106,48,48,12,3,60,37,5,25,39,25,18,48,95,98,30,30,32,56,8,20,20,38,3,23,15,32,27,46,56,41,109,50,73,41,46,42,31,40,24,31,13,48,60,51,41,86,5,16,32,22,5,36,24,9,27,13,14,49,28,40,5,18,5,17,86,23,32,10,82,76,48,41,6,51,86,42,26,79,25,7,36,5,8,4,5,12,25,45,41,36,5,11,38,27,43,6,39,34,57,80,40,11,64,27,6,54,8,48,5,46,49,5,27,32,5,28,35,48,7,32,35,19,33,32,29,34,6,28,22,52,5,30,15,7,7,5,15,12,18,24,42,33,55,36,33,14,41,39,39,21,66,23,5,14,4,30,74,40,19,44,92,33,4,66,132,32,73,65,16,4,40,43,5,33,7,6,55,5,37,12,20,13,6,34,28,28,8,16,7,11,32,21,34,32,7,4,28,47,50,32,53,91,25,5,66,58,19,24,4,14,20,28,16,10,14,4,38,75,27,12,4,81,55,85,44,93,67,8,61,81,39,50,5,29,23,29,60,28,8,25,31,8,34,49,59,12,22,57,37,4,50,21,49,22,35,49,24,8,57,29,5,52,46,73,4,13,20,25,31,10,36,43,32,36,11,27,62,3,6,2,2,6,8,35,15,6,61,30,10,3,55,70,31,8,6,18,62,45,116,60,7,109,20,7,40,19,20,9,29,9,4,78,41,4,51,50,4,20,49,6,39,40,4,44,32,38,33,27,6,15,3,42,24,5,23,60,93,29,50,34,4,21,36,42,36,29,26,39,20,4,28,5,30,32,6,32,3,38,19,36,24,22,4,43,9,45,34,7,37,33,20,29,3,34,42,13,31,65,23,28,46,5,55,10,35,153,10,34,23,14,13,4,61,10,5,27,3,46,98,38,45,49,39,15,36,27,30,33,27,16,10,19,15,3,32,4,30,22,30,56,65,13,10,28,53,81,7,22,62,93,30,5,21,13,6,18,114,14,12,37,33,43,44,24,47,33,49,21,24,5,45,48,24,14,22,22,21,72,47,40,6,64,6,42,51,50,20,24,4,21,11,17,6,34,4,21,4,27,11,5,23,32,4,52,40,8,26,44,43,7,56,4,45,34,22,17,4,22,15,5,38,22,32,36,58,4,23,20,10,30,16,49,11,6,5,15,6,40,27,6,13,72,18,22,12,4,20,26,11,4,29,67,27,19,40,3,77,19,26,39,58,67,3,30,5,92,43,4,26,26,20,27,7,75,61,41,29,20,25,7,22,48,9,84,41,5,22,67,4,71,4,7,10,29,4,33,46,5,56,36,8,45,64,20,8,52,5,5,5,5,11,5,19,22,110,43,32,28,38,10,72,45,62,48,45,72,162,6,26,22,14,7,6,7,6,14,35,24,82,142,11,56,36,34,50,10,17,74,66,56,74,43,23,48,77,99,12,34,20,10,12,45,5,88,55,5,60,4,34,5,35,18,12,55,62,77,46,41,35,94,13,9,28,33,37,32,51,33,14,54,46,72,6,36,26,31,58,17,24,13,27,32,58,66,7,33,24,58,111,5,43,26,13,27,17,64,27,43,15,38,3,28,122,5,35,53,15,8,21,22,33,37,94,15,8,64,62,23,40,22,86,41,40,8,48,90,36,120,48,71,60,159,47,32,82,5,35,22,7,25,6,24,17,4,69,23,5,44,63,16,5,27,21,26,7,86,7,36,25,5,21,5,44,33,4,93,19,4,24,8,37,15,10,30,3,6,27,13,8,10,6,9,21,13,6,20,38,8,27,10,6,19,68,19,93,32,51,10,31,85,8,5,37,2,6,63,26,32,45,25,81,23,5,42,51,22,16,26,18,42,8,29,13,42,40,6,2,9,6,8,12,23,12,18,32,6,8,11,13,43,30,29,26,31,108,23,116,14,45,6,37,20,183,55,119,75,166,101,51,85,121,53,42,26,41,61,33,52,83,31,8,17,16,28,53,65,66,24,39,19,5,47,6,39,28,12,50,16,27,27,5,30,31,23,33,135,20,20,53,7,11,28,101,16,5,24,13,4,43,10,30,27,4,60,19,32,21,5,86,53,4,71,29,6,46,23,35,15,7,20,30,2,3,22,79,19,6,23,7,18,17,22,14,52,46,26,7,16,6,49,24,48,41,20,22,7,8,41,83,46,6,30,5,35,43,28,35,6,19,6,9,35,4,41,6,41,5,4,5,15,6,30,8,9,36,12,3,34,7,21,23,13,3,57,18,3,39,53,6,40,7,29,11,7,45,50,26,76,24,56,16,17,3,34,11,22,16,3,46,74,59,8,24,36,40,39,54,24,25,83,34,29,28,6,11,82,59,5,20,32,30,46,6,22,45,67,62,51,60,79,63,8,82,74,5,26,20,4,46,4,18,7,8,51,7,83,42,77,37,10,32,22,20,160,7,51,53,11,50,22,42,55,4,27,4,73,13,25,193,124,45,42,32,31,6,36,43,40,54,42,20,81,75,48,7,18,184,5,93,60,41,7,28,14,114,25,65,23,67,75,84,32,39,9,54,27,15,42,39,10,49,20,80,36,28,76,10,18,49,34,93,6,65,9,19,60,16,19,94,35,49,9,52,72,9,44,65,15,4,25,6,23,6,37,29,9,17,48,74,16,29,87,42,53,44,7,24,49,19,33,40,19,5,50,53,17,68,40,6,41,44,7,38,18,40,138,5,48,39,8,33,31,60,23,8,21,21,56,25,20,6,26,9,56,3,69,34,39,6,20,53,4,36,18,9,19,19,4,33,22,36,28,35,61,16,21,6,48,9,41,43,4,27,29,26,5,32,7,16,28,8,82,5,54,11,7,20,47,75,5,33,21,12,19,34,25,36,21,5,23,13,20,8,80,12,45,109,28,25,6,26,55,31,3,41,3,25,17,38,17,6,25,5,14,31,24,22,19,5,26,26,11,57,31,22,3,7,35,36,28,4,41,6,52,48,27,14,7,22,9,16,5,12,3,13,22,5,6,40,19,5,28,134,6,48,9,9,5,20,5,36,12,5,21,37,22,7,25,31,6,27,22,5,34,11,20,7,10,5,12,17,17,5,40,59,30,24,71,48,50,9,35,9,15,5,8,11,19,7,15,32,23,16,20,43,18,24,21,14,38,60,12,21,10,14,21,17,38,6,42,8,19,7,4,1],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of word counts within data\"},\"xaxis\":{\"title\":{\"text\":\"Word Count\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('eb6c40c3-5daa-4e7e-beb8-b99e8e978fe0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences with word length of greater than 3.0 and less than 25.0 includes 31.83% of the whole!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "which clearly is not a result we were looking forward to have, next we will clean our text, numbers and oddly nonsentences considered as one, will be eliminated."
      ],
      "metadata": {
        "id": "nHmBabYeXjqP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdpUgdWghkA8"
      },
      "source": [
        "##Section B: Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dr652Fha6cw"
      },
      "source": [
        "###Subsection 1: tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sents = [word_tokenize(sent) for sent in data[\"sentences\"]]\n",
        "data[\"tokenized_sents\"] = tokenized_sents\n",
        "data.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jq1BgfrFY1Kp",
        "outputId": "86cf1708-852e-40c8-d30e-d1d9458f70e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentences  labels author  \\\n",
              "5407   But becauseself-con\\nsciousness is,essentiall...       0    heg   \n",
              "2885   But in that case the same relation \\nwould sti...       0    heg   \n",
              "5335   The government is itself \\nnothing else but th...       0    heg   \n",
              "18942  -Because every art becomes \\ncapable of expres...       2    nei   \n",
              "9329   For they are then merely empty concepts of ob-...       1    kan   \n",
              "\n",
              "       sentence_len_by_words  \\\n",
              "5407                      22   \n",
              "2885                      71   \n",
              "5335                      20   \n",
              "18942                    107   \n",
              "9329                      67   \n",
              "\n",
              "                                         tokenized_sents  \n",
              "5407   [But, becauseself-con, sciousness, is, ,, ess...  \n",
              "2885   [But, in, that, case, the, same, relation, wou...  \n",
              "5335   [The, government, is, itself, nothing, else, b...  \n",
              "18942  [-Because, every, art, becomes, capable, of, e...  \n",
              "9329   [For, they, are, then, merely, empty, concepts...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ca23d44-4553-4f14-9047-cc15419e57bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "      <th>author</th>\n",
              "      <th>sentence_len_by_words</th>\n",
              "      <th>tokenized_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5407</th>\n",
              "      <td>But becauseself-con\\nsciousness is,essentiall...</td>\n",
              "      <td>0</td>\n",
              "      <td>heg</td>\n",
              "      <td>22</td>\n",
              "      <td>[But, becauseself-con, sciousness, is, ,, ess...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885</th>\n",
              "      <td>But in that case the same relation \\nwould sti...</td>\n",
              "      <td>0</td>\n",
              "      <td>heg</td>\n",
              "      <td>71</td>\n",
              "      <td>[But, in, that, case, the, same, relation, wou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5335</th>\n",
              "      <td>The government is itself \\nnothing else but th...</td>\n",
              "      <td>0</td>\n",
              "      <td>heg</td>\n",
              "      <td>20</td>\n",
              "      <td>[The, government, is, itself, nothing, else, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18942</th>\n",
              "      <td>-Because every art becomes \\ncapable of expres...</td>\n",
              "      <td>2</td>\n",
              "      <td>nei</td>\n",
              "      <td>107</td>\n",
              "      <td>[-Because, every, art, becomes, capable, of, e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9329</th>\n",
              "      <td>For they are then merely empty concepts of ob-...</td>\n",
              "      <td>1</td>\n",
              "      <td>kan</td>\n",
              "      <td>67</td>\n",
              "      <td>[For, they, are, then, merely, empty, concepts...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ca23d44-4553-4f14-9047-cc15419e57bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ca23d44-4553-4f14-9047-cc15419e57bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ca23d44-4553-4f14-9047-cc15419e57bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distributions.word_and_freq(data,\"tokenized_sents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHGeIN-FTzSJ",
        "outputId": "b0109b00-1ad3-4d40-cdc7-fdfb6ba1c31d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word             Frequency        % of the total  \n",
            ",                44766            5.867280402947926\n",
            "the              42530            5.574217833565101\n",
            "of               31031            4.06709507626049\n",
            ".                20465            2.682256476931808\n",
            "and              16988            2.226541560230518\n",
            "is               16958            2.222609593736115\n",
            "to               16331            2.1404314940030957\n",
            "in               16298            2.1361063308592527\n",
            "a                13119            1.7194489480023643\n",
            "it               10440            1.3683243400521903\n",
            "that             10065            1.3191747588721547\n",
            "as               9209             1.2069826482318602\n",
            "which            7064             0.9258470438820567\n",
            "this             6215             0.8145723920904562\n",
            "not              6163             0.807756983500158\n",
            "be               5876             0.770141170703704\n",
            "its              5436             0.7124723287857957\n",
            "for              5157             0.6759050403878492\n",
            ";                4946             0.6482502093772159\n",
            "with             4016             0.5263592480507276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will check again after normalising our data, actions like:\n",
        ">omitting stopwords<br/>\n",
        ">punctuations removal"
      ],
      "metadata": {
        "id": "lacB6tqCamwE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN_EHVS6iSin"
      },
      "source": [
        "###Subsection 2: normalising"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Stop_words = stopwords.words('english')\n",
        "Stop_words[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SiOG9goc-vy",
        "outputId": "23092f37-d0e9-4604-a8bc-af3e31c4fa7e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0Lu_ArAww76m"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    #removing roman numbers\n",
        "    pattern = r\"\\b(?=[MDCLXVI])M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})([I]X|[I]V|V?[I]{0,3})\\b\\.?\"\n",
        "    re.sub(pattern, '&', text)\n",
        "    #removing numbers\n",
        "    text_nonum = re.sub(r'\\d+', '', text)\n",
        "    #getting rid of punctuations\n",
        "    text_nopunct = \"\".join([char.lower() for char in text_nonum if char not in string.punctuation]) \n",
        "    #getting rid of white spaces\n",
        "    text_no_doublespace = re.sub('\\s+', ' ', text_nopunct).strip()\n",
        "\n",
        "    return text_no_doublespace\n",
        "\n",
        "def normalize_sentence(tokenized_sents, minimum_length=2, stopword_removal=True, lower_case=False, number_removal = True):\n",
        "  \n",
        "    normalized_sents = tokenized_sents\n",
        "    \n",
        "    if stopword_removal:\n",
        "        stopwords = [x.lower() for x in nltk.corpus.stopwords.words('english')]\n",
        "        normalized_sents=[[word for word in sentence if (word.lower() not in stopwords)] for sentence in normalized_sents ]\n",
        "\n",
        "    if lower_case:\n",
        "        normalized_sents=[[word.lower() for word in sentence if len(word)>minimum_length] for sentence in normalized_sents ]\n",
        "\n",
        "    elif minimum_length>1:\n",
        "        normalized_sents= [[word for word in sentence if len(word)>minimum_length] for sentence in normalized_sents ]        \n",
        "        \n",
        "    return normalized_sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0OSaHRa1lD2T"
      },
      "outputs": [],
      "source": [
        "clean_token = [word_tokenize(clean_text(txt)) for txt in data[\"sentences\"]]\n",
        "data[\"clean_token\"] = clean_token\n",
        "normalized_sents = normalize_sentence(clean_token)\n",
        "data[\"normalized_sents\"] = normalized_sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "zrT90BVDa_8S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "30e1efe1-8819-4f35-9f1e-76392ef2653a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentences  labels author  \\\n",
              "3856   The category is therefore determined for consc...       0    heg   \n",
              "20883                                            Friend!       2    nei   \n",
              "8256   These \\nprinciples could not be drawn from exp...       1    kan   \n",
              "3497   However, this \\nseems to imply that he cannot ...       0    heg   \n",
              "86     The onset of the new spirit \\nis the product o...       0    heg   \n",
              "\n",
              "       sentence_len_by_words  \\\n",
              "3856                      25   \n",
              "20883                      2   \n",
              "8256                      21   \n",
              "3497                      53   \n",
              "86                        39   \n",
              "\n",
              "                                         tokenized_sents  \\\n",
              "3856   [The, category, is, therefore, determined, for...   \n",
              "20883                                        [Friend, !]   \n",
              "8256   [These, principles, could, not, be, drawn, fro...   \n",
              "3497   [However, ,, this, seems, to, imply, that, he,...   \n",
              "86     [The, onset, of, the, new, spirit, is, the, pr...   \n",
              "\n",
              "                                        normalized_sents  \\\n",
              "3856   [category, therefore, determined, conscousness...   \n",
              "20883                                           [friend]   \n",
              "8256   [principles, could, drawn, experience, would, ...   \n",
              "3497   [however, seems, imply, determine, end, action...   \n",
              "86     [onset, new, spirit, product, widespread, uphe...   \n",
              "\n",
              "                                             clean_token  \n",
              "3856   [the, category, is, therefore, determined, for...  \n",
              "20883                                           [friend]  \n",
              "8256   [these, principles, could, not, be, drawn, fro...  \n",
              "3497   [however, this, seems, to, imply, that, he, ca...  \n",
              "86     [the, onset, of, the, new, spirit, is, the, pr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-852d9b89-f287-4744-a4bd-ec222651ec8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "      <th>author</th>\n",
              "      <th>sentence_len_by_words</th>\n",
              "      <th>tokenized_sents</th>\n",
              "      <th>normalized_sents</th>\n",
              "      <th>clean_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3856</th>\n",
              "      <td>The category is therefore determined for consc...</td>\n",
              "      <td>0</td>\n",
              "      <td>heg</td>\n",
              "      <td>25</td>\n",
              "      <td>[The, category, is, therefore, determined, for...</td>\n",
              "      <td>[category, therefore, determined, conscousness...</td>\n",
              "      <td>[the, category, is, therefore, determined, for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20883</th>\n",
              "      <td>Friend!</td>\n",
              "      <td>2</td>\n",
              "      <td>nei</td>\n",
              "      <td>2</td>\n",
              "      <td>[Friend, !]</td>\n",
              "      <td>[friend]</td>\n",
              "      <td>[friend]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8256</th>\n",
              "      <td>These \\nprinciples could not be drawn from exp...</td>\n",
              "      <td>1</td>\n",
              "      <td>kan</td>\n",
              "      <td>21</td>\n",
              "      <td>[These, principles, could, not, be, drawn, fro...</td>\n",
              "      <td>[principles, could, drawn, experience, would, ...</td>\n",
              "      <td>[these, principles, could, not, be, drawn, fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3497</th>\n",
              "      <td>However, this \\nseems to imply that he cannot ...</td>\n",
              "      <td>0</td>\n",
              "      <td>heg</td>\n",
              "      <td>53</td>\n",
              "      <td>[However, ,, this, seems, to, imply, that, he,...</td>\n",
              "      <td>[however, seems, imply, determine, end, action...</td>\n",
              "      <td>[however, this, seems, to, imply, that, he, ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>The onset of the new spirit \\nis the product o...</td>\n",
              "      <td>0</td>\n",
              "      <td>heg</td>\n",
              "      <td>39</td>\n",
              "      <td>[The, onset, of, the, new, spirit, is, the, pr...</td>\n",
              "      <td>[onset, new, spirit, product, widespread, uphe...</td>\n",
              "      <td>[the, onset, of, the, new, spirit, is, the, pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-852d9b89-f287-4744-a4bd-ec222651ec8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-852d9b89-f287-4744-a4bd-ec222651ec8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-852d9b89-f287-4744-a4bd-ec222651ec8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distributions.word_and_freq(data,\"normalized_sents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8dIScURggAo",
        "outputId": "344eaa04-8c03-4f88-aa83-346ba2def369"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word             Frequency        % of the total  \n",
            "one              3646             1.177854018465753\n",
            "reason           1799             0.5811737189303043\n",
            "pure             1776             0.5737434823903393\n",
            "would            1731             0.5592060630730167\n",
            "consciousness    1648             0.5323926007766213\n",
            "thus             1562             0.5046099771924044\n",
            "object           1554             0.5020255470915469\n",
            "time             1505             0.48619591272379553\n",
            "must             1324             0.4277231816918972\n",
            "even             1270             0.41027827851110976\n",
            "first            1231             0.39767918176943007\n",
            "also             1184             0.3824956549268929\n",
            "nature           1151             0.37183488076085625\n",
            "world            1151             0.37183488076085625\n",
            "something        1105             0.35697440768092625\n",
            "therefore        1095             0.3537438700548545\n",
            "merely           1080             0.34889806361574693\n",
            "concept          1075             0.34728279480271107\n",
            "since            1064             0.3437292034140321\n",
            "existence        1054             0.3404986657879604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"sentence_len_by_words\"] = [len(sen) for sen in data[\"normalized_sents\"]]\n",
        "distributions.full_df_run(data,minmax=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "oKvxeA4Bgt9e",
        "outputId": "7ad52fc4-17ce-4e5a-dfb5-d48627336c1e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9c9a8ec9-8a4e-424d-880c-c71c71463962\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9c9a8ec9-8a4e-424d-880c-c71c71463962\")) {                    Plotly.newPlot(                        \"9c9a8ec9-8a4e-424d-880c-c71c71463962\",                        [{\"x\":[3,15,14,25,26,27,21,1,16,0,21,20,11,23,10,16,3,0,7,19,0,10,20,32,14,21,9,13,29,18,0,46,15,17,0,8,15,10,23,23,0,21,13,28,14,0,39,7,10,18,39,25,0,27,7,6,12,33,12,16,6,8,23,7,5,0,11,21,27,11,30,27,0,8,11,8,38,2,12,16,0,9,6,10,12,7,18,9,20,17,22,27,8,26,13,0,11,11,12,15,22,15,9,27,13,27,17,17,8,10,0,17,19,25,20,22,24,29,2,0,14,10,17,12,23,0,12,19,12,12,0,23,13,11,27,10,11,3,0,2,5,11,5,24,20,12,15,0,9,16,10,12,26,8,3,13,0,7,15,15,7,14,18,4,0,12,8,6,12,8,20,4,10,2,22,32,0,24,3,9,12,35,6,19,0,17,20,7,6,5,13,10,0,10,8,6,6,8,13,13,13,20,6,9,9,8,7,22,25,26,10,0,7,6,2,16,40,0,17,14,16,19,24,23,19,12,14,17,15,0,16,4,9,25,37,22,18,2,4,0,6,2,11,12,18,13,25,0,6,18,16,10,18,0,11,15,9,8,15,15,18,12,6,12,5,23,6,12,11,0,31,13,22,31,9,18,18,16,5,9,0,15,35,11,0,15,8,10,1,11,15,12,12,5,4,6,21,8,5,18,12,12,17,8,3,7,9,15,10,0,29,18,8,17,0,18,9,4,17,9,10,3,6,8,8,7,23,10,13,16,6,2,5,15,0,19,7,15,9,0,24,9,14,16,0,24,20,15,6,9,10,15,10,17,14,3,7,2,17,22,0,10,14,12,5,23,0,18,26,11,15,20,0,21,3,5,15,13,12,16,5,3,32,23,5,10,13,7,0,13,11,10,34,22,12,16,5,20,0,21,9,15,23,7,7,19,6,5,15,20,0,7,1,11,7,15,4,0,14,11,15,10,16,10,22,4,19,22,15,0,13,0,27,0,16,22,20,13,14,8,16,24,9,0,22,3,31,50,16,23,18,18,11,19,20,15,24,26,15,0,16,25,0,5,17,6,15,5,12,15,16,10,17,5,32,7,13,1,13,16,23,9,0,1,6,10,6,15,3,34,12,9,22,24,0,15,12,4,8,11,13,8,18,9,8,8,25,6,0,6,16,18,22,0,23,11,14,17,8,5,15,8,1,15,0,13,1,2,4,26,1,21,8,3,6,21,16,10,12,11,8,3,16,20,16,11,16,16,19,10,1,6,19,11,6,11,8,15,11,22,5,30,14,7,9,34,0,38,6,18,19,0,0,11,12,2,18,26,9,30,0,17,20,3,17,5,15,0,21,16,12,10,14,5,12,8,7,22,8,7,8,19,24,10,15,15,20,4,2,23,16,16,0,9,17,8,15,36,13,27,12,0,40,26,18,26,0,13,25,7,10,30,17,36,5,13,11,0,27,21,17,10,10,6,27,7,2,35,53,22,17,41,9,9,16,10,8,16,21,0,28,7,14,9,19,41,19,16,14,14,24,5,12,22,20,13,15,0,22,6,21,11,32,0,9,27,20,5,0,75,17,27,11,20,8,32,16,6,17,13,8,6,0,41,0,9,18,8,28,13,37,13,18,22,22,14,30,0,10,15,20,12,11,19,20,0,19,11,17,4,10,16,8,13,2,12,23,30,26,0,14,20,25,19,0,11,17,18,5,16,0,7,15,7,16,0,9,12,2,19,12,16,11,10,5,11,6,21,0,23,11,12,21,17,6,18,17,10,27,0,16,12,10,3,10,7,6,13,3,5,7,0,11,8,11,22,9,20,10,23,19,13,10,14,11,11,10,0,11,0,17,7,8,6,26,8,4,15,11,6,0,26,13,6,8,4,32,20,3,9,17,0,13,6,17,16,6,0,0,14,27,3,9,0,19,10,0,4,9,1,2,1,8,10,8,0,2,6,14,14,3,17,14,6,0,4,1,1,16,26,0,2,2,12,14,5,0,13,21,0,12,16,7,4,6,14,14,4,9,11,3,9,1,23,7,3,1,9,9,27,0,23,16,0,2,11,0,14,3,17,0,21,22,0,13,10,14,9,5,5,0,1,4,4,3,3,8,0,10,10,4,14,13,13,7,14,10,8,6,9,1,8,4,6,16,23,1,14,13,25,12,10,4,18,7,7,11,16,1,14,17,24,11,0,22,22,8,16,3,22,18,2,10,16,16,12,32,1,16,1,3,10,5,13,14,19,14,15,14,16,1,0,12,12,4,16,1,13,0,16,9,8,11,9,17,9,21,13,8,25,7,10,12,9,0,16,23,35,12,12,8,0,11,39,10,14,24,0,10,7,9,14,14,10,21,0,6,10,6,13,6,9,11,6,21,11,24,16,6,18,5,12,0,9,8,9,8,13,10,15,5,8,23,19,0,17,16,11,12,20,0,12,10,18,6,11,4,6,16,3,8,7,20,0,12,7,11,8,8,12,10,14,17,0,26,21,21,0,8,12,8,8,10,11,4,10,18,9,5,12,0,17,10,11,21,11,3,7,18,10,0,19,19,19,0,13,20,0,8,20,10,2,0,19,19,2,0,12,30,10,15,0,13,6,10,13,12,5,2,21,26,0,26,18,29,27,20,30,23,19,13,30,19,6,11,32,1,5,17,24,8,15,11,8,12,23,0,6,17,13,11,16,0,14,14,2,21,10,12,7,17,28,4,5,6,17,12,16,22,6,12,4,11,3,18,17,23,4,9,16,13,12,23,11,19,10,9,41,21,0,18,20,36,5,8,13,14,7,5,5,0,21,8,10,16,4,17,15,6,16,0,15,32,19,27,2,28,17,24,5,33,0,9,12,4,20,13,19,6,16,15,24,14,14,0,13,22,18,0,20,15,9,6,10,6,15,9,3,12,22,16,14,8,9,0,40,0,27,0,10,8,14,38,29,14,15,5,42,13,0,16,10,5,28,5,9,12,11,12,8,9,16,13,6,13,4,13,14,10,21,30,10,2,12,36,12,7,22,0,9,10,13,7,7,7,7,11,14,18,6,28,12,9,21,19,0,9,16,15,15,21,28,4,0,27,13,22,22,8,8,17,5,13,5,14,6,13,3,14,6,5,0,8,9,9,39,10,6,26,9,0,16,14,13,10,16,23,3,17,15,19,10,8,0,16,15,10,6,7,11,4,17,1,14,14,10,0,14,13,19,10,14,10,13,36,21,0,14,12,9,13,17,5,20,9,0,15,14,8,8,17,12,26,22,16,0,22,31,23,11,20,30,23,27,12,13,28,0,37,8,15,10,3,4,13,4,8,0,12,17,6,12,30,9,7,10,6,4,0,33,5,30,7,16,5,14,12,13,14,17,32,9,8,0,10,13,18,6,15,32,26,18,31,14,8,5,2,8,16,18,8,10,10,17,4,9,29,16,24,26,21,8,35,1,2,7,4,18,15,5,9,13,27,14,5,0,6,7,14,13,15,10,6,4,11,21,12,2,23,8,7,3,17,8,11,1,13,4,16,12,19,6,16,0,13,5,24,20,14,19,16,0,13,11,14,9,10,0,14,3,9,27,13,7,18,7,14,7,6,15,9,17,6,12,13,12,22,12,0,20,13,17,5,0,7,10,11,0,22,23,7,16,16,10,12,19,8,19,10,5,0,7,3,8,9,8,9,13,16,0,3,7,15,6,3,18,23,6,8,8,17,11,10,0,6,11,1,3,6,15,0,8,21,0,18,6,15,7,5,6,0,11,0,14,12,15,9,10,5,0,11,13,5,0,9,3,5,4,7,20,25,7,11,12,0,22,7,5,11,10,10,26,13,15,14,0,11,22,10,16,34,16,0,7,10,14,6,2,28,3,0,7,6,9,11,16,22,16,33,10,5,7,15,5,0,17,7,5,5,11,10,10,8,5,0,8,18,6,5,7,0,8,7,23,0,5,2,10,6,11,14,13,19,9,10,11,0,23,6,19,9,8,12,11,16,10,0,20,14,6,15,3,15,13,13,12,13,31,13,19,23,8,13,11,32,18,17,16,6,54,16,17,21,0,11,12,1,10,9,5,15,6,3,8,33,16,18,0,6,9,5,13,9,8,12,30,10,17,7,4,13,6,22,0,10,7,9,3,11,3,16,30,20,35,16,0,9,19,40,0,13,16,17,4,13,14,9,9,0,12,10,36,18,5,21,23,17,20,4,18,16,9,9,16,11,14,22,0,6,12,12,17,5,13,10,19,0,24,20,10,6,0,11,8,15,11,0,20,6,31,0,12,14,8,5,3,19,0,11,9,5,10,10,12,15,6,30,0,11,22,14,22,10,0,17,19,22,30,6,18,17,0,31,22,3,13,0,32,8,14,7,11,14,0,33,3,27,18,12,0,30,18,19,29,34,15,15,6,21,8,17,22,6,0,10,21,4,7,22,4,19,33,1,0,43,0,21,7,14,21,9,17,0,8,28,19,5,14,31,0,14,19,10,18,20,12,4,17,13,27,13,18,10,4,7,17,8,0,10,4,0,17,10,15,29,41,0,11,10,19,0,14,27,16,0,8,15,10,10,7,3,9,32,0,23,12,6,46,11,10,11,10,4,17,10,7,11,30,12,11,13,18,0,0,4,10,5,14,9,24,23,14,0,12,14,16,4,0,19,37,0,8,13,6,22,11,3,11,23,11,5,11,17,13,20,3,0,13,9,10,11,8,1,12,18,10,3,14,3,0,8,0,3,9,13,24,12,13,8,3,29,4,15,19,15,13,0,13,5,12,10,15,16,1,16,5,5,4,9,14,14,0,20,9,0,3,19,25,0,6,5,29,12,13,29,7,2,23,14,30,24,2,0,20,10,24,0,2,14,16,6,11,4,1,0,8,3,8,0,25,15,20,20,0,2,9,14,10,17,17,22,2,12,9,2,11,11,5,0,21,2,20,21,15,6,0,9,29,27,17,18,21,25,14,17,9,13,0,11,15,18,14,25,18,16,12,26,8,10,11,19,21,0,9,0,12,29,20,29,9,17,0,19,12,3,15,17,26,0,10,7,16,11,5,14,13,29,10,3,0,25,3,0,18,30,16,59,12,13,10,0,16,4,16,10,5,29,37,11,11,6,17,48,18,13,0,0,12,0,8,32,0,11,20,7,18,0,6,6,39,0,18,25,17,25,16,28,31,8,16,32,0,11,12,13,16,12,0,10,13,13,22,11,9,0,0,14,19,18,14,12,12,16,11,11,0,10,17,14,4,12,8,4,7,13,0,5,0,6,2,9,7,7,18,17,17,15,6,12,10,20,6,0,15,17,11,16,16,10,20,10,2,12,7,36,0,43,5,0,12,0,32,9,23,22,6,8,0,5,12,0,29,18,8,13,10,13,0,9,11,21,20,32,0,4,26,0,19,24,0,4,3,17,9,0,39,0,21,22,7,24,11,4,9,16,30,15,30,0,7,6,9,27,34,8,27,0,18,15,1,30,7,19,24,0,36,18,0,32,0,14,14,15,18,0,27,23,15,28,5,20,0,0,1,19,14,23,19,27,16,7,36,17,0,39,7,13,7,0,7,13,45,11,0,12,28,9,19,0,4,16,25,19,0,10,3,9,7,4,22,7,2,5,15,9,0,33,18,21,0,42,16,31,11,34,8,0,16,20,20,3,30,0,18,0,13,6,20,0,16,10,24,17,23,18,29,9,19,15,14,11,0,12,0,20,25,20,0,12,26,12,8,0,11,18,18,4,0,18,25,16,9,6,36,15,15,6,7,3,16,29,10,13,2,0,16,0,27,7,23,21,9,17,28,15,41,16,20,25,0,13,11,6,6,21,12,15,4,4,11,3,0,9,14,10,16,24,14,13,0,27,13,10,16,25,16,2,8,25,28,25,4,13,20,0,30,14,0,16,0,9,36,15,28,18,0,22,31,20,6,9,34,0,43,0,35,16,19,37,16,0,10,0,6,3,18,13,12,16,1,0,13,15,8,7,42,14,19,0,14,2,15,15,11,16,14,9,12,6,4,9,8,10,0,11,10,6,0,11,8,0,9,20,39,33,34,0,47,0,18,24,13,15,14,0,12,10,16,0,14,32,22,1,0,20,18,17,10,13,29,0,38,25,13,18,0,13,3,27,9,7,2,27,7,0,16,15,10,7,0,16,19,16,24,18,18,21,18,25,11,0,14,14,7,17,44,15,30,20,12,3,0,10,8,53,0,8,33,0,12,21,14,0,11,10,25,17,3,17,0,15,12,20,11,8,25,35,12,0,18,9,0,26,27,12,13,0,14,10,6,17,18,18,67,12,5,9,0,11,15,12,25,8,12,0,8,28,19,9,0,21,11,12,21,4,5,15,28,8,5,36,0,16,47,8,17,0,31,10,4,39,0,0,10,11,7,5,15,3,3,10,35,26,11,14,7,19,35,0,19,12,12,5,9,23,21,0,25,8,17,2,12,3,0,13,21,22,12,13,0,7,13,8,22,0,7,25,4,7,3,12,29,31,0,24,16,3,13,17,27,13,18,2,0,26,11,17,16,1,7,9,0,14,29,25,32,13,32,21,6,0,13,19,17,39,35,8,0,9,16,18,17,0,18,8,4,11,12,5,7,0,6,6,8,14,0,7,5,11,7,18,11,23,34,0,33,26,26,31,0,18,0,11,36,22,22,44,7,13,17,16,14,13,21,13,0,12,9,17,12,17,13,15,1,21,22,0,23,14,6,16,7,26,21,19,36,0,24,6,21,0,11,2,7,15,21,12,18,60,0,13,0,12,12,8,17,25,20,31,17,11,0,12,52,25,8,19,17,0,4,23,7,8,13,5,15,19,0,9,0,14,6,24,8,6,16,7,9,11,21,0,12,8,5,13,2,5,11,6,17,10,7,6,16,7,27,9,0,6,5,17,21,30,8,0,0,6,0,0,25,20,23,20,13,23,32,17,9,5,6,4,19,5,3,13,8,13,0,12,10,12,11,17,32,0,0,25,0,8,26,34,14,14,0,22,32,17,0,9,3,16,14,11,12,23,16,17,24,10,5,2,0,10,0,6,7,13,13,0,19,0,13,23,12,10,0,25,11,5,19,18,13,0,10,12,9,27,1,20,10,0,26,9,15,19,5,0,10,15,10,26,16,5,34,24,0,5,28,15,17,17,15,5,9,21,2,25,11,22,8,22,0,0,19,6,15,11,0,5,16,18,9,12,7,17,5,10,12,0,5,3,12,21,5,18,14,4,14,7,18,20,28,7,12,13,0,28,0,21,18,12,5,7,0,9,20,17,9,13,16,14,0,6,10,11,8,0,4,10,13,15,0,15,11,0,15,10,25,7,0,7,8,33,0,14,23,9,13,10,13,10,0,10,23,15,3,21,16,0,4,9,12,6,16,30,19,11,13,6,20,5,0,0,1,11,15,25,8,18,23,16,0,34,8,33,24,0,10,9,15,9,17,8,0,19,26,19,6,9,0,14,10,0,19,26,12,14,3,18,17,16,14,12,11,2,13,8,14,37,18,4,0,4,10,21,18,17,9,0,8,0,21,7,21,27,3,11,16,18,13,16,16,12,11,8,25,28,0,15,14,0,10,14,18,11,21,13,5,0,6,0,10,10,13,11,14,11,19,10,7,0,21,8,8,20,7,7,2,8,14,39,0,16,3,21,21,8,15,5,12,13,8,0,7,23,32,10,12,15,15,0,20,7,14,16,31,18,19,10,0,17,14,10,22,7,26,0,11,1,0,21,42,18,9,14,11,7,22,27,0,18,12,33,0,13,11,15,8,21,6,25,0,16,14,0,0,4,6,11,10,16,15,22,28,12,10,15,6,19,15,10,0,11,10,17,15,5,16,8,9,0,6,7,16,10,0,16,2,0,14,18,14,61,0,15,8,16,24,12,0,12,14,33,34,0,18,9,15,18,16,21,17,0,3,14,4,10,16,1,27,19,16,20,3,15,22,17,12,17,12,6,10,0,26,9,7,5,14,11,0,11,21,11,24,6,6,0,6,6,11,15,7,15,5,20,22,15,0,15,17,9,15,10,9,9,6,5,6,18,34,25,12,1,27,7,0,11,0,13,24,11,8,26,18,0,37,8,8,14,8,17,0,27,10,17,17,8,13,0,21,20,24,19,0,6,15,6,18,25,0,12,20,10,29,13,7,0,17,21,30,25,13,18,7,0,38,8,12,0,6,16,0,0,12,16,21,18,26,0,15,22,14,26,11,0,7,15,14,12,10,9,12,0,9,5,8,20,20,20,25,1,0,7,21,0,15,10,8,28,19,28,7,10,34,13,11,8,17,11,0,10,22,36,9,13,19,5,0,14,3,27,12,26,12,10,16,0,2,6,19,15,12,5,0,11,19,9,7,11,17,33,11,13,0,18,14,8,0,8,1,0,19,20,0,4,8,8,3,23,9,21,15,16,13,8,20,24,17,12,8,7,22,0,7,26,10,3,5,24,32,15,7,0,9,21,15,9,0,10,8,15,10,11,2,0,20,0,11,4,8,3,17,21,6,14,15,8,21,13,20,8,19,0,5,9,7,4,6,2,0,0,10,1,8,20,23,17,11,16,14,43,0,11,6,15,11,10,2,11,16,9,1,14,11,10,0,17,7,13,25,0,36,0,0,1,13,17,13,39,0,32,8,19,0,18,12,14,14,7,9,22,17,0,6,36,5,5,3,5,7,0,10,9,0,8,11,11,26,11,18,10,17,19,6,15,10,5,0,1,1,9,13,10,14,11,12,6,18,17,3,7,7,0,11,16,0,12,21,12,17,13,7,0,6,5,6,13,18,13,20,6,4,6,1,21,8,20,0,9,15,18,0,5,12,25,44,0,19,1,0,9,0,2,2,7,10,22,13,9,0,15,8,8,20,21,20,2,2,5,5,30,25,19,0,10,33,13,8,16,0,8,10,0,7,15,0,10,29,0,13,11,17,13,5,34,0,35,5,16,17,27,29,5,18,15,16,23,21,11,0,19,2,23,11,0,16,23,23,9,14,45,26,24,14,50,19,0,11,31,14,3,0,23,7,0,6,13,7,12,0,13,9,11,7,18,30,11,15,4,29,23,9,12,0,15,22,9,6,21,27,12,16,5,0,16,0,8,7,6,15,29,17,16,6,31,18,37,21,12,21,8,9,13,18,9,9,17,21,1,0,0,10,10,9,13,0,13,8,19,24,11,0,11,10,38,17,18,8,18,23,0,18,10,30,15,10,24,8,8,6,0,4,23,27,0,12,9,22,13,24,14,37,6,4,3,2,11,6,5,6,6,17,27,0,11,12,1,18,40,7,7,0,3,11,11,21,40,12,10,14,24,23,0,21,25,15,12,22,20,9,28,36,0,32,0,2,22,10,19,4,3,17,25,14,10,41,2,39,13,18,12,0,14,12,18,6,10,22,25,21,14,0,15,0,14,21,15,16,13,3,16,7,17,16,15,0,11,0,5,14,8,8,15,28,15,19,0,13,13,8,6,10,31,1,16,12,36,26,21,17,0,15,12,10,12,18,10,7,15,15,15,30,11,0,22,13,15,19,14,7,0,11,10,19,24,21,10,32,17,23,11,14,20,21,12,12,12,24,6,0,18,21,16,16,18,15,0,0,3,19,10,1,20,10,17,10,18,0,4,2,9,0,6,7,10,17,6,19,20,21,0,16,32,12,8,19,13,21,14,14,0,13,2,17,14,19,0,20,29,16,5,13,8,8,20,24,12,0,6,12,8,10,10,18,6,3,15,12,12,0,6,9,17,12,9,4,0,9,14,2,1,15,13,19,17,17,30,18,4,8,15,7,5,6,0,9,17,1,12,11,6,12,0,11,15,18,20,8,11,3,0,23,57,12,17,28,12,17,21,0,3,4,12,19,11,6,20,0,16,13,9,4,9,17,20,14,2,0,7,0,6,9,16,14,11,12,7,22,36,4,31,0,7,6,18,10,3,13,6,17,11,6,7,8,15,19,11,13,16,2,14,13,55,23,9,26,23,0,18,22,18,4,24,0,17,6,16,11,14,4,16,19,7,9,0,7,15,13,3,0,16,11,6,7,7,4,11,12,18,12,12,15,0,11,7,12,10,3,11,20,14,21,0,16,11,14,13,20,0,0,1,8,6,3,14,20,17,21,8,0,27,11,8,19,15,14,12,3,0,14,5,17,23,0,5,55,0,14,14,12,9,0,4,9,28,4,10,0,23,11,22,0,14,10,6,13,13,14,0,9,5,21,9,12,6,25,17,0,14,8,24,1,29,8,11,0,0,1,12,15,11,9,13,20,0,8,19,4,15,1,28,6,9,14,11,21,13,0,10,9,21,26,41,18,9,0,5,0,32,21,11,9,16,0,22,12,9,0,12,5,28,40,23,9,15,12,24,0,10,21,10,35,7,0,9,12,2,7,2,26,19,7,0,0,22,27,13,5,6,0,13,12,10,25,0,7,16,14,18,4,10,0,9,12,2,10,9,0,1,16,6,15,0,6,9,11,12,11,18,15,4,0,8,10,36,0,15,11,7,16,4,1,32,9,12,7,31,19,9,0,20,21,8,28,0,8,12,12,14,8,25,21,9,10,27,20,13,14,27,16,14,18,19,13,9,12,9,15,0,18,5,0,39,26,21,14,0,29,18,6,12,8,20,4,2,1,32,0,56,21,3,15,14,15,0,6,22,9,0,13,28,0,7,26,24,18,19,15,23,17,14,16,15,9,10,0,3,6,12,7,1,17,12,8,17,28,6,5,0,7,7,31,17,12,14,0,25,0,14,4,6,28,16,16,4,1,5,7,24,5,24,9,17,21,7,13,23,11,16,0,4,11,14,17,6,10,7,2,17,23,30,0,14,5,18,0,13,13,18,21,0,20,16,13,0,16,19,17,0,26,12,0,11,13,27,28,25,0,17,16,7,0,3,18,16,7,0,11,14,7,9,17,21,21,28,17,8,2,9,2,17,1,0,22,14,12,0,9,10,0,1,14,11,11,0,14,35,15,29,0,5,31,17,23,19,10,18,0,3,37,25,12,18,0,6,1,2,4,4,5,5,6,19,8,30,25,0,10,8,5,12,12,13,29,9,1,8,5,22,20,0,15,18,14,12,10,23,12,16,13,1,0,5,6,9,21,24,1,15,14,13,0,14,12,26,1,0,12,15,19,3,1,9,8,7,12,4,7,8,8,14,19,13,8,22,11,23,10,0,16,0,16,24,14,7,12,12,6,10,13,9,7,14,29,7,2,8,7,0,19,8,11,8,2,0,11,12,14,27,12,9,4,13,2,0,14,5,16,36,0,13,17,16,0,8,8,17,13,9,17,10,2,3,8,26,0,30,11,26,9,8,29,17,11,5,11,10,23,49,10,20,16,33,0,8,14,4,27,26,0,25,27,5,30,40,33,0,8,21,0,5,20,4,5,4,6,4,10,13,5,15,9,14,22,0,19,15,6,6,17,16,12,25,0,12,12,7,7,5,8,35,8,13,6,0,2,20,0,17,3,17,8,29,8,22,14,12,10,3,14,20,9,0,12,14,15,0,12,30,3,5,31,0,22,22,7,0,26,6,0,9,20,2,4,23,25,7,0,11,11,19,12,11,6,11,19,17,3,15,22,11,0,21,15,16,13,27,0,4,19,6,17,3,13,0,16,40,7,11,6,26,0,4,33,6,20,1,12,14,24,10,17,0,24,21,39,6,13,10,7,0,18,14,15,0,17,32,14,22,23,28,0,12,20,19,26,5,18,17,25,14,0,2,15,4,0,14,4,12,20,13,16,0,21,14,4,23,18,0,13,19,15,9,1,10,0,16,15,4,17,4,0,20,13,6,8,16,0,16,7,0,18,18,12,13,43,16,17,27,36,1,10,20,8,10,22,19,0,27,17,13,1,14,25,5,0,6,18,21,6,61,16,0,27,15,20,13,18,12,23,8,7,8,2,8,6,25,20,6,1,4,4,12,10,22,0,24,0,8,34,20,16,4,34,12,14,0,5,18,15,10,19,0,11,26,17,26,28,0,19,13,0,6,16,0,36,24,0,13,20,14,13,33,28,25,27,9,0,20,18,14,14,0,18,21,20,13,0,11,8,24,17,11,0,11,7,12,19,18,28,27,0,13,8,6,9,11,23,26,0,15,32,19,0,20,11,0,35,39,17,32,22,36,21,16,14,28,9,15,8,10,10,6,0,7,19,24,14,6,0,0,3,1,11,7,19,16,8,6,17,0,4,7,23,27,20,1,11,6,5,9,0,3,5,10,11,9,10,36,8,35,0,10,6,11,0,9,12,0,13,3,25,22,23,0,8,17,24,16,22,16,8,3,18,1,14,6,32,17,10,2,9,2,5,6,24,13,14,6,6,0,9,9,14,7,23,9,11,12,24,10,9,13,14,4,9,9,4,21,13,26,1,21,0,15,6,11,11,7,14,0,22,13,17,0,5,19,16,0,9,11,20,30,11,2,8,7,10,14,36,1,15,12,21,2,0,19,20,12,0,8,8,5,18,6,0,4,19,8,4,5,0,11,17,0,13,21,14,5,2,14,19,2,28,0,22,10,4,10,4,6,7,6,22,0,12,22,8,0,7,3,12,0,9,8,18,15,1,16,12,11,2,20,10,9,13,9,10,0,10,10,26,12,17,5,6,0,22,13,9,11,20,36,16,16,20,10,0,15,13,9,0,20,7,12,8,18,35,14,3,12,0,10,6,12,11,11,27,0,13,12,11,7,18,0,11,21,3,8,2,14,5,27,11,5,13,5,8,0,4,16,16,7,22,7,15,23,12,10,4,16,8,15,11,19,0,9,11,8,11,7,11,11,0,14,16,17,3,6,16,13,10,6,1,0,14,0,6,9,4,2,3,29,19,11,4,9,10,17,11,1,0,21,9,15,17,4,0,14,17,9,5,6,24,6,0,31,20,21,4,9,0,0,5,3,5,19,7,18,10,24,0,26,10,18,57,13,19,21,17,9,15,12,1,9,30,6,11,12,0,7,34,12,0,20,14,7,8,17,11,23,12,18,8,15,5,0,28,24,10,0,8,9,16,15,19,9,24,6,13,14,0,23,19,11,11,14,22,0,22,0,15,12,21,37,29,3,0,16,4,20,17,9,0,12,10,8,14,12,18,9,0,14,0,7,13,15,15,7,12,16,20,17,8,23,16,0,15,11,22,20,15,10,0,18,21,12,24,20,6,0,17,18,0,7,9,16,12,7,24,19,4,2,9,18,16,18,13,8,0,7,10,33,20,14,21,25,18,5,8,0,5,8,14,5,0,34,10,25,29,6,11,15,11,20,10,9,12,23,0,19,25,9,13,23,12,8,7,10,0,4,0,4,9,15,0,10,12,29,14,22,16,15,8,11,0,14,8,21,0,15,7,13,12,0,8,12,18,0,4,11,14,8,0,12,0,10,10,19,21,7,8,14,16,30,8,0,16,12,18,9,6,10,6,5,8,17,8,12,7,13,11,0,14,23,8,0,19,10,2,0,8,14,10,24,31,9,24,9,8,30,0,7,3,31,12,14,0,40,20,22,30,6,0,3,37,7,16,19,0,19,28,5,11,21,1,23,3,6,10,26,0,21,24,21,24,0,23,28,4,18,10,0,13,27,21,12,11,11,16,0,9,11,8,5,18,0,10,25,12,12,15,19,8,24,0,9,11,14,13,0,8,18,12,17,11,8,31,34,20,21,25,1,0,11,25,9,13,22,32,6,0,7,5,8,3,32,0,6,51,16,8,12,28,17,0,20,8,49,12,0,1,9,10,6,15,18,12,14,11,0,11,15,12,4,0,12,17,24,0,9,19,11,13,18,3,9,2,9,8,5,35,13,13,6,3,4,19,9,15,23,0,2,1,26,0,10,21,15,13,14,0,8,18,9,7,28,12,0,20,15,3,22,0,13,13,10,0,6,4,15,15,17,3,0,24,0,19,18,27,13,24,2,13,8,18,0,21,12,17,10,9,23,11,12,13,7,10,5,17,0,21,8,6,9,0,10,21,18,26,11,13,0,2,7,6,18,11,25,9,38,17,8,23,0,21,7,12,4,13,16,8,14,12,0,8,15,20,10,0,10,6,11,15,13,12,6,3,30,10,0,2,9,11,9,11,26,28,25,8,18,14,30,20,1,0,11,21,20,16,27,16,10,10,0,2,19,16,19,12,0,14,15,12,9,13,5,24,31,0,22,10,11,0,8,0,14,8,9,16,2,18,9,10,24,41,29,2,25,3,14,10,41,1,18,0,30,10,29,0,15,16,18,11,10,15,17,0,13,23,21,23,2,28,9,22,14,24,29,0,7,26,4,0,18,2,22,0,7,31,0,21,7,16,7,16,2,0,3,9,19,0,11,3,53,15,0,12,21,22,29,34,32,0,3,18,21,17,13,0,5,25,9,20,15,20,6,14,0,15,12,9,8,14,0,3,7,22,0,13,5,17,10,1,20,33,0,0,1,12,28,20,12,14,11,9,21,28,0,33,10,18,24,10,10,5,13,24,22,0,6,10,11,17,28,0,6,0,0,17,8,27,18,6,14,13,10,12,0,8,23,16,11,19,11,28,0,72,13,43,15,1,2,14,31,20,0,14,5,34,0,27,16,9,16,15,8,4,29,7,0,4,4,8,7,25,26,12,8,12,17,0,9,0,17,18,8,10,19,4,10,10,24,0,12,13,6,15,13,23,0,11,10,26,17,9,16,23,10,24,0,3,14,0,2,20,23,5,11,16,38,11,27,10,3,14,17,13,23,0,8,10,5,26,29,0,32,30,0,7,0,5,11,17,15,0,29,23,7,10,16,16,23,0,13,8,17,26,18,23,22,18,14,3,12,11,19,0,9,21,22,14,15,0,12,8,5,16,20,0,10,17,20,11,15,8,32,16,16,15,21,10,1,6,14,16,7,9,0,15,18,19,38,5,10,13,9,11,18,24,35,33,0,25,26,15,19,24,0,24,11,3,20,38,14,25,0,20,21,25,45,46,0,15,10,20,16,0,10,9,40,8,0,12,10,0,7,18,15,22,16,8,9,0,12,21,8,1,2,2,1,1,12,17,0,10,18,26,12,0,8,14,14,16,18,21,10,0,2,19,0,21,20,23,23,18,9,22,25,24,0,22,29,33,39,0,10,12,8,14,0,4,28,17,10,0,20,0,8,7,16,13,14,25,0,17,8,28,14,1,23,66,0,28,15,21,0,3,13,26,33,0,14,9,6,12,7,30,19,15,15,10,2,24,13,17,8,6,16,0,15,42,22,0,7,18,23,11,6,9,12,33,0,14,13,14,10,9,14,7,10,19,0,16,11,11,9,13,12,14,20,18,29,0,5,8,7,55,0,11,9,47,31,3,19,0,21,7,14,20,22,15,0,31,7,32,1,0,16,0,18,5,9,2,12,10,18,3,9,20,3,0,18,9,6,18,26,33,0,11,9,12,16,3,4,4,7,12,13,8,3,11,16,2,0,16,12,16,13,10,5,0,5,5,14,19,17,7,13,4,13,0,24,3,5,27,5,3,15,22,17,20,0,7,16,10,12,3,0,1,9,5,10,7,35,0,8,5,19,10,18,34,0,27,13,0,9,11,10,18,22,5,6,17,6,23,14,25,0,1,10,6,9,8,18,21,27,0,28,30,10,0,20,6,16,12,6,8,13,6,5,0,12,13,13,18,0,5,11,5,4,17,0,4,30,12,34,22,19,0,18,8,19,4,6,21,14,4,0,40,0,12,3,42,23,0,27,14,5,0,10,14,26,52,11,2,27,17,34,42,20,11,23,34,4,16,0,9,18,7,7,0,13,21,26,17,12,10,11,18,0,19,10,9,5,14,17,13,22,20,4,0,9,23,4,11,25,16,19,0,20,6,28,8,30,16,25,20,14,18,17,17,8,9,18,15,20,8,0,7,3,10,18,21,4,0,12,12,32,7,35,1,16,0,17,12,10,9,25,10,7,0,6,13,13,28,10,10,18,10,13,0,5,19,15,3,17,0,0,22,16,12,15,23,11,7,18,18,19,0,15,12,10,10,7,43,0,26,20,19,3,15,3,13,11,0,6,20,11,17,16,21,9,21,16,5,22,0,3,2,24,20,34,6,16,6,10,8,12,6,0,14,0,12,9,15,8,7,8,10,34,0,3,9,5,8,10,16,16,6,14,0,14,7,7,48,0,15,3,21,3,11,15,4,0,8,0,16,7,14,9,23,6,23,26,0,16,10,4,19,26,0,20,24,16,4,9,11,14,4,17,24,14,0,8,0,32,11,9,21,14,36,13,11,19,1,15,13,27,13,13,0,13,14,25,0,26,10,6,6,3,4,0,6,9,0,10,6,6,7,1,1,4,2,17,0,11,18,12,4,0,8,17,9,18,41,14,15,7,18,2,20,31,3,0,24,7,11,0,0,15,4,8,21,14,10,11,11,0,39,6,7,24,13,19,26,27,22,12,14,14,15,31,20,8,0,9,0,37,14,12,17,46,0,11,4,5,9,11,22,9,19,16,2,13,25,8,8,26,0,12,12,7,0,5,0,11,13,18,19,0,14,19,16,2,22,15,9,13,18,6,9,14,12,39,7,5,25,4,10,10,31,25,7,14,26,5,28,7,10,5,17,58,27,11,29,14,4,19,24,12,12,90,24,19,20,18,16,7,14,2,14,16,30,55,19,20,29,23,16,37,30,6,19,33,3,36,27,21,4,14,7,12,58,43,29,20,33,8,16,30,8,15,4,8,22,54,5,30,27,20,61,30,13,26,10,31,14,22,22,38,28,6,40,24,14,53,16,37,13,38,35,53,2,22,9,48,42,27,10,41,13,44,11,11,6,2,12,18,14,29,17,26,31,9,18,73,32,22,27,20,48,19,37,21,24,51,35,13,13,17,27,21,15,65,45,34,17,11,44,17,38,42,69,4,6,30,4,26,35,11,16,10,26,44,20,14,11,9,6,56,64,59,43,23,52,26,98,15,13,38,47,121,33,9,50,17,30,23,48,42,72,105,27,53,6,43,40,36,40,15,16,18,26,40,23,36,63,52,35,44,0,11,9,47,19,4,22,14,27,32,31,7,31,3,1,3,13,19,23,40,13,12,12,8,4,0,2,0,1,6,2,10,5,13,17,20,51,22,42,51,22,19,10,1,10,12,12,11,7,16,9,16,17,15,15,11,11,13,30,36,19,13,16,7,18,36,6,28,14,6,22,3,5,13,15,37,20,13,26,24,5,12,12,14,29,15,6,15,2,19,80,5,10,8,12,6,10,7,30,6,25,13,1,8,9,26,23,17,2,33,20,28,54,1,7,1,47,13,42,24,28,15,23,10,14,37,13,23,7,24,15,18,18,1,22,5,49,8,26,18,22,14,8,8,1,10,17,5,12,14,8,10,14,0,9,9,8,20,19,16,28,14,23,13,73,12,8,18,22,27,1,11,3,2,13,23,43,9,30,54,25,19,5,5,8,9,24,9,13,13,9,7,15,9,16,17,15,15,10,4,11,13,27,6,6,11,7,10,40,8,5,18,17,7,19,39,7,5,21,8,6,5,2,6,9,13,6,3,18,7,23,23,14,23,30,25,5,11,5,12,5,6,3,6,12,17,53,27,8,3,17,19,8,6,9,4,8,6,5,10,7,33,15,18,17,19,20,28,28,8,32,6,40,6,8,17,8,22,11,15,12,24,0,31,8,8,10,13,0,12,9,67,0,17,17,10,19,13,108,4,12,26,16,34,7,13,44,39,30,10,23,41,50,25,36,9,8,15,9,7,7,8,26,24,20,2,31,19,18,7,5,9,22,5,21,28,44,13,24,21,2,22,12,13,1,8,11,6,39,21,26,15,45,9,13,21,7,23,21,23,11,19,6,35,10,12,17,7,6,39,12,11,11,4,1,7,3,7,10,24,9,15,7,24,16,8,17,10,16,2,26,26,36,15,4,17,20,15,6,11,37,6,2,2,36,42,1,9,44,16,18,10,12,10,16,13,12,3,0,5,19,12,13,9,0,0,14,2,8,7,26,5,12,12,16,13,14,37,20,10,2,4,6,7,11,3,1,34,25,12,8,6,7,17,26,24,8,6,17,14,9,0,5,13,4,7,11,10,13,6,19,15,10,9,8,14,31,6,31,15,24,13,8,9,3,1,25,12,10,12,5,13,4,4,9,12,12,11,9,18,11,14,10,19,1,1,2,6,6,14,7,19,2,24,20,11,8,10,16,34,10,6,11,23,1,23,25,20,24,16,11,18,17,14,12,20,6,23,14,23,41,7,3,3,9,11,5,3,22,6,5,5,15,9,26,7,6,5,13,6,5,1,34,27,11,45,35,17,9,16,15,24,9,82,38,35,14,14,19,7,30,1,6,16,34,10,16,3,7,19,13,13,26,31,8,7,17,21,31,82,11,4,35,17,9,2,1,32,47,17,10,24,28,31,20,14,1,24,10,10,15,9,56,66,4,11,26,7,23,14,9,13,21,7,6,6,21,26,5,21,13,14,24,9,15,7,24,16,8,18,11,18,2,28,40,36,5,19,19,15,5,12,9,29,6,2,25,37,1,2,30,14,7,11,26,16,11,13,34,5,27,8,31,4,7,2,1,6,12,14,9,6,15,12,16,11,21,11,15,16,13,4,15,29,7,15,8,20,26,12,9,14,16,27,25,8,1,9,10,65,15,39,5,10,10,12,5,16,2,6,4,4,9,12,10,12,10,19,5,6,8,6,6,14,7,24,9,15,19,5,3,2,1,42,18,24,20,11,8,10,16,34,10,6,9,5,42,25,20,23,16,11,18,17,14,12,21,6,12,1,15,34,41,7,3,3,9,12,31,6,5,5,15,9,3,3,16,16,27,10,41,22,14,18,8,17,15,4,1,30,85,39,9,21,5,14,14,8,6,1,20,33,9,15,2,7,20,12,13,29,27,8,3,1,6,8,21,21,31,83,11,4,37,9,7,1,17,32,49,17,15,24,20,8,31,12,1,15,29,10,10,15,9,37,18,67,0,32,2,23,9,30,30,36,26,13,14,21,28,3,1,34,1,44,0,25,7,33,22,21,6,9,19,74,0,25,21,8,89,1,35,3,12,48,2,30,18,3,14,6,14,9,17,10,7,3,11,13,2,0,0,5,15,5,8,3,12,12,12,31,9,24,12,6,40,18,14,18,13,18,15,7,12,16,6,33,53,0,2,7,6,25,5,3,0,0,11,19,19,44,31,21,14,10,37,26,16,1,5,23,17,10,53,10,34,18,22,17,2,3,0,0,3,11,14,48,32,50,37,6,42,18,33,5,15,6,15,10,11,19,10,33,20,0,0,5,24,7,56,15,8,0,7,0,7,0,8,30,9,8,23,15,2,3,3,6,66,3,12,16,3,4,0,3,0,13,9,11,15,11,3,1,3,5,25,36,8,29,23,20,12,7,5,6,4,5,11,7,10,11,7,33,34,6,27,12,4,3,10,10,35,10,0,0,1,0,2,7,12,6,11,18,4,4,32,9,5,9,1,3,12,11,15,21,1,37,0,21,13,30,19,10,1,20,25,13,7,2,0,0,1,0,0,13,32,33,12,13,19,6,4,54,14,18,19,13,6,1,11,34,0,35,5,4,21,16,10,29,17,26,4,11,10,4,0,0,1,0,23,31,11,19,24,25,14,3,14,8,29,9,5,41,19,13,9,26,6,11,11,20,20,22,27,14,4,0,0,1,0,17,40,8,18,24,20,6,6,8,5,4,22,37,9,12,7,3,34,34,11,17,11,17,3,0,0,1,0,0,9,27,23,8,10,23,13,39,40,3,2,0,4,1,4,11,24,2,26,8,8,6,19,8,25,13,18,29,7,19,17,2,0,0,1,0,32,48,33,0,29,55,3,11,46,22,4,7,12,19,28,5,65,0,0,1,0,0,0,1,43,16,17,27,16,36,12,4,8,2,12,3,0,7,5,0,0,1,0,0,14,25,31,37,26,22,19,6,30,2,32,20,25,16,22,18,14,19,30,43,7,3,0,0,1,0,0,26,27,38,23,26,25,6,18,46,12,1,70,11,43,14,34,15,11,12,30,8,6,5,0,2,0,0,1,0,0,0,4,23,8,6,21,17,17,12,29,39,11,28,3,25,9,10,12,19,13,11,12,26,11,54,9,3,0,1,0,0,13,51,20,4,23,17,6,31,26,11,1,1,13,17,12,21,24,14,36,34,21,33,9,0,0,1,0,0,14,17,34,60,0,3,39,7,20,1,9,36,9,15,4,0,3,30,37,54,8,0,0,1,0,0,0,0,8,17,43,23,36,7,31,3,11,21,11,1,26,6,11,30,8,12,11,16,63,10,18,7,0,0,1,0,0,0,0,13,18,17,12,14,14,5,37,31,8,12,16,7,17,9,1,14,34,60,7,6,10,30,17,17,35,0,0,1,0,0,29,6,16,11,16,23,27,25,15,26,24,31,15,14,27,30,11,15,3,8,16,24,15,11,0,0,1,0,0,11,17,47,17,22,13,8,30,19,24,13,22,44,14,14,18,15,16,8,25,16,13,20,5,0,0,1,0,0,0,0,2,15,12,42,22,15,46,29,13,25,14,16,17,13,33,36,9,29,42,25,3,0,0,1,0,0,2,9,31,7,11,22,27,24,33,27,10,15,7,13,10,13,26,29,11,25,16,9,31,33,2,24,0,9,0,0,1,0,0,22,3,5,7,8,10,30,14,11,12,9,15,19,22,18,19,11,2,26,18,26,9,9,2,16,15,13,11,17,14,13,0,0,1,0,0,15,12,34,7,16,21,75,7,33,2,0,0,1,0,0,0,19,11,5,36,6,20,0,5,21,7,9,40,14,2,1,8,12,30,5,14,10,14,21,63,30,19,2,0,0,1,0,0,0,2,16,52,12,14,17,20,8,16,14,37,1,36,5,6,15,19,21,15,27,32,27,5,8,0,0,1,0,0,0,12,16,32,33,0,4,28,11,11,33,20,1,7,19,25,29,35,6,63,9,4,0,0,1,0,0,0,0,2,36,18,30,0,11,50,19,10,2,7,1,1,4,1,17,22,32,33,22,25,41,2,12,3,0,0,1,0,0,0,38,0,7,5,43,20,15,19,15,15,23,4,1,21,3,11,20,12,7,16,7,31,7,30,27,13,0,0,1,0,0,0,25,1,5,25,23,60,38,25,8,10,1,1,64,8,34,52,37,9,0,0,1,0,0,0,12,53,3,46,26,13,31,18,5,1,28,91,14,3,30,5,17,8,6,0,0,1,0,0,0,26,16,73,5,13,11,36,6,7,1,4,10,24,28,20,17,23,19,34,21,17,3,0,0,1,0,0,0,0,0,22,16,24,24,22,14,20,16,22,10,4,1,8,17,38,2,22,17,9,7,10,13,57,9,2,0,0,1,0,0,0,15,12,19,4,13,7,4,9,21,17,75,13,2,1,1,17,15,73,70,3,26,0,0,1,0,0,0,14,8,27,5,19,42,16,23,16,25,19,0,0,1,0,1,18,5,19,8,23,15,23,41,13,18,20,10,42,8,43,12,26,44,21,21,2,11,4,0,0,1,0,39,36,33,14,16,24,13,9,4,18,18,3,0,0,1,0,0,0,22,22,17,17,14,3,8,14,12,10,16,37,31,33,20,17,8,24,11,14,16,15,24,24,22,20,2,0,0,1,0,0,0,24,46,21,11,17,26,5,12,31,20,7,11,7,16,36,17,6,17,14,7,15,24,5,45,2,0,0,1,0,0,0,21,25,22,46,17,20,10,17,48,10,42,10,10,7,7,31,21,23,13,5,32,7,29,36,26,34,30,40,2,0,0,1,0,0,0,11,16,16,40,16,20,20,3,28,13,10,6,30,8,16,23,10,24,16,12,8,13,27,20,5,11,10,6,0,0,1,0,0,0,28,14,15,16,44,8,35,24,23,36,2,26,27,16,38,12,32,34,12,3,0,0,1,0,0,0,14,17,31,25,21,21,21,16,38,6,28,3,7,5,2,2,4,2,12,36,7,8,4,9,2,1,6,1,2,1,5,3,5,20,4,0,0,1,0,0,0,43,0,28,30,53,1,14,19,25,3,12,68,4,18,0,5,13,14,18,22,3,8,16,7,0,0,1,0,0,0,23,18,37,5,8,12,22,20,3,34,16,8,12,16,11,7,17,23,11,13,9,17,2,30,15,29,40,7,0,2,0,0,1,0,0,0,0,20,17,11,7,19,34,31,27,8,5,13,22,23,28,3,11,20,11,33,25,11,7,27,6,10,0,0,1,0,0,0,21,13,9,17,6,24,18,17,22,0,29,23,13,42,1,3,64,27,19,47,19,45,2,24,0,0,1,0,0,0,15,19,62,35,4,25,40,36,31,7,3,19,23,21,8,25,16,16,1,9,5,8,3,0,0,1,0,0,0,20,27,32,20,18,28,18,5,32,12,8,1,11,2,10,20,25,14,19,24,39,12,5,10,39,13,0,0,1,0,0,0,1,19,26,62,29,11,40,36,4,4,2,3,31,30,12,5,7,3,12,6,16,13,6,13,19,4,19,12,11,2,0,0,1,0,0,0,12,13,2,17,16,17,19,28,19,12,16,13,14,28,15,11,5,28,16,30,20,6,16,33,7,25,1,4,9,7,0,0,1,0,0,0,15,5,11,30,17,18,14,51,14,8,9,14,19,11,2,7,2,45,6,5,8,6,26,38,4,18,7,5,22,9,14,0,0,1,0,0,0,7,12,2,17,35,25,4,14,6,17,20,6,6,4,41,30,25,5,9,18,7,21,48,6,0,0,1,0,0,0,6,23,7,9,25,20,33,7,3,27,8,14,22,6,4,19,8,22,14,15,19,10,17,17,24,21,27,14,0,0,1,0,0,0,18,32,26,13,41,35,29,19,8,26,45,19,12,29,35,8,2,12,14,0,0,1,0,0,0,25,20,32,30,49,6,17,24,20,45,9,14,14,18,8,13,10,6,29,25,27,4,0,0,1,0,0,0,14,35,18,4,21,5,6,16,17,17,13,14,10,9,16,10,7,8,3,13,18,47,15,15,16,13,20,7,20,23,25,21,3,0,0,1,0,0,0,10,13,8,5,47,17,19,27,14,26,10,12,2,3,13,16,20,13,9,24,10,6,21,19,6,26,28,20,11,2,0,0,1,0,0,0,26,10,15,45,2,7,12,27,21,5,8,4,2,13,24,24,19,24,5,8,24,11,23,14,17,17,4,14,3,0,0,1,0,0,0,24,28,20,6,25,11,11,8,15,51,18,9,2,30,21,3,28,28,14,14,4,13,28,18,7,3,0,0,1,0,0,0,33,13,26,24,24,24,34,17,1,13,36,5,21,26,4,0,10,0,7,0,48,19,30,9,7,6,4,6,3,0,0,1,0,0,0,16,17,20,28,24,10,1,7,6,1,9,11,4,6,3,6,1,7,8,3,28,6,3,10,43,18,57,8,14,23,23,28,0,0,1,0,0,0,8,36,23,65,25,15,11,19,27,7,27,32,54,6,25,14,21,18,13,0,0,1,0,0,0,15,21,13,17,11,72,6,27,24,14,16,5,6,23,11,26,1,10,29,22,12,30,18,4,0,0,1,0,0,0,8,45,9,48,10,17,38,8,7,11,11,2,18,60,15,16,15,28,20,19,10,5,6,2,0,0,1,0,0,0,35,3,8,13,40,41,36,17,7,18,2,1,11,6,4,61,28,19,17,21,16,3,5,21,26,7,13,2,0,0,1,0,0,0,21,23,13,18,72,15,19,37,22,11,32,17,12,14,27,10,6,14,12,16,10,10,6,5,0,0,1,0,0,0,22,35,12,26,19,10,19,11,13,32,7,4,14,36,14,26,22,37,31,25,4,24,5,0,0,1,0,0,0,2,8,83,20,27,10,31,14,22,9,12,2,79,14,9,7,16,13,0,2,0,4,13,2,4,4,10,12,5,2,10,18,3,12,39,41,20,13,41,33,7,4,2,8,17,5,4,0,0,1,0,0,39,24,45,27,38,7,15,16,9,16,18,22,14,11,10,9,21,23,13,17,24,53,12,3,0,0,1,0,0,29,28,54,15,8,13,27,2,10,10,9,20,13,4,24,32,57,52,25,16,18,3,0,0,1,0,0,0,27,25,19,39,29,35,28,11,6,0,4,6,7,59,28,6,17,1,19,17,15,9,9,7,8,9,10,3,0,0,1,0,0,12,24,32,44,24,6,3,10,24,9,8,5,17,8,13,23,0,1,2,12,21,53,33,52,4,25,18,9,3,0,0,1,0,0,13,29,11,26,13,18,14,47,14,11,9,2,16,34,46,14,11,28,9,3,38,8,1,6,23,2,0,0,1,0,0,0,15,14,18,23,15,20,27,33,14,17,13,2,5,2,2,26,28,14,23,15,14,21,22,30,12,25,6,3,9,0,0,1,0,0,3,21,35,21,6,13,12,34,21,13,12,20,8,2,6,37,10,10,28,6,39,43,19,15,5,18,10,42,34,27,25,46,28,16,0,0,1,0,0,0,9,26,15,18,22,14,11,10,9,21,36,16,23,57,15,8,13,22,33,45,10,29,4,0,0,1,0,0,0,40,25,17,18,32,27,51,1,12,16,6,18,19,17,15,15,24,32,38,6,21,2,0,0,1,0,0,0,9,84,14,57,6,17,8,66,49,18,85,2,0,0,1,0,0,0,2,13,18,21,16,21,27,34,13,17,20,2,5,2,6,18,28,15,23,14,14,21,22,40,15,6,3,6,4,0,0,1,0,0,0,2,11,27,23,34,16,6,15,12,34,21,13,12,26,38,12,31,9,4,17,17,23,5,18,1,17,28,18,11,11,27,11,65,19,2,31,2,10,8,10,1,2,0,0,1,0,0,42,11,10,46,22,45,49,9,4,14,0,2,51,2,11,35,13,8,5,12,17,0,2,12,22,8,20,5,0,0,1,0,0,8,15,8,14,10,20,13,25,14,40,18,38,17,10,2,9,12,38,11,24,30,21,12,15,9,14,15,2,3,0,0,1,0,0,18,20,11,42,13,9,30,15,51,5,8,1,18,36,15,5,7,24,46,21,58,13,0,0,1,0,0,5,14,5,23,19,14,48,14,24,32,11,6,12,27,18,28,4,3,13,9,31,8,46,10,33,0,0,1,0,0,6,4,34,42,26,76,31,19,25,16,43,17,28,23,10,21,5,0,0,1,0,0,0,7,17,34,8,23,61,16,17,36,21,14,48,15,22,17,42,19,19,14,14,6,2,0,0,1,0,0,25,72,23,22,24,13,27,3,29,29,31,8,26,19,32,10,35,3,0,0,1,0,0,0,10,17,13,21,74,12,52,10,7,17,5,1,6,6,6,3,21,3,8,17,19,23,7,9,12,14,7,5,4,28,6,13,7,46,56,3,47,18,47,10,4,4,0,0,1,0,5,3,14,9,17,16,9,13,7,30,53,71,5,2,19,8,26,58,43,25,13,3,0,0,1,0,11,20,11,10,7,13,22,9,12,18,20,22,14,19,8,34,43,13,3,5,17,21,23,36,5,4,4,2,0,0,1,0,5,25,14,8,9,9,14,45,0,15,19,3,17,3,41,6,65,13,18,13,21,10,5,3,17,15,0,0,1,0,15,29,23,11,18,22,17,5,10,62,44,25,7,11,22,5,11,18,33,10,26,22,11,23,8,21,48,55,30,10,36,2,0,0,1,0,10,28,38,6,8,33,18,18,13,27,22,26,1,28,22,51,30,20,27,24,69,0,0,1,0,13,60,12,11,40,21,34,12,6,4,1,20,5,8,12,27,14,5,8,30,13,32,16,7,38,15,0,0,1,0,8,14,9,8,9,27,28,28,40,21,28,20,12,26,5,10,16,14,49,21,21,17,12,16,3,0,0,1,0,4,11,42,21,10,7,10,12,14,27,22,15,27,13,7,12,31,10,23,19,5,17,31,19,7,10,10,7,5,11,11,16,2,0,0,1,0,37,62,38,16,39,26,4,24,20,9,37,42,16,15,3,16,17,5,0,0,1,0,25,42,36,13,4,10,50,10,4,3,13,12,5,6,2,8,24,12,19,47,8,6,18,18,20,10,8,20,11,2,0,0,1,0,14,38,58,14,16,14,19,26,26,10,28,3,0,0,1,0,6,5,34,10,39,6,5,20,22,18,6,47,12,5,1,4,10,5,4,15,6,6,1,20,4,3,0,0,1,0,0,0,4,16,6,5,28,28,18,41,32,20,14,14,4,12,9,22,26,11,2,35,54,8,10,3,0,0,1,0,12,43,15,19,40,13,30,18,11,6,1,8,7,11,29,60,36,11,11,6,1,2,9,12,2,0,0,1,0,6,9,23,6,11,9,12,6,21,24,12,9,10,24,11,6,4,2,10,46,34,3,10,3,7,28,0,17,20,0,0,1,0,1,8,17,2,27,17,4,3,8,25,13,20,12,12,7,39,11,6,6,14,65,13,25,13,14,16,21,22,10,2,3,0,0,1,0,8,47,7,30,46,14,22,16,4,21,23,4,1,20,19,10,14,16,7,18,8,44,17,26,30,3,0,0,1,0,18,16,43,45,3,8,2,7,21,8,28,4,14,16,21,6,16,17,18,46,19,38,24,0,0,1,0,20,17,25,12,23,25,14,64,18,5,32,31,19,5,5,10,24,10,11,17,13,5,0,0,1,0,25,19,25,13,23,11,22,29,54,4,1,9,17,7,18,30,25,14,61,26,31,7,0,0,1,0,28,8,16,50,45,13,21,24,10,17,7,52,30,12,16,8,10,21,18,14,16,28,5,0,0,1,0,20,56,22,56,6,50,17,13,4,20,48,37,16,21,28,41,10,9,41,37,26,24,24,22,8,1,20,24,17,6,34,22,42,17,28,4,0,0,1,0,0,0,0,58,21,22,57,48,31,25,12,19,61,26,18,10,3,6,9,24,13,0,0,1,0,0,11,24,17,28,40,21,43,40,15,18,17,65,29,9,27,17,10,25,0,0,1,0,0,4,11,11,14,28,14,7,21,30,44,23,12,11,18,52,76,20,11,4,51,0,0,1,0,0,0,0,0,4,0,4,0,4,11,23,1,15,35,11,18,6,19,10,11,5,27,1,5,6,20,17,13,13,14,14,12,16,11,13,23,29,0,29,3,0,0,1,0,0,24,15,7,25,8,29,21,14,48,18,9,5,2,1,6,25,50,3,7,6,25,15,4,0,0,1,0,0,23,11,34,41,26,18,11,9,12,19,13,10,8,2,7,6,0,0,1,0,0,0,0,3,20,19,27,19,27,51,14,20,48,26,28,37,8,16,7,5,11,18,7,4,0,0,1,0,0,0,0,11,45,24,45,30,16,23,5,3,40,32,63,14,56,9,13,6,2,0,0,1,0,0,0,0,17,36,14,17,43,22,57,17,49,1,49,24,46,0,1,8,23,26,3,0,0,1,0,0,0,0,21,7,17,12,33,21,22,28,83,7,13,16,16,21,10,13,61,24,17,25,0,0,1,0,0,0,0,71,31,23,48,43,52,43,4,16,19,32,30,8,20,0,0,1,0,0,0,0,14,52,7,7,57,15,25,27,40,18,48,25,36,9,16,24,14,0,0,1,0,0,0,0,1,61,42,25,31,20,48,0,0,1,0,0,0,0,8,56,13,22,49,40,8,29,15,32,39,17,24,37,13,20,11,23,2,11,5,0,0,1,0,0,0,0,27,5,11,16,16,16,13,13,12,22,19,76,20,25,6,40,7,22,10,9,9,51,50,2,0,0,1,0,0,0,0,16,0,6,0,11,25,27,18,10,31,20,3,1,3,7,27,17,6,13,46,29,21,36,7,20,21,3,0,0,1,0,0,0,0,12,20,19,8,6,42,33,31,5,10,23,8,5,9,7,8,26,14,8,46,6,8,0,3,0,10,51,13,5,0,0,1,0,0,0,0,9,51,19,24,32,14,10,34,17,21,3,19,27,14,24,25,18,23,19,8,18,22,9,26,40,6,23,9,3,16,3,12,25,13,14,11,23,15,11,14,12,2,0,0,1,0,0,0,0,21,12,11,4,28,13,16,16,19,10,16,30,17,3,2,19,28,8,31,28,10,11,10,21,18,2,0,0,1,0,0,0,0,1,18,19,28,14,12,11,2,16,3,22,51,13,7,16,3,46,18,10,10,24,25,17,15,61,4,4,19,8,19,5,7,5,4,32,36,23,9,0,0,1,0,0,0,0,3,27,12,8,2,20,6,19,7,3,30,8,16,23,33,0,50,20,23,43,8,5,0,0,1,0,0,0,0,13,22,16,22,4,2,14,26,30,26,17,6,35,27,20,14,14,11,13,16,8,17,16,20,21,10,15,39,20,45,24,22,10,11,32,2,0,0,1,0,0,0,0,3,34,21,33,23,31,30,53,0,20,17,24,29,35,15,22,3,0,0,1,0,0,0,0,2,10,30,40,35,8,9,34,30,29,26,10,8,13,10,5,14,1,24,21,5,9,4,29,17,47,21,19,9,5,8,6,3,2,0,0,1,0,0,0,0,23,10,4,24,15,14,35,25,18,27,11,3,42,30,21,15,14,1,14,25,18,16,0,0,1,0,0,0,0,3,17,38,6,9,6,25,5,20,11,8,22,16,13,4,26,8,8,46,21,36,45,65,9,54,72,15,46,7,24,22,3,0,0,1,0,0,0,0,3,23,15,9,22,33,12,40,39,10,25,2,53,15,8,27,18,20,14,56,14,2,0,0,1,0,0,0,0,68,74,43,27,13,8,2,39,50,1,7,32,72,10,3,0,0,1,0,0,0,0,18,7,24,4,19,19,54,10,34,21,16,17,35,20,20,40,14,16,27,38,5,3,0,0,1,0,0,0,0,18,38,48,27,8,27,5,12,25,12,30,50,20,16,15,17,15,45,7,0,0,1,0,0,0,0,2,14,69,13,34,13,18,11,53,8,26,5,21,27,24,13,3,24,7,13,25,4,0,0,1,0,0,0,0,14,34,28,30,33,2,27,18,10,15,9,32,7,7,8,15,3,10,5,26,10,31,8,12,15,26,13,7,0,0,1,0,0,0,0,10,9,15,21,12,1,15,16,16,15,8,10,35,18,12,3,9,7,1,1,17,27,4,15,30,22,16,21,36,17,2,0,0,1,0,0,0,0,17,13,21,10,28,13,10,13,14,12,18,48,4,15,23,17,12,19,66,21,7,13,25,0,0,1,0,0,0,0,1,10,42,35,11,21,31,11,26,8,5,18,38,15,7,2,20,10,21,59,23,0,0,1,0,0,0,0,18,21,5,14,43,18,17,15,20,26,8,4,43,11,4,5,21,12,21,19,26,22,21,10,9,15,0,0,1,0,0,0,0,26,25,20,11,28,6,32,13,29,24,13,2,24,36,25,4,6,12,9,9,2,16,17,60,14,3,0,0,1,0,0,0,0,13,49,30,17,2,58,15,40,20,5,6,34,24,5,11,20,6,29,19,0,0,1,0,0,0,0,13,37,18,19,20,53,11,15,12,8,24,20,27,29,21,17,7,9,15,36,15,24,3,0,0,1,0,0,0,0,8,14,67,19,38,43,4,4,8,24,19,34,28,28,7,19,25,5,0,0,1,0,0,0,0,10,16,38,9,18,37,8,12,25,18,15,10,9,22,6,11,121,5,11,28,23,9,3,0,0,1,0,0,0,0,7,30,0,8,8,8,10,30,23,11,18,30,6,16,3,16,11,11,60,15,13,66,28,10,15,0,0,1,0,0,0,0,30,16,12,21,23,49,11,31,9,33,25,17,54,15,37,46,0,0,1,0,0,0,0,8,19,8,57,1,8,11,13,30,33,10,1,18,14,48,28,20,1,8,17,8,53,19,7,0,0,1,0,0,0,0,12,39,13,20,23,32,68,19,9,18,12,6,20,16,12,13,27,20,13,8,5,27,14,13,6,3,0,0,1,0,0,0,0,14,28,10,31,17,10,33,16,31,15,7,12,5,1,2,25,25,49,41,19,10,15,26,4,14,3,0,0,1,0,0,0,0,8,69,25,10,30,9,24,12,9,31,40,15,19,35,32,18,51,3,17,0,0,1,0,0,0,0,5,8,5,14,41,32,15,11,4,15,15,16,17,18,2,4,4,83,62,35,42,16,0,0,1,0,0,0,0,10,27,13,25,23,20,21,14,11,24,5,18,7,8,15,5,14,13,8,2,7,25,8,14,23,8,10,82,2,0,0,1,0,0,0,0,21,22,31,10,51,16,71,2,15,9,1,30,22,6,4,2,52,27,35,13,24,5,0,0,1,0,0,0,0,11,19,19,23,28,11,13,6,11,48,13,4,2,57,34,27,110,0,0,1,0,0,0,0,12,51,29,26,9,64,21,5,11,17,31,28,15,32,6,18,51,8,0,0,1,0,0,0,0,31,15,19,34,29,17,7,25,15,21,16,13,23,22,37,20,2,0,0,1,0,0,0,0,30,12,19,6,12,29,32,36,15,36,6,22,65,36,22,4,8,22,18,17,0,0,1,0,0,0,0,4,10,29,34,14,20,67,38,21,2,8,24,11,38,8,14,8,16,21,9,28,2,11,0,0,1,0,0,0,0,25,29,22,28,16,71,6,17,15,2,27,25,15,20,19,27,15,19,56,3,0,0,1,0,0,0,0,48,15,32,28,20,7,40,23,4,28,38,16,49,11,68,5,0,0,1,0,0,0,0,37,11,8,10,12,4,9,17,47,12,15,4,42,1,2,18,26,50,4,3,12,22,36,41,19,0,0,1,0,0,0,0,28,26,18,13,14,43,30,19,11,9,25,10,8,22,8,41,10,1,18,14,19,12,43,0,0,1,0,0,0,0,6,23,20,32,27,28,24,9,16,20,9,19,11,54,15,11,12,4,9,17,5,8,14,16,9,12,19,23,0,0,1,0,0,0,0,4,18,10,25,12,13,23,8,17,17,7,9,10,21,12,28,13,8,4,9,5,5,16,0,27,17,7,9,21,8,19,20,10,6,3,0,0,1,0,0,0,0,4,23,10,23,4,11,33,14,13,46,14,7,23,78,10,17,40,19,33,30,2,0,0,1,0,0,0,0,45,11,8,7,14,18,27,18,23,17,27,11,12,35,20,12,35,11,33,5,19,25,16,15,11,2,0,0,1,0,0,0,0,6,1,25,14,10,29,35,17,8,12,25,27,8,33,20,20,12,5,8,30,60,24,18,0,0,1,0,0,0,0,8,18,29,16,12,13,12,18,21,23,14,20,16,42,8,38,16,14,15,18,10,31,16,18,3,9,0,0,1,0,0,0,0,50,15,44,15,34,15,12,18,7,12,8,5,103,28,9,5,61,0,0,1,0,0,0,0,35,39,6,10,12,5,6,49,17,16,13,14,52,49,8,13,15,38,5,6,10,14,0,0,1,0,0,0,0,12,17,12,41,47,35,26,27,9,6,19,22,76,13,44,29,15,10,0,0,1,0,0,0,0,10,18,38,18,21,19,7,4,6,9,21,26,27,10,18,35,42,39,10,12,23,11,0,0,1,0,0,0,0,14,14,15,18,16,32,21,11,7,38,38,2,15,6,11,15,18,39,22,31,17,10,11,18,6,0,0,1,0,0,0,0,3,43,34,24,18,32,14,17,15,13,10,24,27,17,20,24,11,35,9,79,0,0,1,0,0,0,0,13,20,20,36,21,66,10,11,23,2,53,19,25,6,5,8,9,61,16,20,34,22,20,31,22,48,56,45,6,13,7,0,0,1,0,0,0,0,3,19,14,15,10,46,13,21,36,4,31,14,11,11,61,34,21,5,13,28,26,20,0,0,1,0,0,0,0,6,25,5,18,4,30,29,59,23,21,28,16,12,31,14,21,18,14,47,11,12,2,0,0,1,0,0,0,0,2,24,30,23,24,49,12,22,22,31,13,67,13,49,11,47,6,14,6,20,3,3,0,0,1,0,0,0,0,9,24,10,24,23,20,37,6,33,10,15,11,28,33,13,89,28,21,3,3,0,0,1,0,0,0,0,9,30,8,12,56,13,44,27,14,13,15,15,34,27,99,10,0,0,1,0,0,0,0,38,18,16,17,12,3,6,17,7,13,23,6,6,32,2,15,48,17,17,8,30,17,26,18,0,0,1,0,0,0,0,96,34,36,39,7,39,10,28,11,36,7,12,27,37,0,0,1,0,0,0,0,18,9,18,40,38,2,35,38,19,3,54,34,21,12,27,18,14,13,16,0,0,1,0,0,0,0,17,35,73,52,15,13,10,27,11,6,37,10,47,3,58,14,0,0,1,0,0,0,0,28,30,21,23,18,15,19,21,21,19,49,19,44,53,6,8,19,9,17,5,0,0,1,0,0,0,0,34,40,12,26,23,58,8,9,18,5,3,16,10,17,31,94,7,18,23,0,0,1,0,0,0,0,15,27,28,23,23,16,18,5,3,49,11,9,27,7,24,62,36,17,20,22,16,7,5,2,0,0,1,0,0,0,0,27,32,24,19,50,32,36,14,4,19,32,60,27,21,0,11,11,11,3,15,34,0,0,1,0,0,0,0,19,16,6,27,15,6,17,32,20,22,30,8,5,8,12,17,12,34,12,23,19,11,4,7,1,38,13,2,0,0,1,0,0,0,0,10,28,13,6,15,41,29,64,12,35,17,48,50,10,29,18,6,0,0,1,0,0,0,0,43,9,55,69,32,54,27,40,29,12,64,10,1,46,23,30,27,11,13,15,10,24,37,30,37,6,42,19,6,34,5,0,1,31,9,12,10,24,22,17,26,25,34,44,14,16,8,11,6,18,18,12,8,14,12,37,14,11,5,0,1,9,16,4,3,29,35,84,18,7,19,15,4,19,10,16,41,20,10,16,19,8,37,12,8,2,0,0,1,23,12,31,9,12,14,16,12,13,15,17,25,12,16,41,23,43,22,15,47,55,18,3,0,0,1,21,29,50,13,7,8,9,26,10,38,7,17,13,2,83,6,45,0,14,7,42,1,4,1,10,11,4,0,1,7,18,22,5,26,12,16,29,21,18,46,15,30,60,13,42,13,4,19,11,24,8,4,6,8,4,0,1,3,18,18,17,25,7,0,1,7,16,12,20,33,9,34,22,14,14,0,9,6,7,17,16,37,28,25,26,25,23,0,0,1,22,9,11,20,32,12,12,46,11,16,18,9,20,14,5,18,21,10,16,13,24,9,27,10,24,0,1,7,9,16,16,16,30,39,38,11,46,28,4,11,17,14,12,27,26,5,16,9,17,5,15,9,7,2,0,1,12,22,12,33,9,12,15,10,3,16,28,28,38,27,23,25,9,6,16,19,22,21,12,21,5,12,18,9,0,1,23,37,66,18,33,43,24,14,25,15,8,16,24,15,39,29,11,24,0,0,1,4,28,44,19,23,21,21,39,7,12,28,24,33,41,15,32,19,16,38,19,9,0,0,1,28,6,13,18,14,20,34,39,34,6,2,14,6,18,19,27,18,10,21,38,19,11,1,12,9,0,1,20,56,12,9,5,8,20,85,8,6,30,25,11,27,15,50,28,20,16,0,0,1,1,9,22,35,14,4,8,12,8,23,43,12,30,31,31,33,53,21,13,11,56,0,1,12,33,8,24,28,16,9,16,17,9,30,19,66,43,28,19,7,9,12,0,0,1,10,25,38,30,14,30,13,27,29,32,39,26,12,19,27,36,16,11,12,0,0,1,9,16,25,16,18,18,24,15,32,9,3,23,29,3,17,5,6,4,11,3,22,14,11,20,48,11,33,12,34,11,0,1,19,58,52,13,6,26,14,21,16,11,4,21,16,9,28,8,12,10,9,30,14,18,18,14,3,0,1,34,29,47,31,20,28,51,62,22,17,6,14,29,19,9,39,4,2,0,0,1,16,23,29,16,26,16,14,8,12,11,11,29,17,29,9,18,8,14,61,8,14,43,14,35,5,2,0,0,1,8,19,19,8,74,16,29,38,12,4,9,10,16,21,41,4,23,6,14,23,36,24,22,11,7,9,12,12,15,13,6,18,11,19,10,24,10,22,19,17,34,8,23,3,7,8,2,0,0,1,37,47,27,14,4,52,18,12,14,16,16,30,15,34,23,4,30,31,28,8,0,0,1,11,85,24,2,20,14,29,43,10,9,1,1,0,0,2,4,33,13,4,10,5,14,15,19,15,15,12,6,5,0,0,1,15,27,49,27,46,2,8,35,13,21,41,12,3,7,15,39,42,18,33,3,0,0,1,32,23,21,34,14,10,7,30,18,11,59,11,45,29,6,14,10,11,41,18,16,0,0,1,53,26,27,23,9,29,43,23,15,7,52,9,8,29,32,43,51,0,0,1,37,28,74,46,34,31,10,62,40,37,11,3,5,9,4,0,0,1,18,9,11,10,8,5,22,5,10,5,22,11,13,11,26,24,7,7,21,16,8,7,11,12,14,13,2,8,16,31,64,15,5,2,23,6,2,0,0,1,10,39,19,18,49,22,13,36,23,18,5,14,33,50,15,16,22,17,9,28,16,12,14,3,0,0,1,5,18,24,22,10,4,10,19,12,40,12,24,14,9,14,9,22,33,13,6,6,0,30,57,28,25,21,29,67,23,12,12,33,33,7,20,8,42,18,5,0,12,19,54,4,20,30,5,29,17,15,17,20,11,21,11,29,11,11,10,30,23,5,17,22,9,0,67,14,22,7,11,31,17,23,21,20,41,67,12,6,2,1,1,2,6,16,48,27,0,17,20,30,50,15,46,4,0,7,0,11,19,4,2,3,1,1,7,17,11,9,1,0,2,0,2,0,2,39,11,12,10,13,15,19,11,50,6,0,45,10,38,17,21,44,38,20,19,30,18,12,35,18,21,24,40,14,14,14,9,0,12,8,17,21,12,7,14,0,11,7,64,2,7,10,23,12,12,9,8,0,11,23,17,0,15,5,36,10,49,13,7,4,16,2,16,4,1,0,14,3,0,0,20,16,15,0,0,21,16,0,0,36,0,3,23,11,69,4,36,89,0,75,27,44,2,2,64,19,19,12,45,0,0,15,26,13,17,20,12,3,3,4,5,4,2,8,15,86,23,29,9,37,8,14,14,5,4,5,3,15,11,2,4,2,8,8,7,24,30,11,26,5,1,4,2,4,8,6,6,10,31,15,43,23,12,18,9,72,10,11,13,3,6,17,66,6,17,8,32,17,51,37,4,19,9,13,34,26,13,20,34,7,7,3,21,25,19,21,43,11,10,47,2,28,21,2,15,8,21,13,5,19,1,9,21,17,6,27,18,5,2,12,16,3,12,26,28,2,8,14,28,10,14,16,30,3,25,11,18,3,27,21,20,7,10,8,25,17,20,48,25,27,7,79,29,8,28,8,30,20,10,25,6,28,19,13,11,16,13,32,35,29,23,13,8,18,16,6,3,27,20,27,2,34,50,10,33,39,32,29,50,37,16,2,31,11,33,3,38,41,11,11,12,10,25,8,15,12,36,15,24,18,21,17,10,43,33,25,10,2,33,24,26,16,3,20,15,21,13,11,11,4,46,44,4,30,34,13,2,18,8,4,10,30,15,14,2,6,3,28,2,9,20,30,16,14,9,5,14,3,24,37,28,21,9,2,35,18,12,28,10,24,24,27,5,10,19,4,13,22,14,18,6,3,5,1,25,47,6,34,3,38,17,10,5,8,14,12,4,9,9,11,15,15,29,2,13,18,19,13,2,7,28,17,21,14,6,21,11,5,23,10,31,30,10,22,12,16,34,9,16,3,8,1,4,6,14,6,10,12,14,30,13,49,23,10,34,40,16,20,6,45,12,30,6,27,27,16,22,1,14,11,16,47,65,20,18,1,26,29,34,17,40,34,40,13,18,10,37,17,38,31,19,48,16,15,28,9,16,12,27,14,38,20,1,14,12,24,23,19,9,13,12,8,4,12,1,10,9,7,13,2,23,18,11,14,6,19,16,18,24,15,20,14,8,23,2,4,21,3,9,11,6,15,22,16,12,7,9,6,4,4,11,24,14,18,18,27,9,11,11,25,1,13,16,2,18,5,1,31,24,21,6,11,23,3,36,16,29,45,20,19,22,19,9,16,26,2,21,34,11,12,31,9,3,7,21,26,5,6,3,10,9,17,17,20,5,8,4,9,14,15,25,8,52,21,15,24,21,4,25,9,26,17,19,22,3,21,12,12,10,3,9,17,13,12,5,7,30,27,14,2,6,7,5,3,26,36,3,2,12,32,2,10,21,19,13,2,25,2,17,14,19,15,22,3,14,22,16,3,7,3,11,2,11,26,17,28,21,20,24,12,11,8,12,14,1,4,10,14,1,6,11,12,12,42,10,4,27,13,17,2,23,10,35,2,14,2,15,11,9,1,5,4,14,16,6,9,8,15,2,6,25,3,23,23,25,10,3,24,22,4,8,31,30,11,10,22,23,2,4,10,2,7,13,2,3,12,1,17,13,24,29,44,17,2,10,2,4,20,2,42,4,10,18,2,18,3,54,7,11,2,33,7,19,12,6,15,4,25,38,27,22,3,20,27,21,1,11,27,11,12,2,13,11,23,22,33,19,49,32,21,2,9,28,8,14,9,25,36,12,19,21,15,15,34,25,16,6,5,15,12,24,14,18,11,17,10,8,20,14,19,14,28,30,12,21,23,1,11,10,6,25,10,13,20,17,29,10,31,7,5,4,11,8,2,23,12,9,20,18,3,14,12,6,4,16,11,14,17,22,6,32,11,13,1,35,17,7,8,7,18,9,24,12,10,34,7,16,2,20,18,18,14,22,33,20,23,32,10,18,27,13,40,18,11,27,26,12,28,7,13,16,22,9,6,29,7,16,54,26,31,24,37,2,34,11,44,18,20,38,18,2,41,46,25,30,2,18,39,30,45,46,13,22,33,46,26,26,20,5,14,5,23,26,23,14,32,48,5,16,27,17,25,10,12,12,19,13,25,12,7,18,17,25,12,17,28,7,17,31,17,35,26,11,22,44,5,5,41,11,8,3,25,57,6,2,12,10,8,26,10,31,30,2,14,23,20,2,40,26,2,18,14,18,2,8,2,12,2,2,15,7,2,10,23,7,2,13,17,10,16,2,6,41,5,11,2,40,4,20,14,20,13,2,27,4,2,19,2,9,4,18,46,25,2,57,20,30,16,9,19,23,8,3,18,43,8,20,22,39,21,22,23,11,28,21,23,35,6,24,27,22,35,19,22,13,46,21,35,30,37,27,18,7,3,30,22,42,27,14,8,28,44,23,14,18,10,40,1,22,18,13,16,13,12,31,20,26,24,11,13,18,18,50,18,8,24,19,27,12,37,9,27,14,33,33,17,15,39,32,10,12,20,25,20,9,35,9,16,28,55,41,106,28,8,28,15,16,18,12,25,17,60,37,21,8,25,45,18,23,40,2,26,22,39,9,3,21,15,4,26,40,3,8,2,6,17,36,19,2,17,7,9,16,26,5,57,17,5,2,15,6,6,27,29,6,2,23,34,22,12,1,21,13,4,12,3,16,12,6,1,7,15,13,16,40,5,7,2,9,23,22,3,13,29,15,22,2,20,24,21,20,12,31,20,30,15,13,4,11,8,19,30,21,3,37,26,17,30,16,8,7,1,10,11,6,9,15,20,10,2,4,7,41,18,76,14,3,15,18,4,28,27,27,14,32,27,19,43,29,20,74,2,27,7,1,31,13,12,4,35,5,16,21,22,2,58,8,36,24,35,18,10,9,7,3,12,15,14,26,21,7,6,5,21,44,18,1,7,6,19,3,42,2,15,26,31,4,7,2,37,12,2,44,8,9,3,24,12,17,1,6,2,12,7,4,7,2,8,13,3,15,17,2,10,2,5,3,14,4,43,18,9,1,22,21,12,15,11,7,4,30,13,20,3,32,10,13,2,24,13,6,9,29,12,7,4,3,9,8,17,10,3,11,23,12,2,29,3,14,34,10,15,28,4,25,22,11,4,26,2,12,17,16,20,4,19,42,25,37,2,33,2,19,8,11,7,9,12,18,15,16,8,4,11,7,15,8,9,58,11,8,2,4,12,38,3,2,21,43,1,32,16,35,15,17,19,2,32,12,10,23,18,24,47,11,3,24,30,4,25,14,9,1,29,10,19,46,3,9,17,20,22,3,8,31,19,18,27,13,9,14,15,7,15,14,3,31,2,29,34,9,2,31,17,27,18,8,41,20,23,24,15,59,29,46,2,75,38,30,19,28,62,18,74,48,43,8,18,24,18,23,4,3,19,12,36,20,16,24,6,21,15,18,18,24,19,7,7,7,18,27,12,36,18,14,21,9,15,11,20,4,17,22,33,13,11,14,18,13,15,36,21,17,8,5,23,35,14,16,13,17,17,11,21,9,34,12,11,13,29,4,7,19,11,34,2,22,11,5,5,17,2,42,23,20,7,12,4,22,2,45,18,3,8,23,8,8,14,25,8,11,17,21,14,5,7,22,10,14,45,23,23,19,15,24,2,17,14,44,32,15,35,8,2,59,6,31,39,21,31,19,4,42,24,26,2,34,6,10,31,3,8,12,13,6,11,11,15,2,8,17,11,2,20,34,25,18,28,2,22,118,2,36,25,40,20,3,29,8,13,20,18,8,3,24,31,8,5,22,16,20,11,10,5,24,25,7,12,9,1,23,34,12,6,8,13,15,21,11,16,8,22,31,14,2,12,22,23,24,21,44,4,2,6,15,14,13,13,25,35,13,3,20,17,24,5,17,2,9,6,6,10,12,8,27,4,19,13,8,18,19,30,2,20,21,2,7,79,19,15,44,13,3,6,17,25,16,6,10,11,13,5,40,13,17,7,11,7,32,29,15,13,8,14,4,6,16,5,6,7,13,20,14,5,10,3,5,17,6,15,14,25,19,17,26,47,6,4,15,26,37,25,10,8,14,11,21,1,9,21,4,29,24,22,18,2,18,11,18,19,21,18,4,18,27,36,9,10,3,17,35,13,10,58,16,3,45,2,14,14,10,2,28,34,12,3,9,17,20,4,13,15,48,38,10,33,17,21,9,9,2,30,33,12,4,26,6,25,22,14,7,3,28,55,8,15,18,13,3,13,39,20,23,2,13,5,36,10,2,27,27,21,12,2,18,31,4,17,5,3,16,23,4,18,16,15,1,10,36,14,21,49,14,11,14,7,18,15,24,3,4,20,2,32,16,6,5,12,23,4,19,11,10,21,2,23,22,2,17,11,2,26,2,24,3,39,14,10,16,5,7,17,30,25,1,7,5,13,21,10,13,15,12,11,12,19,14,14,13,18,8,16,33,6,9,4,12,1,13,1,13,2,9,12,0,14,2,11,7,23,1,13,3,10,1,7,2,11,6,14,2,13,12,2,9,1,8,2,12,4,8,5,2,20,22,1,11,2,8,2,14,10,2,8,1,15,2,11,12,1,25,2,7,4,10,3,11,2,10,1,16,2,7,1,8,2,19,11,2,13,2,10,2,13,3,16,13,2,7,5,9,3,19,13,2,25,4,25,19,25,4,30,4,45,1,11,6,6,1,26,4,9,39,0,2,2,36,2,31,10,7,10,1,22,29,11,22,7,7,14,7,11,33,31,2,2,26,1,18,13,2,27,4,13,3,3,6,24,3,13,21,2,20,6,2,10,10,12,1,7,16,14,7,1,20,17,25,12,2,30,13,40,11,12,2,9,11,22,5,22,11,11,2,16,20,28,2,11,16,25,3,14,30,25,27,27,8,19,24,1,31,11,26,7,15,18,14,1,26,14,5,18,23,18,37,21,20,23,8,6,10,24,17,39,41,11,16,15,14,6,3,4,19,2,11,2,14,1,15,2,7,2,5,10,2,8,2,8,6,2,9,4,14,2,9,1,9,2,15,1,11,2,9,3,8,3,15,10,2,10,3,15,13,12,4,1,5,2,17,2,6,2,8,12,3,8,4,19,25,1,8,19,17,9,23,6,24,9,5,11,13,2,23,14,2,11,9,10,9,18,11,40,3,11,9,16,13,16,21,2,44,1,17,13,19,17,16,10,6,9,5,4,39,35,3,23,22,3,36,10,1,23,3,22,19,23,17,2,28,16,2,12,10,24,6,23,11,4,48,27,23,29,17,17,18,18,39,15,10,4,16,2,20,26,5,14,6,21,16,13,2,14,32,7,2,19,25,19,2,22,19,2,11,1,17,42,1,31,13,2,28,32,13,2,23,30,10,19,2,10,6,3,28,19,20,27,41,25,31,45,4,15,2,21,24,36,1,23,26,1,24,23,12,2,35,27,16,2,17,24,7,1,7,19,13,14,3,27,6,23,25,14,23,3,11,4,12,10,20,14,26,13,34,17,6,3,46,4,32,24,20,36,12,11,6,6,3,16,16,11,14,2,25,23,13,15,2,8,29,13,31,13,24,4,13,9,8,20,3,9,35,22,11,16,15,9,2,49,28,3,46,26,3,13,12,18,22,17,3,7,13,8,13,11,16,6,7,9,16,17,6,16,1,31,3,19,23,53,15,33,2,13,6,4,27,1,14,3,15,2,12,3,20,2,18,10,32,19,3,24,42,42,23,20,9,9,30,11,36,32,36,31,59,48,23,13,17,17,21,23,28,17,29,19,22,19,32,19,14,19,29,20,3,15,25,30,44,29,16,21,4,15,18,6,24,39,4,35,42,44,52,17,14,16,28,47,21,4,32,48,2,13,63,7,16,31,33,3,6,8,12,6,18,20,4,23,23,40,21,6,4,19,45,31,21,3,63,20,75,32,4,8,2,13,2,15,12,26,2,18,1,8,9,2,19,1,12,14,2,8,6,2,18,2,8,5,17,2,7,16,2,13,1,8,17,2,9,4,12,2,2,6,3,7,1,10,2,7,2,8,12,9,4,32,2,17,2,8,15,4,10,6,3,15,2,11,1,6,1,6,8,11,2,11,11,4,10,4,15,2,16,15,9,2,12,3,7,2,13,2,13,2,28,2,7,2,20,12,1,9,3,11,3,14,2,2,14,4,8,10,10,10,1,8,2,16,1,13,3,12,2,8,4,9,4,12,5,2,19,5,3,15,1,7,2,10,2,15,2,9,3,2,6,1,8,3,3,17,4,21,2,10,9,9,7,2,16,2,16,1,12,2,11,1,6,17,12,4,6,14,13,1,9,1,7,2,4,1,19,3,8,8,12,2,13,7,4,3,24,2,10,14,1,13,3,11,13,3,10,5,21,3,22,5,2,3,6,9,23,6,2,14,15,11,2,22,14,12,17,21,13,6,18,12,26,6,2,13,31,22,6,36,2,33,2,24,57,3,16,7,10,15,2,11,14,9,13,17,31,16,18,3,36,20,2,19,14,2,24,2,4,7,5,8,9,12,16,30,3,11,5,13,5,21,31,24,13,4,16,2,9,6,23,3,40,2,13,7,0,19,18,26,2,30,37,13,3,34,21,13,16,3,35,34,26,2,20,24,2,13,18,5,10,34,2,21,3,19,16,2,16,8,1,15,2,41,14,17,4,23,13,6,25,18,4,17,10,14,14,22,2,17,23,9,2,18,17,11,14,8,12,24,4,63,2,29,31,21,28,12,28,3,11,12,9,11,7,5,15,5,12,13,6,23,10,38,11,7,14,7,12,7,25,20,28,3,35,37,13,30,28,74,6,13,24,35,27,20,10,30,29,16,28,29,11,10,21,18,19,21,21,14,20,15,36,16,11,21,11,17,14,13,20,1,13,26,31,13,26,50,22,14,15,6,0,0,24,35,53,54,60,3,1,21,20,21,38,36,30,23,16,3,10,17,12,2,18,55,2,0,9,5,24,18,30,29,53,7,14,3,2,29,11,4,16,35,8,6,24,9,79,52,23,14,11,2,14,7,17,33,15,21,11,7,5,6,7,10,7,11,3,22,1,14,11,25,2,34,3,32,22,8,70,1,5,2,31,10,8,12,2,7,13,3,31,11,2,24,19,2,15,19,2,47,3,18,7,22,19,1,22,7,10,27,21,3,9,14,2,27,12,10,2,18,7,2,13,15,3,6,25,3,21,2,31,25,16,6,39,20,6,25,15,29,18,26,17,30,21,6,13,18,28,8,1,16,14,18,16,5,16,16,4,16,29,15,10,24,18,2,48,11,29,3,3,25,23,7,21,14,41,47,56,25,34,13,3,5,41,38,9,7,11,1,15,2,12,2,4,7,9,7,23,14,23,3,17,2,12,3,14,3,23,3,11,4,34,18,15,23,1,9,15,13,2,13,3,11,2,16,88,21,18,3,13,2,12,25,3,26,36,23,3,20,5,20,4,2,7,16,6,26,8,2,15,2,17,2,6,16,19,2,9,6,4,18,12,4,14,5,1,10,19,2,12,23,17,2,6,2,21,3,30,1,19,15,2,24,8,3,18,13,1,10,10,3,20,2,19,2,13,8,9,2,17,5,15,10,25,1,13,10,15,2,6,13,15,5,30,3,8,10,4,23,24,40,26,21,2,31,16,24,29,4,3,33,23,3,19,20,24,22,5,14,12,8,12,19,2,12,12,9,12,20,36,26,17,5,31,8,21,57,14,15,33,25,4,41,36,11,12,7,6,1,5,18,13,5,2,5,9,12,18,30,8,22,5,7,6,5,24,12,22,3,39,50,36,63,25,2,4,6,4,29,3,29,13,13,1,2,23,2,15,2,24,25,3,14,2,9,11,8,3,15,4,20,3,23,27,3,17,14,8,7,2,23,20,14,13,15,23,15,22,21,23,16,6,19,29,14,18,16,26,26,17,15,2,13,30,7,3,27,3,20,23,1,11,7,4,25,11,4,32,20,6,9,5,23,39,36,13,1,12,8,2,23,13,2,7,31,4,41,3,20,18,4,53,46,11,9,7,20,36,9,12,3,2,25,1,7,32,3,18,3,44,3,10,2,12,4,19,8,39,36,12,4,30,27,17,32,2,10,2,8,5,16,15,2,26,2,5,2,5,2,27,31,38,26,8,32,161,3,17,11,3,43,12,4,34,3,59,2,45,2,20,3,2,30,21,3,32,4,9,12,12,8,8,3,12,15,2,13,2,15,21,6,2,6,5,19,7,2,22,34,7,17,15,2,22,24,7,3,2,18,11,8,4,11,2,27,8,2,20,2,10,2,32,4,11,6,25,17,14,1,17,6,18,11,89,3,36,23,40,36,19,17,35,9,8,16,19,77,7,25,5,44,17,16,12,12,9,37,49,74,24,13,58,27,3,23,30,58,1,36,29,37,6,10,32,35,12,20,18,17,2,7,17,59,14,2,29,38,9,2,36,13,15,22,2,33,20,39,13,6,6,51,15,34,15,11,62,2,56,3,15,3,15,28,3,46,7,19,3,35,15,28,2,39,7,2,24,27,18,62,3,31,22,9,4,9,8,2,24,20,5,3,15,3,17,3,26,4,16,4,29,2,14,2,21,2,26,2,25,2,2,12,17,20,8,2,24,5,2,26,3,16,14,11,8,3,25,28,10,3,31,3,10,3,23,34,11,21,12,2,20,31,21,10,7,2,26,17,2,18,4,30,8,2,12,3,32,2,14,14,12,3,27,4,20,22,1,4,24,31,20,22,22,18,2,37,26,27,4,23,15,15,14,5,43,3,15,46,7,7,31,10,33,34,29,24,12,18,17,12,15,8,31,77,12,2,22,15,45,13,16,19,30,41,28,2,18,33,18,4,19,36,21,45,10,5,17,7,46,4,24,5,23,13,17,16,23,43,31,17,54,31,13,9,2,19,22,11,18,21,25,21,29,24,20,2,27,41,18,2,14,10,14,15,5,3,28,13,3,9,3,24,44,2,17,3,46,2,15,4,3,2,1,15,3,27,5,4,32,2,20,4,18,2,13,3,20,22,4,13,3,10,2,15,5,14,1,8,1,10,1,12,37,12,2,15,8,2,12,3,2,15,1,26,6,3,16,5,21,12,4,8,6,20,1,8,11,10,2,10,2,20,1,13,5,19,39,9,10,16,26,6,14,40,2,26,3,20,10,9,4,17,13,1,17,21,8,2,23,14,7,3,15,7,16,4,23,1,11,2,9,30,23,2,17,19,11,19,3,11,24,5,3,31,3,27,2,40,7,29,2,29,19,3,15,8,2,21,2,8,10,12,3,30,6,4,29,15,6,33,11,8,32,19,7,17,3,19,2,24,5,19,11,11,4,16,57,2,2,35,2,19,35,2,17,3,13,2,8,20,18,19,37,4,13,9,3,9,3,8,2,18,2,5,10,2,22,9,2,33,3,11,36,30,19,14,33,7,1,4,29,22,29,19,31,41,18,13,38,28,41,55,28,4,42,2,21,5,20,0,12,8,2,10,30,22,9,6,13,6,8,10,15,12,32,6,3,3,34,12,37,25,5,28,14,1,15,17,6,12,29,20,15,3,24,16,2,23,2,14,3,43,2,7,4,4,11,14,18,25,31,3,10,8,2,28,2,6,9,4,30,9,24,16,11,23,2,16,10,5,2,5,9,2,9,1,1,48,9,10,4,2,22,2,18,2,52,1,5,12,4,2,17,10,5,52,3,11,2,15,2,11,3,24,2,14,3,9,4,19,5,17,13,9,15,15,3,7,1,7,34,8,15,7,1,7,15,12,8,2,20,17,1,12,8,4,12,3,9,1,8,3,2,4,18,16,8,13,5,2,15,8,22,1,6,2,1,18,9,28,6,2,9,7,11,10,2,15,18,5,15,2,8,0,2,12,1,26,19,2,16,4,20,14,3,16,2,9,3,25,27,2,4,4,12,8,19,15,6,2,9,4,14,5,5,12,12,12,23,13,8,14,4,0,9,5,8,5,10,22,11,8,4,3,11,16,14,6,10,11,5,14,10,11,12,2,2,10,6,9,3,6,10,15,5,7,4,4,3,1,4,6,14,2,14,15,17,3,8,5,8,12,18,3,10,15,30,69,4,38,19,2,46,23,45,28,22,20,14,28,19,2,33,22,21,16,8,12,14,33,9,12,18,3,18,11,1,13,22,33,5,3,15,37,10,24,10,20,13,31,2,16,15,13,12,2,45,50,3,9,10,31,14,11,21,8,22,2,3,64,36,13,2,10,2,18,4,28,15,16,22,3,22,11,12,2,4,11,31,16,13,15,17,11,9,13,12,24,15,18,19,39,17,38,4,19,9,1,3,3,2,8,2,1,8,16,15,12,1,64,15,2,24,0,11,2,26,13,18,12,17,27,19,10,21,35,25,11,25,21,34,18,29,5,20,9,32,18,11,5,8,5,11,1,12,6,21,22,13,0,15,9,10,8,15,15,8,13,4,26,22,27,17,23,9,33,10,3,25,17,15,8,2,42,20,14,10,13,23,13,12,4,26,26,7,33,12,3,15,25,24,24,19,25,11,3,41,22,21,6,1,23,14,2,12,16,6,4,22,39,41,14,14,13,19,1,4,8,18,1,11,6,14,8,21,22,15,44,18,24,14,20,17,13,17,11,15,8,24,30,25,16,40,2,5,18,8,2,15,11,3,14,4,5,16,9,20,2,8,2,8,36,9,15,6,35,29,19,18,2,17,31,17,12,37,12,3,14,3,2,2,0,2,8,19,16,14,1,5,14,10,20,2,16,16,23,37,18,4,28,9,2,21,3,21,3,19,26,2,8,14,2,13,17,21,2,9,10,8,14,8,10,13,2,12,11,18,2,12,7,4,3,2,7,5,9,11,20,16,23,15,16,4,25,18,19,10,32,11,2,6,2,16,36,16,7,22,36,11,2,31,55,13,30,28,7,2,17,21,2,16,2,1,24,1,16,8,7,4,3,13,12,15,3,3,4,4,17,9,18,10,0,2,10,13,20,13,25,38,6,2,24,21,7,9,2,4,8,9,8,1,5,2,16,30,12,5,2,35,22,37,15,37,27,3,27,41,15,19,2,12,10,14,19,14,3,11,13,3,15,22,23,4,9,19,17,2,23,10,17,9,15,16,10,2,16,11,2,22,20,27,1,7,10,11,14,3,11,13,11,9,5,9,25,1,4,1,1,1,2,12,6,2,29,13,7,1,23,33,16,4,3,8,27,18,59,29,3,42,8,3,20,6,10,3,13,3,2,40,17,2,27,11,2,11,22,3,16,21,1,19,11,19,18,11,2,8,1,22,12,3,9,27,45,9,21,13,2,10,16,18,16,12,13,13,6,2,12,2,13,12,3,14,1,17,9,17,7,8,2,18,3,19,16,4,15,15,8,11,1,16,19,5,14,29,10,12,15,2,25,6,16,70,4,14,11,7,8,2,26,4,2,12,1,21,43,13,16,24,15,7,19,12,16,17,12,7,4,9,8,1,14,2,12,6,14,26,31,4,4,15,27,36,2,8,25,36,11,2,9,5,1,8,53,6,3,18,12,18,22,8,18,12,20,10,10,1,19,26,13,10,7,10,7,34,17,17,2,27,2,20,22,20,9,8,2,7,3,7,3,13,2,10,2,12,4,2,9,12,2,22,18,4,11,20,14,3,25,2,18,16,9,7,2,9,5,2,15,8,14,16,25,2,10,8,4,14,8,23,5,3,3,4,2,16,12,2,6,29,10,7,5,2,10,13,4,2,12,30,11,8,20,1,34,9,11,20,23,24,1,12,2,45,21,2,13,11,8,13,3,36,27,18,15,6,14,2,14,21,3,38,16,2,10,33,2,29,2,2,4,9,2,12,17,2,20,11,3,22,27,8,2,23,3,3,3,3,4,2,7,9,50,21,17,16,15,4,34,13,28,20,18,30,67,2,14,10,5,2,2,2,2,5,16,9,33,58,4,25,16,14,22,4,8,28,31,20,28,15,11,18,32,39,6,14,8,3,5,23,2,40,25,2,21,1,15,2,13,7,7,23,35,38,18,19,13,40,4,3,14,16,15,12,18,7,8,14,19,24,3,15,14,12,18,7,11,6,11,16,29,33,2,17,11,24,48,2,13,9,6,12,6,35,9,15,9,17,1,12,56,2,18,24,6,4,9,8,14,16,45,6,3,33,29,10,17,11,49,20,16,3,26,40,16,54,22,25,28,69,18,12,35,2,16,8,3,13,2,12,8,1,30,9,2,18,34,7,2,14,8,10,4,40,4,19,11,2,11,2,22,13,2,44,8,2,11,2,17,5,5,11,1,3,12,4,2,6,2,4,9,5,2,8,13,1,6,4,2,8,25,9,44,14,19,5,13,27,2,2,13,0,2,25,12,12,14,10,35,11,1,17,16,9,6,8,6,13,2,12,5,20,15,3,1,2,2,3,4,8,4,6,16,4,4,5,6,19,9,11,6,16,46,10,54,6,21,2,20,6,77,23,48,35,78,43,20,39,54,22,19,11,18,26,13,21,40,15,3,6,5,11,24,24,32,11,20,9,2,17,2,17,13,5,19,6,12,10,2,13,16,8,15,59,9,12,15,3,5,14,46,6,2,10,5,2,17,4,16,13,2,31,11,13,7,2,37,26,1,28,9,2,21,10,18,5,3,10,16,0,1,11,30,9,2,13,4,8,6,7,5,26,22,13,3,6,2,23,6,17,17,7,9,2,4,22,35,23,2,10,2,13,17,13,19,2,10,3,1,15,2,19,2,18,1,0,2,4,3,14,3,6,13,6,1,12,2,6,9,4,1,21,7,1,11,21,2,17,3,12,3,2,20,22,10,32,12,22,8,10,1,12,6,12,9,1,22,25,20,3,9,19,14,13,22,11,7,33,14,12,8,1,5,39,25,2,9,12,12,16,2,10,23,32,27,29,22,36,30,4,36,29,2,13,10,2,21,1,8,3,4,26,3,43,20,39,14,3,16,11,11,69,3,17,21,5,20,10,20,22,2,11,1,33,5,13,84,50,19,16,12,11,3,15,16,13,22,13,7,37,35,19,3,8,81,1,35,23,17,3,13,7,50,10,28,10,30,33,42,9,14,3,22,13,8,19,20,6,26,7,43,15,13,32,5,7,23,18,45,2,24,3,7,20,6,6,42,11,20,3,26,35,3,18,31,7,2,11,2,11,2,18,13,4,9,21,29,6,13,41,16,22,22,3,12,23,10,15,18,9,2,23,26,7,32,17,2,21,21,5,16,10,22,53,2,23,18,3,11,9,27,11,2,12,6,21,9,7,2,10,4,26,1,34,13,13,2,9,24,2,16,7,3,7,7,1,14,10,16,13,13,28,7,12,2,19,4,12,22,2,15,11,11,2,14,2,9,13,2,37,2,20,5,3,7,14,28,2,18,8,5,8,17,13,16,10,2,10,4,9,2,32,5,21,38,8,6,2,10,23,11,1,23,1,13,5,15,7,2,11,2,5,14,7,9,8,2,11,13,4,25,13,9,1,3,7,15,8,2,22,3,24,22,9,5,3,9,3,8,2,6,1,5,8,1,2,16,10,2,11,55,2,21,3,5,2,10,2,15,6,3,13,17,11,3,12,16,3,14,10,2,15,2,8,2,4,2,6,8,9,2,17,27,13,9,30,22,21,3,12,3,4,2,2,3,6,2,4,16,8,8,8,13,8,9,10,4,17,20,5,7,4,4,5,5,11,2,16,2,7,1,0,0],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of word counts within data\"},\"xaxis\":{\"title\":{\"text\":\"Word Count\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9c9a8ec9-8a4e-424d-880c-c71c71463962');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences with word length of greater than 3.0 and less than 25.0 includes 64.76% of the whole!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "last step we will remove senteces of length 0."
      ],
      "metadata": {
        "id": "ChrkVbIviJ-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data[\"sentence_len_by_words\"]>0]\n",
        "data.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "BTdFRRFeiJEU"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distributions.full_df_run(data,minmax=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "gqje0XHYjBZ6",
        "outputId": "af1795b2-7e6e-4898-9246-9f923d593d48"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"39e23109-4226-47af-a4aa-d4fd92ef8eb8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"39e23109-4226-47af-a4aa-d4fd92ef8eb8\")) {                    Plotly.newPlot(                        \"39e23109-4226-47af-a4aa-d4fd92ef8eb8\",                        [{\"x\":[3,15,14,25,26,27,21,1,16,21,20,11,23,10,16,3,7,19,10,20,32,14,21,9,13,29,18,46,15,17,8,15,10,23,23,21,13,28,14,39,7,10,18,39,25,27,7,6,12,33,12,16,6,8,23,7,5,11,21,27,11,30,27,8,11,8,38,2,12,16,9,6,10,12,7,18,9,20,17,22,27,8,26,13,11,11,12,15,22,15,9,27,13,27,17,17,8,10,17,19,25,20,22,24,29,2,14,10,17,12,23,12,19,12,12,23,13,11,27,10,11,3,2,5,11,5,24,20,12,15,9,16,10,12,26,8,3,13,7,15,15,7,14,18,4,12,8,6,12,8,20,4,10,2,22,32,24,3,9,12,35,6,19,17,20,7,6,5,13,10,10,8,6,6,8,13,13,13,20,6,9,9,8,7,22,25,26,10,7,6,2,16,40,17,14,16,19,24,23,19,12,14,17,15,16,4,9,25,37,22,18,2,4,6,2,11,12,18,13,25,6,18,16,10,18,11,15,9,8,15,15,18,12,6,12,5,23,6,12,11,31,13,22,31,9,18,18,16,5,9,15,35,11,15,8,10,1,11,15,12,12,5,4,6,21,8,5,18,12,12,17,8,3,7,9,15,10,29,18,8,17,18,9,4,17,9,10,3,6,8,8,7,23,10,13,16,6,2,5,15,19,7,15,9,24,9,14,16,24,20,15,6,9,10,15,10,17,14,3,7,2,17,22,10,14,12,5,23,18,26,11,15,20,21,3,5,15,13,12,16,5,3,32,23,5,10,13,7,13,11,10,34,22,12,16,5,20,21,9,15,23,7,7,19,6,5,15,20,7,1,11,7,15,4,14,11,15,10,16,10,22,4,19,22,15,13,27,16,22,20,13,14,8,16,24,9,22,3,31,50,16,23,18,18,11,19,20,15,24,26,15,16,25,5,17,6,15,5,12,15,16,10,17,5,32,7,13,1,13,16,23,9,1,6,10,6,15,3,34,12,9,22,24,15,12,4,8,11,13,8,18,9,8,8,25,6,6,16,18,22,23,11,14,17,8,5,15,8,1,15,13,1,2,4,26,1,21,8,3,6,21,16,10,12,11,8,3,16,20,16,11,16,16,19,10,1,6,19,11,6,11,8,15,11,22,5,30,14,7,9,34,38,6,18,19,11,12,2,18,26,9,30,17,20,3,17,5,15,21,16,12,10,14,5,12,8,7,22,8,7,8,19,24,10,15,15,20,4,2,23,16,16,9,17,8,15,36,13,27,12,40,26,18,26,13,25,7,10,30,17,36,5,13,11,27,21,17,10,10,6,27,7,2,35,53,22,17,41,9,9,16,10,8,16,21,28,7,14,9,19,41,19,16,14,14,24,5,12,22,20,13,15,22,6,21,11,32,9,27,20,5,75,17,27,11,20,8,32,16,6,17,13,8,6,41,9,18,8,28,13,37,13,18,22,22,14,30,10,15,20,12,11,19,20,19,11,17,4,10,16,8,13,2,12,23,30,26,14,20,25,19,11,17,18,5,16,7,15,7,16,9,12,2,19,12,16,11,10,5,11,6,21,23,11,12,21,17,6,18,17,10,27,16,12,10,3,10,7,6,13,3,5,7,11,8,11,22,9,20,10,23,19,13,10,14,11,11,10,11,17,7,8,6,26,8,4,15,11,6,26,13,6,8,4,32,20,3,9,17,13,6,17,16,6,14,27,3,9,19,10,4,9,1,2,1,8,10,8,2,6,14,14,3,17,14,6,4,1,1,16,26,2,2,12,14,5,13,21,12,16,7,4,6,14,14,4,9,11,3,9,1,23,7,3,1,9,9,27,23,16,2,11,14,3,17,21,22,13,10,14,9,5,5,1,4,4,3,3,8,10,10,4,14,13,13,7,14,10,8,6,9,1,8,4,6,16,23,1,14,13,25,12,10,4,18,7,7,11,16,1,14,17,24,11,22,22,8,16,3,22,18,2,10,16,16,12,32,1,16,1,3,10,5,13,14,19,14,15,14,16,1,12,12,4,16,1,13,16,9,8,11,9,17,9,21,13,8,25,7,10,12,9,16,23,35,12,12,8,11,39,10,14,24,10,7,9,14,14,10,21,6,10,6,13,6,9,11,6,21,11,24,16,6,18,5,12,9,8,9,8,13,10,15,5,8,23,19,17,16,11,12,20,12,10,18,6,11,4,6,16,3,8,7,20,12,7,11,8,8,12,10,14,17,26,21,21,8,12,8,8,10,11,4,10,18,9,5,12,17,10,11,21,11,3,7,18,10,19,19,19,13,20,8,20,10,2,19,19,2,12,30,10,15,13,6,10,13,12,5,2,21,26,26,18,29,27,20,30,23,19,13,30,19,6,11,32,1,5,17,24,8,15,11,8,12,23,6,17,13,11,16,14,14,2,21,10,12,7,17,28,4,5,6,17,12,16,22,6,12,4,11,3,18,17,23,4,9,16,13,12,23,11,19,10,9,41,21,18,20,36,5,8,13,14,7,5,5,21,8,10,16,4,17,15,6,16,15,32,19,27,2,28,17,24,5,33,9,12,4,20,13,19,6,16,15,24,14,14,13,22,18,20,15,9,6,10,6,15,9,3,12,22,16,14,8,9,40,27,10,8,14,38,29,14,15,5,42,13,16,10,5,28,5,9,12,11,12,8,9,16,13,6,13,4,13,14,10,21,30,10,2,12,36,12,7,22,9,10,13,7,7,7,7,11,14,18,6,28,12,9,21,19,9,16,15,15,21,28,4,27,13,22,22,8,8,17,5,13,5,14,6,13,3,14,6,5,8,9,9,39,10,6,26,9,16,14,13,10,16,23,3,17,15,19,10,8,16,15,10,6,7,11,4,17,1,14,14,10,14,13,19,10,14,10,13,36,21,14,12,9,13,17,5,20,9,15,14,8,8,17,12,26,22,16,22,31,23,11,20,30,23,27,12,13,28,37,8,15,10,3,4,13,4,8,12,17,6,12,30,9,7,10,6,4,33,5,30,7,16,5,14,12,13,14,17,32,9,8,10,13,18,6,15,32,26,18,31,14,8,5,2,8,16,18,8,10,10,17,4,9,29,16,24,26,21,8,35,1,2,7,4,18,15,5,9,13,27,14,5,6,7,14,13,15,10,6,4,11,21,12,2,23,8,7,3,17,8,11,1,13,4,16,12,19,6,16,13,5,24,20,14,19,16,13,11,14,9,10,14,3,9,27,13,7,18,7,14,7,6,15,9,17,6,12,13,12,22,12,20,13,17,5,7,10,11,22,23,7,16,16,10,12,19,8,19,10,5,7,3,8,9,8,9,13,16,3,7,15,6,3,18,23,6,8,8,17,11,10,6,11,1,3,6,15,8,21,18,6,15,7,5,6,11,14,12,15,9,10,5,11,13,5,9,3,5,4,7,20,25,7,11,12,22,7,5,11,10,10,26,13,15,14,11,22,10,16,34,16,7,10,14,6,2,28,3,7,6,9,11,16,22,16,33,10,5,7,15,5,17,7,5,5,11,10,10,8,5,8,18,6,5,7,8,7,23,5,2,10,6,11,14,13,19,9,10,11,23,6,19,9,8,12,11,16,10,20,14,6,15,3,15,13,13,12,13,31,13,19,23,8,13,11,32,18,17,16,6,54,16,17,21,11,12,1,10,9,5,15,6,3,8,33,16,18,6,9,5,13,9,8,12,30,10,17,7,4,13,6,22,10,7,9,3,11,3,16,30,20,35,16,9,19,40,13,16,17,4,13,14,9,9,12,10,36,18,5,21,23,17,20,4,18,16,9,9,16,11,14,22,6,12,12,17,5,13,10,19,24,20,10,6,11,8,15,11,20,6,31,12,14,8,5,3,19,11,9,5,10,10,12,15,6,30,11,22,14,22,10,17,19,22,30,6,18,17,31,22,3,13,32,8,14,7,11,14,33,3,27,18,12,30,18,19,29,34,15,15,6,21,8,17,22,6,10,21,4,7,22,4,19,33,1,43,21,7,14,21,9,17,8,28,19,5,14,31,14,19,10,18,20,12,4,17,13,27,13,18,10,4,7,17,8,10,4,17,10,15,29,41,11,10,19,14,27,16,8,15,10,10,7,3,9,32,23,12,6,46,11,10,11,10,4,17,10,7,11,30,12,11,13,18,4,10,5,14,9,24,23,14,12,14,16,4,19,37,8,13,6,22,11,3,11,23,11,5,11,17,13,20,3,13,9,10,11,8,1,12,18,10,3,14,3,8,3,9,13,24,12,13,8,3,29,4,15,19,15,13,13,5,12,10,15,16,1,16,5,5,4,9,14,14,20,9,3,19,25,6,5,29,12,13,29,7,2,23,14,30,24,2,20,10,24,2,14,16,6,11,4,1,8,3,8,25,15,20,20,2,9,14,10,17,17,22,2,12,9,2,11,11,5,21,2,20,21,15,6,9,29,27,17,18,21,25,14,17,9,13,11,15,18,14,25,18,16,12,26,8,10,11,19,21,9,12,29,20,29,9,17,19,12,3,15,17,26,10,7,16,11,5,14,13,29,10,3,25,3,18,30,16,59,12,13,10,16,4,16,10,5,29,37,11,11,6,17,48,18,13,12,8,32,11,20,7,18,6,6,39,18,25,17,25,16,28,31,8,16,32,11,12,13,16,12,10,13,13,22,11,9,14,19,18,14,12,12,16,11,11,10,17,14,4,12,8,4,7,13,5,6,2,9,7,7,18,17,17,15,6,12,10,20,6,15,17,11,16,16,10,20,10,2,12,7,36,43,5,12,32,9,23,22,6,8,5,12,29,18,8,13,10,13,9,11,21,20,32,4,26,19,24,4,3,17,9,39,21,22,7,24,11,4,9,16,30,15,30,7,6,9,27,34,8,27,18,15,1,30,7,19,24,36,18,32,14,14,15,18,27,23,15,28,5,20,1,19,14,23,19,27,16,7,36,17,39,7,13,7,7,13,45,11,12,28,9,19,4,16,25,19,10,3,9,7,4,22,7,2,5,15,9,33,18,21,42,16,31,11,34,8,16,20,20,3,30,18,13,6,20,16,10,24,17,23,18,29,9,19,15,14,11,12,20,25,20,12,26,12,8,11,18,18,4,18,25,16,9,6,36,15,15,6,7,3,16,29,10,13,2,16,27,7,23,21,9,17,28,15,41,16,20,25,13,11,6,6,21,12,15,4,4,11,3,9,14,10,16,24,14,13,27,13,10,16,25,16,2,8,25,28,25,4,13,20,30,14,16,9,36,15,28,18,22,31,20,6,9,34,43,35,16,19,37,16,10,6,3,18,13,12,16,1,13,15,8,7,42,14,19,14,2,15,15,11,16,14,9,12,6,4,9,8,10,11,10,6,11,8,9,20,39,33,34,47,18,24,13,15,14,12,10,16,14,32,22,1,20,18,17,10,13,29,38,25,13,18,13,3,27,9,7,2,27,7,16,15,10,7,16,19,16,24,18,18,21,18,25,11,14,14,7,17,44,15,30,20,12,3,10,8,53,8,33,12,21,14,11,10,25,17,3,17,15,12,20,11,8,25,35,12,18,9,26,27,12,13,14,10,6,17,18,18,67,12,5,9,11,15,12,25,8,12,8,28,19,9,21,11,12,21,4,5,15,28,8,5,36,16,47,8,17,31,10,4,39,10,11,7,5,15,3,3,10,35,26,11,14,7,19,35,19,12,12,5,9,23,21,25,8,17,2,12,3,13,21,22,12,13,7,13,8,22,7,25,4,7,3,12,29,31,24,16,3,13,17,27,13,18,2,26,11,17,16,1,7,9,14,29,25,32,13,32,21,6,13,19,17,39,35,8,9,16,18,17,18,8,4,11,12,5,7,6,6,8,14,7,5,11,7,18,11,23,34,33,26,26,31,18,11,36,22,22,44,7,13,17,16,14,13,21,13,12,9,17,12,17,13,15,1,21,22,23,14,6,16,7,26,21,19,36,24,6,21,11,2,7,15,21,12,18,60,13,12,12,8,17,25,20,31,17,11,12,52,25,8,19,17,4,23,7,8,13,5,15,19,9,14,6,24,8,6,16,7,9,11,21,12,8,5,13,2,5,11,6,17,10,7,6,16,7,27,9,6,5,17,21,30,8,6,25,20,23,20,13,23,32,17,9,5,6,4,19,5,3,13,8,13,12,10,12,11,17,32,25,8,26,34,14,14,22,32,17,9,3,16,14,11,12,23,16,17,24,10,5,2,10,6,7,13,13,19,13,23,12,10,25,11,5,19,18,13,10,12,9,27,1,20,10,26,9,15,19,5,10,15,10,26,16,5,34,24,5,28,15,17,17,15,5,9,21,2,25,11,22,8,22,19,6,15,11,5,16,18,9,12,7,17,5,10,12,5,3,12,21,5,18,14,4,14,7,18,20,28,7,12,13,28,21,18,12,5,7,9,20,17,9,13,16,14,6,10,11,8,4,10,13,15,15,11,15,10,25,7,7,8,33,14,23,9,13,10,13,10,10,23,15,3,21,16,4,9,12,6,16,30,19,11,13,6,20,5,1,11,15,25,8,18,23,16,34,8,33,24,10,9,15,9,17,8,19,26,19,6,9,14,10,19,26,12,14,3,18,17,16,14,12,11,2,13,8,14,37,18,4,4,10,21,18,17,9,8,21,7,21,27,3,11,16,18,13,16,16,12,11,8,25,28,15,14,10,14,18,11,21,13,5,6,10,10,13,11,14,11,19,10,7,21,8,8,20,7,7,2,8,14,39,16,3,21,21,8,15,5,12,13,8,7,23,32,10,12,15,15,20,7,14,16,31,18,19,10,17,14,10,22,7,26,11,1,21,42,18,9,14,11,7,22,27,18,12,33,13,11,15,8,21,6,25,16,14,4,6,11,10,16,15,22,28,12,10,15,6,19,15,10,11,10,17,15,5,16,8,9,6,7,16,10,16,2,14,18,14,61,15,8,16,24,12,12,14,33,34,18,9,15,18,16,21,17,3,14,4,10,16,1,27,19,16,20,3,15,22,17,12,17,12,6,10,26,9,7,5,14,11,11,21,11,24,6,6,6,6,11,15,7,15,5,20,22,15,15,17,9,15,10,9,9,6,5,6,18,34,25,12,1,27,7,11,13,24,11,8,26,18,37,8,8,14,8,17,27,10,17,17,8,13,21,20,24,19,6,15,6,18,25,12,20,10,29,13,7,17,21,30,25,13,18,7,38,8,12,6,16,12,16,21,18,26,15,22,14,26,11,7,15,14,12,10,9,12,9,5,8,20,20,20,25,1,7,21,15,10,8,28,19,28,7,10,34,13,11,8,17,11,10,22,36,9,13,19,5,14,3,27,12,26,12,10,16,2,6,19,15,12,5,11,19,9,7,11,17,33,11,13,18,14,8,8,1,19,20,4,8,8,3,23,9,21,15,16,13,8,20,24,17,12,8,7,22,7,26,10,3,5,24,32,15,7,9,21,15,9,10,8,15,10,11,2,20,11,4,8,3,17,21,6,14,15,8,21,13,20,8,19,5,9,7,4,6,2,10,1,8,20,23,17,11,16,14,43,11,6,15,11,10,2,11,16,9,1,14,11,10,17,7,13,25,36,1,13,17,13,39,32,8,19,18,12,14,14,7,9,22,17,6,36,5,5,3,5,7,10,9,8,11,11,26,11,18,10,17,19,6,15,10,5,1,1,9,13,10,14,11,12,6,18,17,3,7,7,11,16,12,21,12,17,13,7,6,5,6,13,18,13,20,6,4,6,1,21,8,20,9,15,18,5,12,25,44,19,1,9,2,2,7,10,22,13,9,15,8,8,20,21,20,2,2,5,5,30,25,19,10,33,13,8,16,8,10,7,15,10,29,13,11,17,13,5,34,35,5,16,17,27,29,5,18,15,16,23,21,11,19,2,23,11,16,23,23,9,14,45,26,24,14,50,19,11,31,14,3,23,7,6,13,7,12,13,9,11,7,18,30,11,15,4,29,23,9,12,15,22,9,6,21,27,12,16,5,16,8,7,6,15,29,17,16,6,31,18,37,21,12,21,8,9,13,18,9,9,17,21,1,10,10,9,13,13,8,19,24,11,11,10,38,17,18,8,18,23,18,10,30,15,10,24,8,8,6,4,23,27,12,9,22,13,24,14,37,6,4,3,2,11,6,5,6,6,17,27,11,12,1,18,40,7,7,3,11,11,21,40,12,10,14,24,23,21,25,15,12,22,20,9,28,36,32,2,22,10,19,4,3,17,25,14,10,41,2,39,13,18,12,14,12,18,6,10,22,25,21,14,15,14,21,15,16,13,3,16,7,17,16,15,11,5,14,8,8,15,28,15,19,13,13,8,6,10,31,1,16,12,36,26,21,17,15,12,10,12,18,10,7,15,15,15,30,11,22,13,15,19,14,7,11,10,19,24,21,10,32,17,23,11,14,20,21,12,12,12,24,6,18,21,16,16,18,15,3,19,10,1,20,10,17,10,18,4,2,9,6,7,10,17,6,19,20,21,16,32,12,8,19,13,21,14,14,13,2,17,14,19,20,29,16,5,13,8,8,20,24,12,6,12,8,10,10,18,6,3,15,12,12,6,9,17,12,9,4,9,14,2,1,15,13,19,17,17,30,18,4,8,15,7,5,6,9,17,1,12,11,6,12,11,15,18,20,8,11,3,23,57,12,17,28,12,17,21,3,4,12,19,11,6,20,16,13,9,4,9,17,20,14,2,7,6,9,16,14,11,12,7,22,36,4,31,7,6,18,10,3,13,6,17,11,6,7,8,15,19,11,13,16,2,14,13,55,23,9,26,23,18,22,18,4,24,17,6,16,11,14,4,16,19,7,9,7,15,13,3,16,11,6,7,7,4,11,12,18,12,12,15,11,7,12,10,3,11,20,14,21,16,11,14,13,20,1,8,6,3,14,20,17,21,8,27,11,8,19,15,14,12,3,14,5,17,23,5,55,14,14,12,9,4,9,28,4,10,23,11,22,14,10,6,13,13,14,9,5,21,9,12,6,25,17,14,8,24,1,29,8,11,1,12,15,11,9,13,20,8,19,4,15,1,28,6,9,14,11,21,13,10,9,21,26,41,18,9,5,32,21,11,9,16,22,12,9,12,5,28,40,23,9,15,12,24,10,21,10,35,7,9,12,2,7,2,26,19,7,22,27,13,5,6,13,12,10,25,7,16,14,18,4,10,9,12,2,10,9,1,16,6,15,6,9,11,12,11,18,15,4,8,10,36,15,11,7,16,4,1,32,9,12,7,31,19,9,20,21,8,28,8,12,12,14,8,25,21,9,10,27,20,13,14,27,16,14,18,19,13,9,12,9,15,18,5,39,26,21,14,29,18,6,12,8,20,4,2,1,32,56,21,3,15,14,15,6,22,9,13,28,7,26,24,18,19,15,23,17,14,16,15,9,10,3,6,12,7,1,17,12,8,17,28,6,5,7,7,31,17,12,14,25,14,4,6,28,16,16,4,1,5,7,24,5,24,9,17,21,7,13,23,11,16,4,11,14,17,6,10,7,2,17,23,30,14,5,18,13,13,18,21,20,16,13,16,19,17,26,12,11,13,27,28,25,17,16,7,3,18,16,7,11,14,7,9,17,21,21,28,17,8,2,9,2,17,1,22,14,12,9,10,1,14,11,11,14,35,15,29,5,31,17,23,19,10,18,3,37,25,12,18,6,1,2,4,4,5,5,6,19,8,30,25,10,8,5,12,12,13,29,9,1,8,5,22,20,15,18,14,12,10,23,12,16,13,1,5,6,9,21,24,1,15,14,13,14,12,26,1,12,15,19,3,1,9,8,7,12,4,7,8,8,14,19,13,8,22,11,23,10,16,16,24,14,7,12,12,6,10,13,9,7,14,29,7,2,8,7,19,8,11,8,2,11,12,14,27,12,9,4,13,2,14,5,16,36,13,17,16,8,8,17,13,9,17,10,2,3,8,26,30,11,26,9,8,29,17,11,5,11,10,23,49,10,20,16,33,8,14,4,27,26,25,27,5,30,40,33,8,21,5,20,4,5,4,6,4,10,13,5,15,9,14,22,19,15,6,6,17,16,12,25,12,12,7,7,5,8,35,8,13,6,2,20,17,3,17,8,29,8,22,14,12,10,3,14,20,9,12,14,15,12,30,3,5,31,22,22,7,26,6,9,20,2,4,23,25,7,11,11,19,12,11,6,11,19,17,3,15,22,11,21,15,16,13,27,4,19,6,17,3,13,16,40,7,11,6,26,4,33,6,20,1,12,14,24,10,17,24,21,39,6,13,10,7,18,14,15,17,32,14,22,23,28,12,20,19,26,5,18,17,25,14,2,15,4,14,4,12,20,13,16,21,14,4,23,18,13,19,15,9,1,10,16,15,4,17,4,20,13,6,8,16,16,7,18,18,12,13,43,16,17,27,36,1,10,20,8,10,22,19,27,17,13,1,14,25,5,6,18,21,6,61,16,27,15,20,13,18,12,23,8,7,8,2,8,6,25,20,6,1,4,4,12,10,22,24,8,34,20,16,4,34,12,14,5,18,15,10,19,11,26,17,26,28,19,13,6,16,36,24,13,20,14,13,33,28,25,27,9,20,18,14,14,18,21,20,13,11,8,24,17,11,11,7,12,19,18,28,27,13,8,6,9,11,23,26,15,32,19,20,11,35,39,17,32,22,36,21,16,14,28,9,15,8,10,10,6,7,19,24,14,6,3,1,11,7,19,16,8,6,17,4,7,23,27,20,1,11,6,5,9,3,5,10,11,9,10,36,8,35,10,6,11,9,12,13,3,25,22,23,8,17,24,16,22,16,8,3,18,1,14,6,32,17,10,2,9,2,5,6,24,13,14,6,6,9,9,14,7,23,9,11,12,24,10,9,13,14,4,9,9,4,21,13,26,1,21,15,6,11,11,7,14,22,13,17,5,19,16,9,11,20,30,11,2,8,7,10,14,36,1,15,12,21,2,19,20,12,8,8,5,18,6,4,19,8,4,5,11,17,13,21,14,5,2,14,19,2,28,22,10,4,10,4,6,7,6,22,12,22,8,7,3,12,9,8,18,15,1,16,12,11,2,20,10,9,13,9,10,10,10,26,12,17,5,6,22,13,9,11,20,36,16,16,20,10,15,13,9,20,7,12,8,18,35,14,3,12,10,6,12,11,11,27,13,12,11,7,18,11,21,3,8,2,14,5,27,11,5,13,5,8,4,16,16,7,22,7,15,23,12,10,4,16,8,15,11,19,9,11,8,11,7,11,11,14,16,17,3,6,16,13,10,6,1,14,6,9,4,2,3,29,19,11,4,9,10,17,11,1,21,9,15,17,4,14,17,9,5,6,24,6,31,20,21,4,9,5,3,5,19,7,18,10,24,26,10,18,57,13,19,21,17,9,15,12,1,9,30,6,11,12,7,34,12,20,14,7,8,17,11,23,12,18,8,15,5,28,24,10,8,9,16,15,19,9,24,6,13,14,23,19,11,11,14,22,22,15,12,21,37,29,3,16,4,20,17,9,12,10,8,14,12,18,9,14,7,13,15,15,7,12,16,20,17,8,23,16,15,11,22,20,15,10,18,21,12,24,20,6,17,18,7,9,16,12,7,24,19,4,2,9,18,16,18,13,8,7,10,33,20,14,21,25,18,5,8,5,8,14,5,34,10,25,29,6,11,15,11,20,10,9,12,23,19,25,9,13,23,12,8,7,10,4,4,9,15,10,12,29,14,22,16,15,8,11,14,8,21,15,7,13,12,8,12,18,4,11,14,8,12,10,10,19,21,7,8,14,16,30,8,16,12,18,9,6,10,6,5,8,17,8,12,7,13,11,14,23,8,19,10,2,8,14,10,24,31,9,24,9,8,30,7,3,31,12,14,40,20,22,30,6,3,37,7,16,19,19,28,5,11,21,1,23,3,6,10,26,21,24,21,24,23,28,4,18,10,13,27,21,12,11,11,16,9,11,8,5,18,10,25,12,12,15,19,8,24,9,11,14,13,8,18,12,17,11,8,31,34,20,21,25,1,11,25,9,13,22,32,6,7,5,8,3,32,6,51,16,8,12,28,17,20,8,49,12,1,9,10,6,15,18,12,14,11,11,15,12,4,12,17,24,9,19,11,13,18,3,9,2,9,8,5,35,13,13,6,3,4,19,9,15,23,2,1,26,10,21,15,13,14,8,18,9,7,28,12,20,15,3,22,13,13,10,6,4,15,15,17,3,24,19,18,27,13,24,2,13,8,18,21,12,17,10,9,23,11,12,13,7,10,5,17,21,8,6,9,10,21,18,26,11,13,2,7,6,18,11,25,9,38,17,8,23,21,7,12,4,13,16,8,14,12,8,15,20,10,10,6,11,15,13,12,6,3,30,10,2,9,11,9,11,26,28,25,8,18,14,30,20,1,11,21,20,16,27,16,10,10,2,19,16,19,12,14,15,12,9,13,5,24,31,22,10,11,8,14,8,9,16,2,18,9,10,24,41,29,2,25,3,14,10,41,1,18,30,10,29,15,16,18,11,10,15,17,13,23,21,23,2,28,9,22,14,24,29,7,26,4,18,2,22,7,31,21,7,16,7,16,2,3,9,19,11,3,53,15,12,21,22,29,34,32,3,18,21,17,13,5,25,9,20,15,20,6,14,15,12,9,8,14,3,7,22,13,5,17,10,1,20,33,1,12,28,20,12,14,11,9,21,28,33,10,18,24,10,10,5,13,24,22,6,10,11,17,28,6,17,8,27,18,6,14,13,10,12,8,23,16,11,19,11,28,72,13,43,15,1,2,14,31,20,14,5,34,27,16,9,16,15,8,4,29,7,4,4,8,7,25,26,12,8,12,17,9,17,18,8,10,19,4,10,10,24,12,13,6,15,13,23,11,10,26,17,9,16,23,10,24,3,14,2,20,23,5,11,16,38,11,27,10,3,14,17,13,23,8,10,5,26,29,32,30,7,5,11,17,15,29,23,7,10,16,16,23,13,8,17,26,18,23,22,18,14,3,12,11,19,9,21,22,14,15,12,8,5,16,20,10,17,20,11,15,8,32,16,16,15,21,10,1,6,14,16,7,9,15,18,19,38,5,10,13,9,11,18,24,35,33,25,26,15,19,24,24,11,3,20,38,14,25,20,21,25,45,46,15,10,20,16,10,9,40,8,12,10,7,18,15,22,16,8,9,12,21,8,1,2,2,1,1,12,17,10,18,26,12,8,14,14,16,18,21,10,2,19,21,20,23,23,18,9,22,25,24,22,29,33,39,10,12,8,14,4,28,17,10,20,8,7,16,13,14,25,17,8,28,14,1,23,66,28,15,21,3,13,26,33,14,9,6,12,7,30,19,15,15,10,2,24,13,17,8,6,16,15,42,22,7,18,23,11,6,9,12,33,14,13,14,10,9,14,7,10,19,16,11,11,9,13,12,14,20,18,29,5,8,7,55,11,9,47,31,3,19,21,7,14,20,22,15,31,7,32,1,16,18,5,9,2,12,10,18,3,9,20,3,18,9,6,18,26,33,11,9,12,16,3,4,4,7,12,13,8,3,11,16,2,16,12,16,13,10,5,5,5,14,19,17,7,13,4,13,24,3,5,27,5,3,15,22,17,20,7,16,10,12,3,1,9,5,10,7,35,8,5,19,10,18,34,27,13,9,11,10,18,22,5,6,17,6,23,14,25,1,10,6,9,8,18,21,27,28,30,10,20,6,16,12,6,8,13,6,5,12,13,13,18,5,11,5,4,17,4,30,12,34,22,19,18,8,19,4,6,21,14,4,40,12,3,42,23,27,14,5,10,14,26,52,11,2,27,17,34,42,20,11,23,34,4,16,9,18,7,7,13,21,26,17,12,10,11,18,19,10,9,5,14,17,13,22,20,4,9,23,4,11,25,16,19,20,6,28,8,30,16,25,20,14,18,17,17,8,9,18,15,20,8,7,3,10,18,21,4,12,12,32,7,35,1,16,17,12,10,9,25,10,7,6,13,13,28,10,10,18,10,13,5,19,15,3,17,22,16,12,15,23,11,7,18,18,19,15,12,10,10,7,43,26,20,19,3,15,3,13,11,6,20,11,17,16,21,9,21,16,5,22,3,2,24,20,34,6,16,6,10,8,12,6,14,12,9,15,8,7,8,10,34,3,9,5,8,10,16,16,6,14,14,7,7,48,15,3,21,3,11,15,4,8,16,7,14,9,23,6,23,26,16,10,4,19,26,20,24,16,4,9,11,14,4,17,24,14,8,32,11,9,21,14,36,13,11,19,1,15,13,27,13,13,13,14,25,26,10,6,6,3,4,6,9,10,6,6,7,1,1,4,2,17,11,18,12,4,8,17,9,18,41,14,15,7,18,2,20,31,3,24,7,11,15,4,8,21,14,10,11,11,39,6,7,24,13,19,26,27,22,12,14,14,15,31,20,8,9,37,14,12,17,46,11,4,5,9,11,22,9,19,16,2,13,25,8,8,26,12,12,7,5,11,13,18,19,14,19,16,2,22,15,9,13,18,6,9,14,12,39,7,5,25,4,10,10,31,25,7,14,26,5,28,7,10,5,17,58,27,11,29,14,4,19,24,12,12,90,24,19,20,18,16,7,14,2,14,16,30,55,19,20,29,23,16,37,30,6,19,33,3,36,27,21,4,14,7,12,58,43,29,20,33,8,16,30,8,15,4,8,22,54,5,30,27,20,61,30,13,26,10,31,14,22,22,38,28,6,40,24,14,53,16,37,13,38,35,53,2,22,9,48,42,27,10,41,13,44,11,11,6,2,12,18,14,29,17,26,31,9,18,73,32,22,27,20,48,19,37,21,24,51,35,13,13,17,27,21,15,65,45,34,17,11,44,17,38,42,69,4,6,30,4,26,35,11,16,10,26,44,20,14,11,9,6,56,64,59,43,23,52,26,98,15,13,38,47,121,33,9,50,17,30,23,48,42,72,105,27,53,6,43,40,36,40,15,16,18,26,40,23,36,63,52,35,44,11,9,47,19,4,22,14,27,32,31,7,31,3,1,3,13,19,23,40,13,12,12,8,4,2,1,6,2,10,5,13,17,20,51,22,42,51,22,19,10,1,10,12,12,11,7,16,9,16,17,15,15,11,11,13,30,36,19,13,16,7,18,36,6,28,14,6,22,3,5,13,15,37,20,13,26,24,5,12,12,14,29,15,6,15,2,19,80,5,10,8,12,6,10,7,30,6,25,13,1,8,9,26,23,17,2,33,20,28,54,1,7,1,47,13,42,24,28,15,23,10,14,37,13,23,7,24,15,18,18,1,22,5,49,8,26,18,22,14,8,8,1,10,17,5,12,14,8,10,14,9,9,8,20,19,16,28,14,23,13,73,12,8,18,22,27,1,11,3,2,13,23,43,9,30,54,25,19,5,5,8,9,24,9,13,13,9,7,15,9,16,17,15,15,10,4,11,13,27,6,6,11,7,10,40,8,5,18,17,7,19,39,7,5,21,8,6,5,2,6,9,13,6,3,18,7,23,23,14,23,30,25,5,11,5,12,5,6,3,6,12,17,53,27,8,3,17,19,8,6,9,4,8,6,5,10,7,33,15,18,17,19,20,28,28,8,32,6,40,6,8,17,8,22,11,15,12,24,31,8,8,10,13,12,9,67,17,17,10,19,13,108,4,12,26,16,34,7,13,44,39,30,10,23,41,50,25,36,9,8,15,9,7,7,8,26,24,20,2,31,19,18,7,5,9,22,5,21,28,44,13,24,21,2,22,12,13,1,8,11,6,39,21,26,15,45,9,13,21,7,23,21,23,11,19,6,35,10,12,17,7,6,39,12,11,11,4,1,7,3,7,10,24,9,15,7,24,16,8,17,10,16,2,26,26,36,15,4,17,20,15,6,11,37,6,2,2,36,42,1,9,44,16,18,10,12,10,16,13,12,3,5,19,12,13,9,14,2,8,7,26,5,12,12,16,13,14,37,20,10,2,4,6,7,11,3,1,34,25,12,8,6,7,17,26,24,8,6,17,14,9,5,13,4,7,11,10,13,6,19,15,10,9,8,14,31,6,31,15,24,13,8,9,3,1,25,12,10,12,5,13,4,4,9,12,12,11,9,18,11,14,10,19,1,1,2,6,6,14,7,19,2,24,20,11,8,10,16,34,10,6,11,23,1,23,25,20,24,16,11,18,17,14,12,20,6,23,14,23,41,7,3,3,9,11,5,3,22,6,5,5,15,9,26,7,6,5,13,6,5,1,34,27,11,45,35,17,9,16,15,24,9,82,38,35,14,14,19,7,30,1,6,16,34,10,16,3,7,19,13,13,26,31,8,7,17,21,31,82,11,4,35,17,9,2,1,32,47,17,10,24,28,31,20,14,1,24,10,10,15,9,56,66,4,11,26,7,23,14,9,13,21,7,6,6,21,26,5,21,13,14,24,9,15,7,24,16,8,18,11,18,2,28,40,36,5,19,19,15,5,12,9,29,6,2,25,37,1,2,30,14,7,11,26,16,11,13,34,5,27,8,31,4,7,2,1,6,12,14,9,6,15,12,16,11,21,11,15,16,13,4,15,29,7,15,8,20,26,12,9,14,16,27,25,8,1,9,10,65,15,39,5,10,10,12,5,16,2,6,4,4,9,12,10,12,10,19,5,6,8,6,6,14,7,24,9,15,19,5,3,2,1,42,18,24,20,11,8,10,16,34,10,6,9,5,42,25,20,23,16,11,18,17,14,12,21,6,12,1,15,34,41,7,3,3,9,12,31,6,5,5,15,9,3,3,16,16,27,10,41,22,14,18,8,17,15,4,1,30,85,39,9,21,5,14,14,8,6,1,20,33,9,15,2,7,20,12,13,29,27,8,3,1,6,8,21,21,31,83,11,4,37,9,7,1,17,32,49,17,15,24,20,8,31,12,1,15,29,10,10,15,9,37,18,67,32,2,23,9,30,30,36,26,13,14,21,28,3,1,34,1,44,25,7,33,22,21,6,9,19,74,25,21,8,89,1,35,3,12,48,2,30,18,3,14,6,14,9,17,10,7,3,11,13,2,5,15,5,8,3,12,12,12,31,9,24,12,6,40,18,14,18,13,18,15,7,12,16,6,33,53,2,7,6,25,5,3,11,19,19,44,31,21,14,10,37,26,16,1,5,23,17,10,53,10,34,18,22,17,2,3,3,11,14,48,32,50,37,6,42,18,33,5,15,6,15,10,11,19,10,33,20,5,24,7,56,15,8,7,7,8,30,9,8,23,15,2,3,3,6,66,3,12,16,3,4,3,13,9,11,15,11,3,1,3,5,25,36,8,29,23,20,12,7,5,6,4,5,11,7,10,11,7,33,34,6,27,12,4,3,10,10,35,10,1,2,7,12,6,11,18,4,4,32,9,5,9,1,3,12,11,15,21,1,37,21,13,30,19,10,1,20,25,13,7,2,1,13,32,33,12,13,19,6,4,54,14,18,19,13,6,1,11,34,35,5,4,21,16,10,29,17,26,4,11,10,4,1,23,31,11,19,24,25,14,3,14,8,29,9,5,41,19,13,9,26,6,11,11,20,20,22,27,14,4,1,17,40,8,18,24,20,6,6,8,5,4,22,37,9,12,7,3,34,34,11,17,11,17,3,1,9,27,23,8,10,23,13,39,40,3,2,4,1,4,11,24,2,26,8,8,6,19,8,25,13,18,29,7,19,17,2,1,32,48,33,29,55,3,11,46,22,4,7,12,19,28,5,65,1,1,43,16,17,27,16,36,12,4,8,2,12,3,7,5,1,14,25,31,37,26,22,19,6,30,2,32,20,25,16,22,18,14,19,30,43,7,3,1,26,27,38,23,26,25,6,18,46,12,1,70,11,43,14,34,15,11,12,30,8,6,5,2,1,4,23,8,6,21,17,17,12,29,39,11,28,3,25,9,10,12,19,13,11,12,26,11,54,9,3,1,13,51,20,4,23,17,6,31,26,11,1,1,13,17,12,21,24,14,36,34,21,33,9,1,14,17,34,60,3,39,7,20,1,9,36,9,15,4,3,30,37,54,8,1,8,17,43,23,36,7,31,3,11,21,11,1,26,6,11,30,8,12,11,16,63,10,18,7,1,13,18,17,12,14,14,5,37,31,8,12,16,7,17,9,1,14,34,60,7,6,10,30,17,17,35,1,29,6,16,11,16,23,27,25,15,26,24,31,15,14,27,30,11,15,3,8,16,24,15,11,1,11,17,47,17,22,13,8,30,19,24,13,22,44,14,14,18,15,16,8,25,16,13,20,5,1,2,15,12,42,22,15,46,29,13,25,14,16,17,13,33,36,9,29,42,25,3,1,2,9,31,7,11,22,27,24,33,27,10,15,7,13,10,13,26,29,11,25,16,9,31,33,2,24,9,1,22,3,5,7,8,10,30,14,11,12,9,15,19,22,18,19,11,2,26,18,26,9,9,2,16,15,13,11,17,14,13,1,15,12,34,7,16,21,75,7,33,2,1,19,11,5,36,6,20,5,21,7,9,40,14,2,1,8,12,30,5,14,10,14,21,63,30,19,2,1,2,16,52,12,14,17,20,8,16,14,37,1,36,5,6,15,19,21,15,27,32,27,5,8,1,12,16,32,33,4,28,11,11,33,20,1,7,19,25,29,35,6,63,9,4,1,2,36,18,30,11,50,19,10,2,7,1,1,4,1,17,22,32,33,22,25,41,2,12,3,1,38,7,5,43,20,15,19,15,15,23,4,1,21,3,11,20,12,7,16,7,31,7,30,27,13,1,25,1,5,25,23,60,38,25,8,10,1,1,64,8,34,52,37,9,1,12,53,3,46,26,13,31,18,5,1,28,91,14,3,30,5,17,8,6,1,26,16,73,5,13,11,36,6,7,1,4,10,24,28,20,17,23,19,34,21,17,3,1,22,16,24,24,22,14,20,16,22,10,4,1,8,17,38,2,22,17,9,7,10,13,57,9,2,1,15,12,19,4,13,7,4,9,21,17,75,13,2,1,1,17,15,73,70,3,26,1,14,8,27,5,19,42,16,23,16,25,19,1,1,18,5,19,8,23,15,23,41,13,18,20,10,42,8,43,12,26,44,21,21,2,11,4,1,39,36,33,14,16,24,13,9,4,18,18,3,1,22,22,17,17,14,3,8,14,12,10,16,37,31,33,20,17,8,24,11,14,16,15,24,24,22,20,2,1,24,46,21,11,17,26,5,12,31,20,7,11,7,16,36,17,6,17,14,7,15,24,5,45,2,1,21,25,22,46,17,20,10,17,48,10,42,10,10,7,7,31,21,23,13,5,32,7,29,36,26,34,30,40,2,1,11,16,16,40,16,20,20,3,28,13,10,6,30,8,16,23,10,24,16,12,8,13,27,20,5,11,10,6,1,28,14,15,16,44,8,35,24,23,36,2,26,27,16,38,12,32,34,12,3,1,14,17,31,25,21,21,21,16,38,6,28,3,7,5,2,2,4,2,12,36,7,8,4,9,2,1,6,1,2,1,5,3,5,20,4,1,43,28,30,53,1,14,19,25,3,12,68,4,18,5,13,14,18,22,3,8,16,7,1,23,18,37,5,8,12,22,20,3,34,16,8,12,16,11,7,17,23,11,13,9,17,2,30,15,29,40,7,2,1,20,17,11,7,19,34,31,27,8,5,13,22,23,28,3,11,20,11,33,25,11,7,27,6,10,1,21,13,9,17,6,24,18,17,22,29,23,13,42,1,3,64,27,19,47,19,45,2,24,1,15,19,62,35,4,25,40,36,31,7,3,19,23,21,8,25,16,16,1,9,5,8,3,1,20,27,32,20,18,28,18,5,32,12,8,1,11,2,10,20,25,14,19,24,39,12,5,10,39,13,1,1,19,26,62,29,11,40,36,4,4,2,3,31,30,12,5,7,3,12,6,16,13,6,13,19,4,19,12,11,2,1,12,13,2,17,16,17,19,28,19,12,16,13,14,28,15,11,5,28,16,30,20,6,16,33,7,25,1,4,9,7,1,15,5,11,30,17,18,14,51,14,8,9,14,19,11,2,7,2,45,6,5,8,6,26,38,4,18,7,5,22,9,14,1,7,12,2,17,35,25,4,14,6,17,20,6,6,4,41,30,25,5,9,18,7,21,48,6,1,6,23,7,9,25,20,33,7,3,27,8,14,22,6,4,19,8,22,14,15,19,10,17,17,24,21,27,14,1,18,32,26,13,41,35,29,19,8,26,45,19,12,29,35,8,2,12,14,1,25,20,32,30,49,6,17,24,20,45,9,14,14,18,8,13,10,6,29,25,27,4,1,14,35,18,4,21,5,6,16,17,17,13,14,10,9,16,10,7,8,3,13,18,47,15,15,16,13,20,7,20,23,25,21,3,1,10,13,8,5,47,17,19,27,14,26,10,12,2,3,13,16,20,13,9,24,10,6,21,19,6,26,28,20,11,2,1,26,10,15,45,2,7,12,27,21,5,8,4,2,13,24,24,19,24,5,8,24,11,23,14,17,17,4,14,3,1,24,28,20,6,25,11,11,8,15,51,18,9,2,30,21,3,28,28,14,14,4,13,28,18,7,3,1,33,13,26,24,24,24,34,17,1,13,36,5,21,26,4,10,7,48,19,30,9,7,6,4,6,3,1,16,17,20,28,24,10,1,7,6,1,9,11,4,6,3,6,1,7,8,3,28,6,3,10,43,18,57,8,14,23,23,28,1,8,36,23,65,25,15,11,19,27,7,27,32,54,6,25,14,21,18,13,1,15,21,13,17,11,72,6,27,24,14,16,5,6,23,11,26,1,10,29,22,12,30,18,4,1,8,45,9,48,10,17,38,8,7,11,11,2,18,60,15,16,15,28,20,19,10,5,6,2,1,35,3,8,13,40,41,36,17,7,18,2,1,11,6,4,61,28,19,17,21,16,3,5,21,26,7,13,2,1,21,23,13,18,72,15,19,37,22,11,32,17,12,14,27,10,6,14,12,16,10,10,6,5,1,22,35,12,26,19,10,19,11,13,32,7,4,14,36,14,26,22,37,31,25,4,24,5,1,2,8,83,20,27,10,31,14,22,9,12,2,79,14,9,7,16,13,2,4,13,2,4,4,10,12,5,2,10,18,3,12,39,41,20,13,41,33,7,4,2,8,17,5,4,1,39,24,45,27,38,7,15,16,9,16,18,22,14,11,10,9,21,23,13,17,24,53,12,3,1,29,28,54,15,8,13,27,2,10,10,9,20,13,4,24,32,57,52,25,16,18,3,1,27,25,19,39,29,35,28,11,6,4,6,7,59,28,6,17,1,19,17,15,9,9,7,8,9,10,3,1,12,24,32,44,24,6,3,10,24,9,8,5,17,8,13,23,1,2,12,21,53,33,52,4,25,18,9,3,1,13,29,11,26,13,18,14,47,14,11,9,2,16,34,46,14,11,28,9,3,38,8,1,6,23,2,1,15,14,18,23,15,20,27,33,14,17,13,2,5,2,2,26,28,14,23,15,14,21,22,30,12,25,6,3,9,1,3,21,35,21,6,13,12,34,21,13,12,20,8,2,6,37,10,10,28,6,39,43,19,15,5,18,10,42,34,27,25,46,28,16,1,9,26,15,18,22,14,11,10,9,21,36,16,23,57,15,8,13,22,33,45,10,29,4,1,40,25,17,18,32,27,51,1,12,16,6,18,19,17,15,15,24,32,38,6,21,2,1,9,84,14,57,6,17,8,66,49,18,85,2,1,2,13,18,21,16,21,27,34,13,17,20,2,5,2,6,18,28,15,23,14,14,21,22,40,15,6,3,6,4,1,2,11,27,23,34,16,6,15,12,34,21,13,12,26,38,12,31,9,4,17,17,23,5,18,1,17,28,18,11,11,27,11,65,19,2,31,2,10,8,10,1,2,1,42,11,10,46,22,45,49,9,4,14,2,51,2,11,35,13,8,5,12,17,2,12,22,8,20,5,1,8,15,8,14,10,20,13,25,14,40,18,38,17,10,2,9,12,38,11,24,30,21,12,15,9,14,15,2,3,1,18,20,11,42,13,9,30,15,51,5,8,1,18,36,15,5,7,24,46,21,58,13,1,5,14,5,23,19,14,48,14,24,32,11,6,12,27,18,28,4,3,13,9,31,8,46,10,33,1,6,4,34,42,26,76,31,19,25,16,43,17,28,23,10,21,5,1,7,17,34,8,23,61,16,17,36,21,14,48,15,22,17,42,19,19,14,14,6,2,1,25,72,23,22,24,13,27,3,29,29,31,8,26,19,32,10,35,3,1,10,17,13,21,74,12,52,10,7,17,5,1,6,6,6,3,21,3,8,17,19,23,7,9,12,14,7,5,4,28,6,13,7,46,56,3,47,18,47,10,4,4,1,5,3,14,9,17,16,9,13,7,30,53,71,5,2,19,8,26,58,43,25,13,3,1,11,20,11,10,7,13,22,9,12,18,20,22,14,19,8,34,43,13,3,5,17,21,23,36,5,4,4,2,1,5,25,14,8,9,9,14,45,15,19,3,17,3,41,6,65,13,18,13,21,10,5,3,17,15,1,15,29,23,11,18,22,17,5,10,62,44,25,7,11,22,5,11,18,33,10,26,22,11,23,8,21,48,55,30,10,36,2,1,10,28,38,6,8,33,18,18,13,27,22,26,1,28,22,51,30,20,27,24,69,1,13,60,12,11,40,21,34,12,6,4,1,20,5,8,12,27,14,5,8,30,13,32,16,7,38,15,1,8,14,9,8,9,27,28,28,40,21,28,20,12,26,5,10,16,14,49,21,21,17,12,16,3,1,4,11,42,21,10,7,10,12,14,27,22,15,27,13,7,12,31,10,23,19,5,17,31,19,7,10,10,7,5,11,11,16,2,1,37,62,38,16,39,26,4,24,20,9,37,42,16,15,3,16,17,5,1,25,42,36,13,4,10,50,10,4,3,13,12,5,6,2,8,24,12,19,47,8,6,18,18,20,10,8,20,11,2,1,14,38,58,14,16,14,19,26,26,10,28,3,1,6,5,34,10,39,6,5,20,22,18,6,47,12,5,1,4,10,5,4,15,6,6,1,20,4,3,1,4,16,6,5,28,28,18,41,32,20,14,14,4,12,9,22,26,11,2,35,54,8,10,3,1,12,43,15,19,40,13,30,18,11,6,1,8,7,11,29,60,36,11,11,6,1,2,9,12,2,1,6,9,23,6,11,9,12,6,21,24,12,9,10,24,11,6,4,2,10,46,34,3,10,3,7,28,17,20,1,1,8,17,2,27,17,4,3,8,25,13,20,12,12,7,39,11,6,6,14,65,13,25,13,14,16,21,22,10,2,3,1,8,47,7,30,46,14,22,16,4,21,23,4,1,20,19,10,14,16,7,18,8,44,17,26,30,3,1,18,16,43,45,3,8,2,7,21,8,28,4,14,16,21,6,16,17,18,46,19,38,24,1,20,17,25,12,23,25,14,64,18,5,32,31,19,5,5,10,24,10,11,17,13,5,1,25,19,25,13,23,11,22,29,54,4,1,9,17,7,18,30,25,14,61,26,31,7,1,28,8,16,50,45,13,21,24,10,17,7,52,30,12,16,8,10,21,18,14,16,28,5,1,20,56,22,56,6,50,17,13,4,20,48,37,16,21,28,41,10,9,41,37,26,24,24,22,8,1,20,24,17,6,34,22,42,17,28,4,1,58,21,22,57,48,31,25,12,19,61,26,18,10,3,6,9,24,13,1,11,24,17,28,40,21,43,40,15,18,17,65,29,9,27,17,10,25,1,4,11,11,14,28,14,7,21,30,44,23,12,11,18,52,76,20,11,4,51,1,4,4,4,11,23,1,15,35,11,18,6,19,10,11,5,27,1,5,6,20,17,13,13,14,14,12,16,11,13,23,29,29,3,1,24,15,7,25,8,29,21,14,48,18,9,5,2,1,6,25,50,3,7,6,25,15,4,1,23,11,34,41,26,18,11,9,12,19,13,10,8,2,7,6,1,3,20,19,27,19,27,51,14,20,48,26,28,37,8,16,7,5,11,18,7,4,1,11,45,24,45,30,16,23,5,3,40,32,63,14,56,9,13,6,2,1,17,36,14,17,43,22,57,17,49,1,49,24,46,1,8,23,26,3,1,21,7,17,12,33,21,22,28,83,7,13,16,16,21,10,13,61,24,17,25,1,71,31,23,48,43,52,43,4,16,19,32,30,8,20,1,14,52,7,7,57,15,25,27,40,18,48,25,36,9,16,24,14,1,1,61,42,25,31,20,48,1,8,56,13,22,49,40,8,29,15,32,39,17,24,37,13,20,11,23,2,11,5,1,27,5,11,16,16,16,13,13,12,22,19,76,20,25,6,40,7,22,10,9,9,51,50,2,1,16,6,11,25,27,18,10,31,20,3,1,3,7,27,17,6,13,46,29,21,36,7,20,21,3,1,12,20,19,8,6,42,33,31,5,10,23,8,5,9,7,8,26,14,8,46,6,8,3,10,51,13,5,1,9,51,19,24,32,14,10,34,17,21,3,19,27,14,24,25,18,23,19,8,18,22,9,26,40,6,23,9,3,16,3,12,25,13,14,11,23,15,11,14,12,2,1,21,12,11,4,28,13,16,16,19,10,16,30,17,3,2,19,28,8,31,28,10,11,10,21,18,2,1,1,18,19,28,14,12,11,2,16,3,22,51,13,7,16,3,46,18,10,10,24,25,17,15,61,4,4,19,8,19,5,7,5,4,32,36,23,9,1,3,27,12,8,2,20,6,19,7,3,30,8,16,23,33,50,20,23,43,8,5,1,13,22,16,22,4,2,14,26,30,26,17,6,35,27,20,14,14,11,13,16,8,17,16,20,21,10,15,39,20,45,24,22,10,11,32,2,1,3,34,21,33,23,31,30,53,20,17,24,29,35,15,22,3,1,2,10,30,40,35,8,9,34,30,29,26,10,8,13,10,5,14,1,24,21,5,9,4,29,17,47,21,19,9,5,8,6,3,2,1,23,10,4,24,15,14,35,25,18,27,11,3,42,30,21,15,14,1,14,25,18,16,1,3,17,38,6,9,6,25,5,20,11,8,22,16,13,4,26,8,8,46,21,36,45,65,9,54,72,15,46,7,24,22,3,1,3,23,15,9,22,33,12,40,39,10,25,2,53,15,8,27,18,20,14,56,14,2,1,68,74,43,27,13,8,2,39,50,1,7,32,72,10,3,1,18,7,24,4,19,19,54,10,34,21,16,17,35,20,20,40,14,16,27,38,5,3,1,18,38,48,27,8,27,5,12,25,12,30,50,20,16,15,17,15,45,7,1,2,14,69,13,34,13,18,11,53,8,26,5,21,27,24,13,3,24,7,13,25,4,1,14,34,28,30,33,2,27,18,10,15,9,32,7,7,8,15,3,10,5,26,10,31,8,12,15,26,13,7,1,10,9,15,21,12,1,15,16,16,15,8,10,35,18,12,3,9,7,1,1,17,27,4,15,30,22,16,21,36,17,2,1,17,13,21,10,28,13,10,13,14,12,18,48,4,15,23,17,12,19,66,21,7,13,25,1,1,10,42,35,11,21,31,11,26,8,5,18,38,15,7,2,20,10,21,59,23,1,18,21,5,14,43,18,17,15,20,26,8,4,43,11,4,5,21,12,21,19,26,22,21,10,9,15,1,26,25,20,11,28,6,32,13,29,24,13,2,24,36,25,4,6,12,9,9,2,16,17,60,14,3,1,13,49,30,17,2,58,15,40,20,5,6,34,24,5,11,20,6,29,19,1,13,37,18,19,20,53,11,15,12,8,24,20,27,29,21,17,7,9,15,36,15,24,3,1,8,14,67,19,38,43,4,4,8,24,19,34,28,28,7,19,25,5,1,10,16,38,9,18,37,8,12,25,18,15,10,9,22,6,11,121,5,11,28,23,9,3,1,7,30,8,8,8,10,30,23,11,18,30,6,16,3,16,11,11,60,15,13,66,28,10,15,1,30,16,12,21,23,49,11,31,9,33,25,17,54,15,37,46,1,8,19,8,57,1,8,11,13,30,33,10,1,18,14,48,28,20,1,8,17,8,53,19,7,1,12,39,13,20,23,32,68,19,9,18,12,6,20,16,12,13,27,20,13,8,5,27,14,13,6,3,1,14,28,10,31,17,10,33,16,31,15,7,12,5,1,2,25,25,49,41,19,10,15,26,4,14,3,1,8,69,25,10,30,9,24,12,9,31,40,15,19,35,32,18,51,3,17,1,5,8,5,14,41,32,15,11,4,15,15,16,17,18,2,4,4,83,62,35,42,16,1,10,27,13,25,23,20,21,14,11,24,5,18,7,8,15,5,14,13,8,2,7,25,8,14,23,8,10,82,2,1,21,22,31,10,51,16,71,2,15,9,1,30,22,6,4,2,52,27,35,13,24,5,1,11,19,19,23,28,11,13,6,11,48,13,4,2,57,34,27,110,1,12,51,29,26,9,64,21,5,11,17,31,28,15,32,6,18,51,8,1,31,15,19,34,29,17,7,25,15,21,16,13,23,22,37,20,2,1,30,12,19,6,12,29,32,36,15,36,6,22,65,36,22,4,8,22,18,17,1,4,10,29,34,14,20,67,38,21,2,8,24,11,38,8,14,8,16,21,9,28,2,11,1,25,29,22,28,16,71,6,17,15,2,27,25,15,20,19,27,15,19,56,3,1,48,15,32,28,20,7,40,23,4,28,38,16,49,11,68,5,1,37,11,8,10,12,4,9,17,47,12,15,4,42,1,2,18,26,50,4,3,12,22,36,41,19,1,28,26,18,13,14,43,30,19,11,9,25,10,8,22,8,41,10,1,18,14,19,12,43,1,6,23,20,32,27,28,24,9,16,20,9,19,11,54,15,11,12,4,9,17,5,8,14,16,9,12,19,23,1,4,18,10,25,12,13,23,8,17,17,7,9,10,21,12,28,13,8,4,9,5,5,16,27,17,7,9,21,8,19,20,10,6,3,1,4,23,10,23,4,11,33,14,13,46,14,7,23,78,10,17,40,19,33,30,2,1,45,11,8,7,14,18,27,18,23,17,27,11,12,35,20,12,35,11,33,5,19,25,16,15,11,2,1,6,1,25,14,10,29,35,17,8,12,25,27,8,33,20,20,12,5,8,30,60,24,18,1,8,18,29,16,12,13,12,18,21,23,14,20,16,42,8,38,16,14,15,18,10,31,16,18,3,9,1,50,15,44,15,34,15,12,18,7,12,8,5,103,28,9,5,61,1,35,39,6,10,12,5,6,49,17,16,13,14,52,49,8,13,15,38,5,6,10,14,1,12,17,12,41,47,35,26,27,9,6,19,22,76,13,44,29,15,10,1,10,18,38,18,21,19,7,4,6,9,21,26,27,10,18,35,42,39,10,12,23,11,1,14,14,15,18,16,32,21,11,7,38,38,2,15,6,11,15,18,39,22,31,17,10,11,18,6,1,3,43,34,24,18,32,14,17,15,13,10,24,27,17,20,24,11,35,9,79,1,13,20,20,36,21,66,10,11,23,2,53,19,25,6,5,8,9,61,16,20,34,22,20,31,22,48,56,45,6,13,7,1,3,19,14,15,10,46,13,21,36,4,31,14,11,11,61,34,21,5,13,28,26,20,1,6,25,5,18,4,30,29,59,23,21,28,16,12,31,14,21,18,14,47,11,12,2,1,2,24,30,23,24,49,12,22,22,31,13,67,13,49,11,47,6,14,6,20,3,3,1,9,24,10,24,23,20,37,6,33,10,15,11,28,33,13,89,28,21,3,3,1,9,30,8,12,56,13,44,27,14,13,15,15,34,27,99,10,1,38,18,16,17,12,3,6,17,7,13,23,6,6,32,2,15,48,17,17,8,30,17,26,18,1,96,34,36,39,7,39,10,28,11,36,7,12,27,37,1,18,9,18,40,38,2,35,38,19,3,54,34,21,12,27,18,14,13,16,1,17,35,73,52,15,13,10,27,11,6,37,10,47,3,58,14,1,28,30,21,23,18,15,19,21,21,19,49,19,44,53,6,8,19,9,17,5,1,34,40,12,26,23,58,8,9,18,5,3,16,10,17,31,94,7,18,23,1,15,27,28,23,23,16,18,5,3,49,11,9,27,7,24,62,36,17,20,22,16,7,5,2,1,27,32,24,19,50,32,36,14,4,19,32,60,27,21,11,11,11,3,15,34,1,19,16,6,27,15,6,17,32,20,22,30,8,5,8,12,17,12,34,12,23,19,11,4,7,1,38,13,2,1,10,28,13,6,15,41,29,64,12,35,17,48,50,10,29,18,6,1,43,9,55,69,32,54,27,40,29,12,64,10,1,46,23,30,27,11,13,15,10,24,37,30,37,6,42,19,6,34,5,1,31,9,12,10,24,22,17,26,25,34,44,14,16,8,11,6,18,18,12,8,14,12,37,14,11,5,1,9,16,4,3,29,35,84,18,7,19,15,4,19,10,16,41,20,10,16,19,8,37,12,8,2,1,23,12,31,9,12,14,16,12,13,15,17,25,12,16,41,23,43,22,15,47,55,18,3,1,21,29,50,13,7,8,9,26,10,38,7,17,13,2,83,6,45,14,7,42,1,4,1,10,11,4,1,7,18,22,5,26,12,16,29,21,18,46,15,30,60,13,42,13,4,19,11,24,8,4,6,8,4,1,3,18,18,17,25,7,1,7,16,12,20,33,9,34,22,14,14,9,6,7,17,16,37,28,25,26,25,23,1,22,9,11,20,32,12,12,46,11,16,18,9,20,14,5,18,21,10,16,13,24,9,27,10,24,1,7,9,16,16,16,30,39,38,11,46,28,4,11,17,14,12,27,26,5,16,9,17,5,15,9,7,2,1,12,22,12,33,9,12,15,10,3,16,28,28,38,27,23,25,9,6,16,19,22,21,12,21,5,12,18,9,1,23,37,66,18,33,43,24,14,25,15,8,16,24,15,39,29,11,24,1,4,28,44,19,23,21,21,39,7,12,28,24,33,41,15,32,19,16,38,19,9,1,28,6,13,18,14,20,34,39,34,6,2,14,6,18,19,27,18,10,21,38,19,11,1,12,9,1,20,56,12,9,5,8,20,85,8,6,30,25,11,27,15,50,28,20,16,1,1,9,22,35,14,4,8,12,8,23,43,12,30,31,31,33,53,21,13,11,56,1,12,33,8,24,28,16,9,16,17,9,30,19,66,43,28,19,7,9,12,1,10,25,38,30,14,30,13,27,29,32,39,26,12,19,27,36,16,11,12,1,9,16,25,16,18,18,24,15,32,9,3,23,29,3,17,5,6,4,11,3,22,14,11,20,48,11,33,12,34,11,1,19,58,52,13,6,26,14,21,16,11,4,21,16,9,28,8,12,10,9,30,14,18,18,14,3,1,34,29,47,31,20,28,51,62,22,17,6,14,29,19,9,39,4,2,1,16,23,29,16,26,16,14,8,12,11,11,29,17,29,9,18,8,14,61,8,14,43,14,35,5,2,1,8,19,19,8,74,16,29,38,12,4,9,10,16,21,41,4,23,6,14,23,36,24,22,11,7,9,12,12,15,13,6,18,11,19,10,24,10,22,19,17,34,8,23,3,7,8,2,1,37,47,27,14,4,52,18,12,14,16,16,30,15,34,23,4,30,31,28,8,1,11,85,24,2,20,14,29,43,10,9,1,1,2,4,33,13,4,10,5,14,15,19,15,15,12,6,5,1,15,27,49,27,46,2,8,35,13,21,41,12,3,7,15,39,42,18,33,3,1,32,23,21,34,14,10,7,30,18,11,59,11,45,29,6,14,10,11,41,18,16,1,53,26,27,23,9,29,43,23,15,7,52,9,8,29,32,43,51,1,37,28,74,46,34,31,10,62,40,37,11,3,5,9,4,1,18,9,11,10,8,5,22,5,10,5,22,11,13,11,26,24,7,7,21,16,8,7,11,12,14,13,2,8,16,31,64,15,5,2,23,6,2,1,10,39,19,18,49,22,13,36,23,18,5,14,33,50,15,16,22,17,9,28,16,12,14,3,1,5,18,24,22,10,4,10,19,12,40,12,24,14,9,14,9,22,33,13,6,6,30,57,28,25,21,29,67,23,12,12,33,33,7,20,8,42,18,5,12,19,54,4,20,30,5,29,17,15,17,20,11,21,11,29,11,11,10,30,23,5,17,22,9,67,14,22,7,11,31,17,23,21,20,41,67,12,6,2,1,1,2,6,16,48,27,17,20,30,50,15,46,4,7,11,19,4,2,3,1,1,7,17,11,9,1,2,2,2,39,11,12,10,13,15,19,11,50,6,45,10,38,17,21,44,38,20,19,30,18,12,35,18,21,24,40,14,14,14,9,12,8,17,21,12,7,14,11,7,64,2,7,10,23,12,12,9,8,11,23,17,15,5,36,10,49,13,7,4,16,2,16,4,1,14,3,20,16,15,21,16,36,3,23,11,69,4,36,89,75,27,44,2,2,64,19,19,12,45,15,26,13,17,20,12,3,3,4,5,4,2,8,15,86,23,29,9,37,8,14,14,5,4,5,3,15,11,2,4,2,8,8,7,24,30,11,26,5,1,4,2,4,8,6,6,10,31,15,43,23,12,18,9,72,10,11,13,3,6,17,66,6,17,8,32,17,51,37,4,19,9,13,34,26,13,20,34,7,7,3,21,25,19,21,43,11,10,47,2,28,21,2,15,8,21,13,5,19,1,9,21,17,6,27,18,5,2,12,16,3,12,26,28,2,8,14,28,10,14,16,30,3,25,11,18,3,27,21,20,7,10,8,25,17,20,48,25,27,7,79,29,8,28,8,30,20,10,25,6,28,19,13,11,16,13,32,35,29,23,13,8,18,16,6,3,27,20,27,2,34,50,10,33,39,32,29,50,37,16,2,31,11,33,3,38,41,11,11,12,10,25,8,15,12,36,15,24,18,21,17,10,43,33,25,10,2,33,24,26,16,3,20,15,21,13,11,11,4,46,44,4,30,34,13,2,18,8,4,10,30,15,14,2,6,3,28,2,9,20,30,16,14,9,5,14,3,24,37,28,21,9,2,35,18,12,28,10,24,24,27,5,10,19,4,13,22,14,18,6,3,5,1,25,47,6,34,3,38,17,10,5,8,14,12,4,9,9,11,15,15,29,2,13,18,19,13,2,7,28,17,21,14,6,21,11,5,23,10,31,30,10,22,12,16,34,9,16,3,8,1,4,6,14,6,10,12,14,30,13,49,23,10,34,40,16,20,6,45,12,30,6,27,27,16,22,1,14,11,16,47,65,20,18,1,26,29,34,17,40,34,40,13,18,10,37,17,38,31,19,48,16,15,28,9,16,12,27,14,38,20,1,14,12,24,23,19,9,13,12,8,4,12,1,10,9,7,13,2,23,18,11,14,6,19,16,18,24,15,20,14,8,23,2,4,21,3,9,11,6,15,22,16,12,7,9,6,4,4,11,24,14,18,18,27,9,11,11,25,1,13,16,2,18,5,1,31,24,21,6,11,23,3,36,16,29,45,20,19,22,19,9,16,26,2,21,34,11,12,31,9,3,7,21,26,5,6,3,10,9,17,17,20,5,8,4,9,14,15,25,8,52,21,15,24,21,4,25,9,26,17,19,22,3,21,12,12,10,3,9,17,13,12,5,7,30,27,14,2,6,7,5,3,26,36,3,2,12,32,2,10,21,19,13,2,25,2,17,14,19,15,22,3,14,22,16,3,7,3,11,2,11,26,17,28,21,20,24,12,11,8,12,14,1,4,10,14,1,6,11,12,12,42,10,4,27,13,17,2,23,10,35,2,14,2,15,11,9,1,5,4,14,16,6,9,8,15,2,6,25,3,23,23,25,10,3,24,22,4,8,31,30,11,10,22,23,2,4,10,2,7,13,2,3,12,1,17,13,24,29,44,17,2,10,2,4,20,2,42,4,10,18,2,18,3,54,7,11,2,33,7,19,12,6,15,4,25,38,27,22,3,20,27,21,1,11,27,11,12,2,13,11,23,22,33,19,49,32,21,2,9,28,8,14,9,25,36,12,19,21,15,15,34,25,16,6,5,15,12,24,14,18,11,17,10,8,20,14,19,14,28,30,12,21,23,1,11,10,6,25,10,13,20,17,29,10,31,7,5,4,11,8,2,23,12,9,20,18,3,14,12,6,4,16,11,14,17,22,6,32,11,13,1,35,17,7,8,7,18,9,24,12,10,34,7,16,2,20,18,18,14,22,33,20,23,32,10,18,27,13,40,18,11,27,26,12,28,7,13,16,22,9,6,29,7,16,54,26,31,24,37,2,34,11,44,18,20,38,18,2,41,46,25,30,2,18,39,30,45,46,13,22,33,46,26,26,20,5,14,5,23,26,23,14,32,48,5,16,27,17,25,10,12,12,19,13,25,12,7,18,17,25,12,17,28,7,17,31,17,35,26,11,22,44,5,5,41,11,8,3,25,57,6,2,12,10,8,26,10,31,30,2,14,23,20,2,40,26,2,18,14,18,2,8,2,12,2,2,15,7,2,10,23,7,2,13,17,10,16,2,6,41,5,11,2,40,4,20,14,20,13,2,27,4,2,19,2,9,4,18,46,25,2,57,20,30,16,9,19,23,8,3,18,43,8,20,22,39,21,22,23,11,28,21,23,35,6,24,27,22,35,19,22,13,46,21,35,30,37,27,18,7,3,30,22,42,27,14,8,28,44,23,14,18,10,40,1,22,18,13,16,13,12,31,20,26,24,11,13,18,18,50,18,8,24,19,27,12,37,9,27,14,33,33,17,15,39,32,10,12,20,25,20,9,35,9,16,28,55,41,106,28,8,28,15,16,18,12,25,17,60,37,21,8,25,45,18,23,40,2,26,22,39,9,3,21,15,4,26,40,3,8,2,6,17,36,19,2,17,7,9,16,26,5,57,17,5,2,15,6,6,27,29,6,2,23,34,22,12,1,21,13,4,12,3,16,12,6,1,7,15,13,16,40,5,7,2,9,23,22,3,13,29,15,22,2,20,24,21,20,12,31,20,30,15,13,4,11,8,19,30,21,3,37,26,17,30,16,8,7,1,10,11,6,9,15,20,10,2,4,7,41,18,76,14,3,15,18,4,28,27,27,14,32,27,19,43,29,20,74,2,27,7,1,31,13,12,4,35,5,16,21,22,2,58,8,36,24,35,18,10,9,7,3,12,15,14,26,21,7,6,5,21,44,18,1,7,6,19,3,42,2,15,26,31,4,7,2,37,12,2,44,8,9,3,24,12,17,1,6,2,12,7,4,7,2,8,13,3,15,17,2,10,2,5,3,14,4,43,18,9,1,22,21,12,15,11,7,4,30,13,20,3,32,10,13,2,24,13,6,9,29,12,7,4,3,9,8,17,10,3,11,23,12,2,29,3,14,34,10,15,28,4,25,22,11,4,26,2,12,17,16,20,4,19,42,25,37,2,33,2,19,8,11,7,9,12,18,15,16,8,4,11,7,15,8,9,58,11,8,2,4,12,38,3,2,21,43,1,32,16,35,15,17,19,2,32,12,10,23,18,24,47,11,3,24,30,4,25,14,9,1,29,10,19,46,3,9,17,20,22,3,8,31,19,18,27,13,9,14,15,7,15,14,3,31,2,29,34,9,2,31,17,27,18,8,41,20,23,24,15,59,29,46,2,75,38,30,19,28,62,18,74,48,43,8,18,24,18,23,4,3,19,12,36,20,16,24,6,21,15,18,18,24,19,7,7,7,18,27,12,36,18,14,21,9,15,11,20,4,17,22,33,13,11,14,18,13,15,36,21,17,8,5,23,35,14,16,13,17,17,11,21,9,34,12,11,13,29,4,7,19,11,34,2,22,11,5,5,17,2,42,23,20,7,12,4,22,2,45,18,3,8,23,8,8,14,25,8,11,17,21,14,5,7,22,10,14,45,23,23,19,15,24,2,17,14,44,32,15,35,8,2,59,6,31,39,21,31,19,4,42,24,26,2,34,6,10,31,3,8,12,13,6,11,11,15,2,8,17,11,2,20,34,25,18,28,2,22,118,2,36,25,40,20,3,29,8,13,20,18,8,3,24,31,8,5,22,16,20,11,10,5,24,25,7,12,9,1,23,34,12,6,8,13,15,21,11,16,8,22,31,14,2,12,22,23,24,21,44,4,2,6,15,14,13,13,25,35,13,3,20,17,24,5,17,2,9,6,6,10,12,8,27,4,19,13,8,18,19,30,2,20,21,2,7,79,19,15,44,13,3,6,17,25,16,6,10,11,13,5,40,13,17,7,11,7,32,29,15,13,8,14,4,6,16,5,6,7,13,20,14,5,10,3,5,17,6,15,14,25,19,17,26,47,6,4,15,26,37,25,10,8,14,11,21,1,9,21,4,29,24,22,18,2,18,11,18,19,21,18,4,18,27,36,9,10,3,17,35,13,10,58,16,3,45,2,14,14,10,2,28,34,12,3,9,17,20,4,13,15,48,38,10,33,17,21,9,9,2,30,33,12,4,26,6,25,22,14,7,3,28,55,8,15,18,13,3,13,39,20,23,2,13,5,36,10,2,27,27,21,12,2,18,31,4,17,5,3,16,23,4,18,16,15,1,10,36,14,21,49,14,11,14,7,18,15,24,3,4,20,2,32,16,6,5,12,23,4,19,11,10,21,2,23,22,2,17,11,2,26,2,24,3,39,14,10,16,5,7,17,30,25,1,7,5,13,21,10,13,15,12,11,12,19,14,14,13,18,8,16,33,6,9,4,12,1,13,1,13,2,9,12,14,2,11,7,23,1,13,3,10,1,7,2,11,6,14,2,13,12,2,9,1,8,2,12,4,8,5,2,20,22,1,11,2,8,2,14,10,2,8,1,15,2,11,12,1,25,2,7,4,10,3,11,2,10,1,16,2,7,1,8,2,19,11,2,13,2,10,2,13,3,16,13,2,7,5,9,3,19,13,2,25,4,25,19,25,4,30,4,45,1,11,6,6,1,26,4,9,39,2,2,36,2,31,10,7,10,1,22,29,11,22,7,7,14,7,11,33,31,2,2,26,1,18,13,2,27,4,13,3,3,6,24,3,13,21,2,20,6,2,10,10,12,1,7,16,14,7,1,20,17,25,12,2,30,13,40,11,12,2,9,11,22,5,22,11,11,2,16,20,28,2,11,16,25,3,14,30,25,27,27,8,19,24,1,31,11,26,7,15,18,14,1,26,14,5,18,23,18,37,21,20,23,8,6,10,24,17,39,41,11,16,15,14,6,3,4,19,2,11,2,14,1,15,2,7,2,5,10,2,8,2,8,6,2,9,4,14,2,9,1,9,2,15,1,11,2,9,3,8,3,15,10,2,10,3,15,13,12,4,1,5,2,17,2,6,2,8,12,3,8,4,19,25,1,8,19,17,9,23,6,24,9,5,11,13,2,23,14,2,11,9,10,9,18,11,40,3,11,9,16,13,16,21,2,44,1,17,13,19,17,16,10,6,9,5,4,39,35,3,23,22,3,36,10,1,23,3,22,19,23,17,2,28,16,2,12,10,24,6,23,11,4,48,27,23,29,17,17,18,18,39,15,10,4,16,2,20,26,5,14,6,21,16,13,2,14,32,7,2,19,25,19,2,22,19,2,11,1,17,42,1,31,13,2,28,32,13,2,23,30,10,19,2,10,6,3,28,19,20,27,41,25,31,45,4,15,2,21,24,36,1,23,26,1,24,23,12,2,35,27,16,2,17,24,7,1,7,19,13,14,3,27,6,23,25,14,23,3,11,4,12,10,20,14,26,13,34,17,6,3,46,4,32,24,20,36,12,11,6,6,3,16,16,11,14,2,25,23,13,15,2,8,29,13,31,13,24,4,13,9,8,20,3,9,35,22,11,16,15,9,2,49,28,3,46,26,3,13,12,18,22,17,3,7,13,8,13,11,16,6,7,9,16,17,6,16,1,31,3,19,23,53,15,33,2,13,6,4,27,1,14,3,15,2,12,3,20,2,18,10,32,19,3,24,42,42,23,20,9,9,30,11,36,32,36,31,59,48,23,13,17,17,21,23,28,17,29,19,22,19,32,19,14,19,29,20,3,15,25,30,44,29,16,21,4,15,18,6,24,39,4,35,42,44,52,17,14,16,28,47,21,4,32,48,2,13,63,7,16,31,33,3,6,8,12,6,18,20,4,23,23,40,21,6,4,19,45,31,21,3,63,20,75,32,4,8,2,13,2,15,12,26,2,18,1,8,9,2,19,1,12,14,2,8,6,2,18,2,8,5,17,2,7,16,2,13,1,8,17,2,9,4,12,2,2,6,3,7,1,10,2,7,2,8,12,9,4,32,2,17,2,8,15,4,10,6,3,15,2,11,1,6,1,6,8,11,2,11,11,4,10,4,15,2,16,15,9,2,12,3,7,2,13,2,13,2,28,2,7,2,20,12,1,9,3,11,3,14,2,2,14,4,8,10,10,10,1,8,2,16,1,13,3,12,2,8,4,9,4,12,5,2,19,5,3,15,1,7,2,10,2,15,2,9,3,2,6,1,8,3,3,17,4,21,2,10,9,9,7,2,16,2,16,1,12,2,11,1,6,17,12,4,6,14,13,1,9,1,7,2,4,1,19,3,8,8,12,2,13,7,4,3,24,2,10,14,1,13,3,11,13,3,10,5,21,3,22,5,2,3,6,9,23,6,2,14,15,11,2,22,14,12,17,21,13,6,18,12,26,6,2,13,31,22,6,36,2,33,2,24,57,3,16,7,10,15,2,11,14,9,13,17,31,16,18,3,36,20,2,19,14,2,24,2,4,7,5,8,9,12,16,30,3,11,5,13,5,21,31,24,13,4,16,2,9,6,23,3,40,2,13,7,19,18,26,2,30,37,13,3,34,21,13,16,3,35,34,26,2,20,24,2,13,18,5,10,34,2,21,3,19,16,2,16,8,1,15,2,41,14,17,4,23,13,6,25,18,4,17,10,14,14,22,2,17,23,9,2,18,17,11,14,8,12,24,4,63,2,29,31,21,28,12,28,3,11,12,9,11,7,5,15,5,12,13,6,23,10,38,11,7,14,7,12,7,25,20,28,3,35,37,13,30,28,74,6,13,24,35,27,20,10,30,29,16,28,29,11,10,21,18,19,21,21,14,20,15,36,16,11,21,11,17,14,13,20,1,13,26,31,13,26,50,22,14,15,6,24,35,53,54,60,3,1,21,20,21,38,36,30,23,16,3,10,17,12,2,18,55,2,9,5,24,18,30,29,53,7,14,3,2,29,11,4,16,35,8,6,24,9,79,52,23,14,11,2,14,7,17,33,15,21,11,7,5,6,7,10,7,11,3,22,1,14,11,25,2,34,3,32,22,8,70,1,5,2,31,10,8,12,2,7,13,3,31,11,2,24,19,2,15,19,2,47,3,18,7,22,19,1,22,7,10,27,21,3,9,14,2,27,12,10,2,18,7,2,13,15,3,6,25,3,21,2,31,25,16,6,39,20,6,25,15,29,18,26,17,30,21,6,13,18,28,8,1,16,14,18,16,5,16,16,4,16,29,15,10,24,18,2,48,11,29,3,3,25,23,7,21,14,41,47,56,25,34,13,3,5,41,38,9,7,11,1,15,2,12,2,4,7,9,7,23,14,23,3,17,2,12,3,14,3,23,3,11,4,34,18,15,23,1,9,15,13,2,13,3,11,2,16,88,21,18,3,13,2,12,25,3,26,36,23,3,20,5,20,4,2,7,16,6,26,8,2,15,2,17,2,6,16,19,2,9,6,4,18,12,4,14,5,1,10,19,2,12,23,17,2,6,2,21,3,30,1,19,15,2,24,8,3,18,13,1,10,10,3,20,2,19,2,13,8,9,2,17,5,15,10,25,1,13,10,15,2,6,13,15,5,30,3,8,10,4,23,24,40,26,21,2,31,16,24,29,4,3,33,23,3,19,20,24,22,5,14,12,8,12,19,2,12,12,9,12,20,36,26,17,5,31,8,21,57,14,15,33,25,4,41,36,11,12,7,6,1,5,18,13,5,2,5,9,12,18,30,8,22,5,7,6,5,24,12,22,3,39,50,36,63,25,2,4,6,4,29,3,29,13,13,1,2,23,2,15,2,24,25,3,14,2,9,11,8,3,15,4,20,3,23,27,3,17,14,8,7,2,23,20,14,13,15,23,15,22,21,23,16,6,19,29,14,18,16,26,26,17,15,2,13,30,7,3,27,3,20,23,1,11,7,4,25,11,4,32,20,6,9,5,23,39,36,13,1,12,8,2,23,13,2,7,31,4,41,3,20,18,4,53,46,11,9,7,20,36,9,12,3,2,25,1,7,32,3,18,3,44,3,10,2,12,4,19,8,39,36,12,4,30,27,17,32,2,10,2,8,5,16,15,2,26,2,5,2,5,2,27,31,38,26,8,32,161,3,17,11,3,43,12,4,34,3,59,2,45,2,20,3,2,30,21,3,32,4,9,12,12,8,8,3,12,15,2,13,2,15,21,6,2,6,5,19,7,2,22,34,7,17,15,2,22,24,7,3,2,18,11,8,4,11,2,27,8,2,20,2,10,2,32,4,11,6,25,17,14,1,17,6,18,11,89,3,36,23,40,36,19,17,35,9,8,16,19,77,7,25,5,44,17,16,12,12,9,37,49,74,24,13,58,27,3,23,30,58,1,36,29,37,6,10,32,35,12,20,18,17,2,7,17,59,14,2,29,38,9,2,36,13,15,22,2,33,20,39,13,6,6,51,15,34,15,11,62,2,56,3,15,3,15,28,3,46,7,19,3,35,15,28,2,39,7,2,24,27,18,62,3,31,22,9,4,9,8,2,24,20,5,3,15,3,17,3,26,4,16,4,29,2,14,2,21,2,26,2,25,2,2,12,17,20,8,2,24,5,2,26,3,16,14,11,8,3,25,28,10,3,31,3,10,3,23,34,11,21,12,2,20,31,21,10,7,2,26,17,2,18,4,30,8,2,12,3,32,2,14,14,12,3,27,4,20,22,1,4,24,31,20,22,22,18,2,37,26,27,4,23,15,15,14,5,43,3,15,46,7,7,31,10,33,34,29,24,12,18,17,12,15,8,31,77,12,2,22,15,45,13,16,19,30,41,28,2,18,33,18,4,19,36,21,45,10,5,17,7,46,4,24,5,23,13,17,16,23,43,31,17,54,31,13,9,2,19,22,11,18,21,25,21,29,24,20,2,27,41,18,2,14,10,14,15,5,3,28,13,3,9,3,24,44,2,17,3,46,2,15,4,3,2,1,15,3,27,5,4,32,2,20,4,18,2,13,3,20,22,4,13,3,10,2,15,5,14,1,8,1,10,1,12,37,12,2,15,8,2,12,3,2,15,1,26,6,3,16,5,21,12,4,8,6,20,1,8,11,10,2,10,2,20,1,13,5,19,39,9,10,16,26,6,14,40,2,26,3,20,10,9,4,17,13,1,17,21,8,2,23,14,7,3,15,7,16,4,23,1,11,2,9,30,23,2,17,19,11,19,3,11,24,5,3,31,3,27,2,40,7,29,2,29,19,3,15,8,2,21,2,8,10,12,3,30,6,4,29,15,6,33,11,8,32,19,7,17,3,19,2,24,5,19,11,11,4,16,57,2,2,35,2,19,35,2,17,3,13,2,8,20,18,19,37,4,13,9,3,9,3,8,2,18,2,5,10,2,22,9,2,33,3,11,36,30,19,14,33,7,1,4,29,22,29,19,31,41,18,13,38,28,41,55,28,4,42,2,21,5,20,12,8,2,10,30,22,9,6,13,6,8,10,15,12,32,6,3,3,34,12,37,25,5,28,14,1,15,17,6,12,29,20,15,3,24,16,2,23,2,14,3,43,2,7,4,4,11,14,18,25,31,3,10,8,2,28,2,6,9,4,30,9,24,16,11,23,2,16,10,5,2,5,9,2,9,1,1,48,9,10,4,2,22,2,18,2,52,1,5,12,4,2,17,10,5,52,3,11,2,15,2,11,3,24,2,14,3,9,4,19,5,17,13,9,15,15,3,7,1,7,34,8,15,7,1,7,15,12,8,2,20,17,1,12,8,4,12,3,9,1,8,3,2,4,18,16,8,13,5,2,15,8,22,1,6,2,1,18,9,28,6,2,9,7,11,10,2,15,18,5,15,2,8,2,12,1,26,19,2,16,4,20,14,3,16,2,9,3,25,27,2,4,4,12,8,19,15,6,2,9,4,14,5,5,12,12,12,23,13,8,14,4,9,5,8,5,10,22,11,8,4,3,11,16,14,6,10,11,5,14,10,11,12,2,2,10,6,9,3,6,10,15,5,7,4,4,3,1,4,6,14,2,14,15,17,3,8,5,8,12,18,3,10,15,30,69,4,38,19,2,46,23,45,28,22,20,14,28,19,2,33,22,21,16,8,12,14,33,9,12,18,3,18,11,1,13,22,33,5,3,15,37,10,24,10,20,13,31,2,16,15,13,12,2,45,50,3,9,10,31,14,11,21,8,22,2,3,64,36,13,2,10,2,18,4,28,15,16,22,3,22,11,12,2,4,11,31,16,13,15,17,11,9,13,12,24,15,18,19,39,17,38,4,19,9,1,3,3,2,8,2,1,8,16,15,12,1,64,15,2,24,11,2,26,13,18,12,17,27,19,10,21,35,25,11,25,21,34,18,29,5,20,9,32,18,11,5,8,5,11,1,12,6,21,22,13,15,9,10,8,15,15,8,13,4,26,22,27,17,23,9,33,10,3,25,17,15,8,2,42,20,14,10,13,23,13,12,4,26,26,7,33,12,3,15,25,24,24,19,25,11,3,41,22,21,6,1,23,14,2,12,16,6,4,22,39,41,14,14,13,19,1,4,8,18,1,11,6,14,8,21,22,15,44,18,24,14,20,17,13,17,11,15,8,24,30,25,16,40,2,5,18,8,2,15,11,3,14,4,5,16,9,20,2,8,2,8,36,9,15,6,35,29,19,18,2,17,31,17,12,37,12,3,14,3,2,2,2,8,19,16,14,1,5,14,10,20,2,16,16,23,37,18,4,28,9,2,21,3,21,3,19,26,2,8,14,2,13,17,21,2,9,10,8,14,8,10,13,2,12,11,18,2,12,7,4,3,2,7,5,9,11,20,16,23,15,16,4,25,18,19,10,32,11,2,6,2,16,36,16,7,22,36,11,2,31,55,13,30,28,7,2,17,21,2,16,2,1,24,1,16,8,7,4,3,13,12,15,3,3,4,4,17,9,18,10,2,10,13,20,13,25,38,6,2,24,21,7,9,2,4,8,9,8,1,5,2,16,30,12,5,2,35,22,37,15,37,27,3,27,41,15,19,2,12,10,14,19,14,3,11,13,3,15,22,23,4,9,19,17,2,23,10,17,9,15,16,10,2,16,11,2,22,20,27,1,7,10,11,14,3,11,13,11,9,5,9,25,1,4,1,1,1,2,12,6,2,29,13,7,1,23,33,16,4,3,8,27,18,59,29,3,42,8,3,20,6,10,3,13,3,2,40,17,2,27,11,2,11,22,3,16,21,1,19,11,19,18,11,2,8,1,22,12,3,9,27,45,9,21,13,2,10,16,18,16,12,13,13,6,2,12,2,13,12,3,14,1,17,9,17,7,8,2,18,3,19,16,4,15,15,8,11,1,16,19,5,14,29,10,12,15,2,25,6,16,70,4,14,11,7,8,2,26,4,2,12,1,21,43,13,16,24,15,7,19,12,16,17,12,7,4,9,8,1,14,2,12,6,14,26,31,4,4,15,27,36,2,8,25,36,11,2,9,5,1,8,53,6,3,18,12,18,22,8,18,12,20,10,10,1,19,26,13,10,7,10,7,34,17,17,2,27,2,20,22,20,9,8,2,7,3,7,3,13,2,10,2,12,4,2,9,12,2,22,18,4,11,20,14,3,25,2,18,16,9,7,2,9,5,2,15,8,14,16,25,2,10,8,4,14,8,23,5,3,3,4,2,16,12,2,6,29,10,7,5,2,10,13,4,2,12,30,11,8,20,1,34,9,11,20,23,24,1,12,2,45,21,2,13,11,8,13,3,36,27,18,15,6,14,2,14,21,3,38,16,2,10,33,2,29,2,2,4,9,2,12,17,2,20,11,3,22,27,8,2,23,3,3,3,3,4,2,7,9,50,21,17,16,15,4,34,13,28,20,18,30,67,2,14,10,5,2,2,2,2,5,16,9,33,58,4,25,16,14,22,4,8,28,31,20,28,15,11,18,32,39,6,14,8,3,5,23,2,40,25,2,21,1,15,2,13,7,7,23,35,38,18,19,13,40,4,3,14,16,15,12,18,7,8,14,19,24,3,15,14,12,18,7,11,6,11,16,29,33,2,17,11,24,48,2,13,9,6,12,6,35,9,15,9,17,1,12,56,2,18,24,6,4,9,8,14,16,45,6,3,33,29,10,17,11,49,20,16,3,26,40,16,54,22,25,28,69,18,12,35,2,16,8,3,13,2,12,8,1,30,9,2,18,34,7,2,14,8,10,4,40,4,19,11,2,11,2,22,13,2,44,8,2,11,2,17,5,5,11,1,3,12,4,2,6,2,4,9,5,2,8,13,1,6,4,2,8,25,9,44,14,19,5,13,27,2,2,13,2,25,12,12,14,10,35,11,1,17,16,9,6,8,6,13,2,12,5,20,15,3,1,2,2,3,4,8,4,6,16,4,4,5,6,19,9,11,6,16,46,10,54,6,21,2,20,6,77,23,48,35,78,43,20,39,54,22,19,11,18,26,13,21,40,15,3,6,5,11,24,24,32,11,20,9,2,17,2,17,13,5,19,6,12,10,2,13,16,8,15,59,9,12,15,3,5,14,46,6,2,10,5,2,17,4,16,13,2,31,11,13,7,2,37,26,1,28,9,2,21,10,18,5,3,10,16,1,11,30,9,2,13,4,8,6,7,5,26,22,13,3,6,2,23,6,17,17,7,9,2,4,22,35,23,2,10,2,13,17,13,19,2,10,3,1,15,2,19,2,18,1,2,4,3,14,3,6,13,6,1,12,2,6,9,4,1,21,7,1,11,21,2,17,3,12,3,2,20,22,10,32,12,22,8,10,1,12,6,12,9,1,22,25,20,3,9,19,14,13,22,11,7,33,14,12,8,1,5,39,25,2,9,12,12,16,2,10,23,32,27,29,22,36,30,4,36,29,2,13,10,2,21,1,8,3,4,26,3,43,20,39,14,3,16,11,11,69,3,17,21,5,20,10,20,22,2,11,1,33,5,13,84,50,19,16,12,11,3,15,16,13,22,13,7,37,35,19,3,8,81,1,35,23,17,3,13,7,50,10,28,10,30,33,42,9,14,3,22,13,8,19,20,6,26,7,43,15,13,32,5,7,23,18,45,2,24,3,7,20,6,6,42,11,20,3,26,35,3,18,31,7,2,11,2,11,2,18,13,4,9,21,29,6,13,41,16,22,22,3,12,23,10,15,18,9,2,23,26,7,32,17,2,21,21,5,16,10,22,53,2,23,18,3,11,9,27,11,2,12,6,21,9,7,2,10,4,26,1,34,13,13,2,9,24,2,16,7,3,7,7,1,14,10,16,13,13,28,7,12,2,19,4,12,22,2,15,11,11,2,14,2,9,13,2,37,2,20,5,3,7,14,28,2,18,8,5,8,17,13,16,10,2,10,4,9,2,32,5,21,38,8,6,2,10,23,11,1,23,1,13,5,15,7,2,11,2,5,14,7,9,8,2,11,13,4,25,13,9,1,3,7,15,8,2,22,3,24,22,9,5,3,9,3,8,2,6,1,5,8,1,2,16,10,2,11,55,2,21,3,5,2,10,2,15,6,3,13,17,11,3,12,16,3,14,10,2,15,2,8,2,4,2,6,8,9,2,17,27,13,9,30,22,21,3,12,3,4,2,2,3,6,2,4,16,8,8,8,13,8,9,10,4,17,20,5,7,4,4,5,5,11,2,16,2,7,1],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of word counts within data\"},\"xaxis\":{\"title\":{\"text\":\"Word Count\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('39e23109-4226-47af-a4aa-d4fd92ef8eb8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences with word length of greater than 3.0 and less than 25.0 includes 71.64% of the whole!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh8pYXYibArw"
      },
      "source": [
        "###Subsection 3: Frequency analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE6A5YZ9bIOp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaJ47YM6bOow"
      },
      "source": [
        "###Subsection 5: lemmatization and stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "103Z1ohlbTfM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFPb1QP4bWGP"
      },
      "source": [
        "##Section C: POS-tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx_bhMj9bcLX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVzG3ZbF2fci"
      },
      "source": [
        "##Section D: author classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjfRss-DR3fu"
      },
      "source": [
        "from transformers import BertConfig, BertTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SperdZDDWKxT"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFpUoggdpU3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d527d0-2e63-4aa1-806f-193dbb30d9bd"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n",
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH38OJU0X7rd"
      },
      "source": [
        "# general config\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "TEST_BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 3\n",
        "EEVERY_EPOCH = 1000\n",
        "LEARNING_RATE = 2e-5\n",
        "CLIP = 0.0\n",
        "\n",
        "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
        "OUTPUT_PATH = '/content/bert-fa-base-uncased-sentiment-taaghceh/pytorch_model.bin'\n",
        "\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK02AC0pYIPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7696dd1e-93b6-4263-dd86-9c53e6a438ea"
      },
      "source": [
        "# create a key finder based on label 2 id and id to label\n",
        "\n",
        "label2id = {label: i for i, label in enumerate(poets)}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "print(f'label2id: {label2id}')\n",
        "print(f'id2label: {id2label}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label2id: {'khajoo': 0, 'asad': 1, 'bahar': 2, 'feyz': 3, 'asadi': 4, 'hafez': 5, 'jami': 6, 'kamal': 7, 'moulavi': 8, 'parvin': 9}\n",
            "id2label: {0: 'khajoo', 1: 'asad', 2: 'bahar', 3: 'feyz', 4: 'asadi', 5: 'hafez', 6: 'jami', 7: 'kamal', 8: 'moulavi', 9: 'parvin'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGJRNBXFYOcx"
      },
      "source": [
        "# setup the tokenizer and configuration\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "config = BertConfig.from_pretrained(\n",
        "    MODEL_NAME_OR_PATH, **{\n",
        "        'label2id': label2id,\n",
        "        'id2label': id2label,\n",
        "    })\n",
        "\n",
        "print(config.to_json_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr9L9N91gSpm"
      },
      "source": [
        "### Input Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BIajCqGgYEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574e4a16-0ec2-4ffa-d634-f50ad96a1d5c"
      },
      "source": [
        "idx = np.random.randint(0, len(train))\n",
        "sample_poem = train.iloc[idx]['poem']\n",
        "sample_poet = train.iloc[idx]['poet']\n",
        "\n",
        "print(f'Sample: \\n{sample_poem}\\n{sample_poet}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: \n",
            "     \n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygnLJu8uhjPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c435c65-fe96-4cec-b3da-dd0117ce0a2f"
      },
      "source": [
        "tokens = tokenizer.tokenize(sample_poem)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f'  poem: {sample_poem}')\n",
        "print(f'  Coded_tokens: {tokens}')\n",
        "print(f'   Tokens: {tokenizer.convert_tokens_to_string(tokens)}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  poem:      \n",
            "  Coded_tokens: ['', '', '', '', '##', '##', '', '']\n",
            "   Tokens:      \n",
            "Token IDs: [4275, 6004, 96985, 8997, 2013, 2051, 3012, 3592]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgsgZ2b5h2I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c7d972-3025-447f-ec0c-f10d3cbb898d"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "    sample_poem,\n",
        "    max_length=32,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "    return_token_type_ids=True,\n",
        "    return_attention_mask=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "print(f'Keys: {encoding.keys()}\\n')\n",
        "for k in encoding.keys():\n",
        "    print(f'{k}:\\n{encoding[k]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "\n",
            "input_ids:\n",
            "tensor([[    2,  4275,  6004, 96985,  8997,  2013,  2051,  3012,  3592,     4,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]])\n",
            "token_type_ids:\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask:\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr8cRm9xiyKh"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaJBSSuMizgr"
      },
      "source": [
        "class PoemsDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, poems, targets=None, label_list=None, max_len=128):\n",
        "        self.poems = poems\n",
        "        self.targets = targets\n",
        "        self.has_target = isinstance(targets, list) or isinstance(targets, np.ndarray)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "        \n",
        "        self.label_map = {label: i for i, label in enumerate(label_list)} if isinstance(label_list, list) else {}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.poems)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        poem = str(self.poems[item])\n",
        "\n",
        "        if self.has_target:\n",
        "            target = self.targets[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            poem,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        inputs = {\n",
        "            'poem': poem,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "        }\n",
        "\n",
        "        if self.has_target:\n",
        "            inputs['targets'] = torch.tensor(target, dtype=torch.long)\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "\n",
        "def create_data_loader(x, y, tokenizer, max_len, batch_size, label_list):\n",
        "    dataset = PoemsDataset(\n",
        "        poems=x,\n",
        "        targets=y,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len, \n",
        "        label_list=label_list)\n",
        "    \n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEcefj6fkZFl"
      },
      "source": [
        "label_list = poets\n",
        "train_data_loader = create_data_loader(train['poem'].to_numpy(), train['poet'].to_numpy(), tokenizer, MAX_LEN, TRAIN_BATCH_SIZE, label_list)\n",
        "valid_data_loader = create_data_loader(valid['poem'].to_numpy(), valid['poet'].to_numpy(), tokenizer, MAX_LEN, VALID_BATCH_SIZE, label_list)\n",
        "test_data_loader = create_data_loader(test['poem'].to_numpy(), None, tokenizer, MAX_LEN, TEST_BATCH_SIZE, label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qSxzPU2krDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a117735c-3245-47d8-9fdc-3208a1163f3d"
      },
      "source": [
        "sample_data = next(iter(train_data_loader))\n",
        "\n",
        "print(sample_data.keys())\n",
        "\n",
        "print(sample_data['poem'])\n",
        "print(sample_data['input_ids'].shape)\n",
        "print(sample_data['input_ids'][0, :])\n",
        "print(sample_data['attention_mask'].shape)\n",
        "print(sample_data['attention_mask'][0, :])\n",
        "print(sample_data['token_type_ids'].shape)\n",
        "print(sample_data['token_type_ids'][0, :])\n",
        "print(sample_data['targets'].shape)\n",
        "print(sample_data['targets'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['poem', 'input_ids', 'attention_mask', 'token_type_ids', 'targets'])\n",
            "['      ', '       ', '     ', '         ', '    ', '       ', '        ', '    ', '       ', '     ', '      ', '      ', '       ', '     ', '      ', '     ']\n",
            "torch.Size([16, 128])\n",
            "tensor([    2, 13460,  2897,  3140, 14655,  3029,  3603,  3063,     4,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "torch.Size([16, 128])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "torch.Size([16, 128])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "torch.Size([16])\n",
            "tensor([4, 0, 8, 2, 8, 7, 5, 9, 0, 9, 8, 3, 2, 4, 1, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDUNgRODuOTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844d265f-5438-41c1-dd35-7bc8d2704df9"
      },
      "source": [
        "sample_test = next(iter(test_data_loader))\n",
        "print(sample_test.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['poem', 'input_ids', 'attention_mask', 'token_type_ids'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv75ARn_R_Dt"
      },
      "source": [
        "class ClassifierModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(ClassifierModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, 10)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        pooled_output = self.bert(\n",
        "            input_ids=input_ids, \n",
        "            attention_mask=attention_mask, \n",
        "            token_type_ids=token_type_ids)['pooler_output']\n",
        "        \n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrObbZAdNTNl"
      },
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "pt_model = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vzQGZGUmw3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e8cfda-9053-4d9e-d416-35fe7cd00068"
      },
      "source": [
        "pt_model = ClassifierModel(config=config)\n",
        "pt_model = pt_model.to(device)\n",
        "\n",
        "print('pt_model', type(pt_model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_model <class '__main__.ClassifierModel'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name,param in pt_model.named_parameters():\n",
        "  if'classifier' not in name:\n",
        "    param.requires_grad = False\n",
        "  else:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "Lr_-sMgyTNfZ",
        "outputId": "774dd631-8370-4a43-c24c-b48871213a90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZQDfLlp0Sf"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e044fZSfBoKe"
      },
      "source": [
        "def simple_accuracy(y_true, y_pred):\n",
        "    return (y_true == y_pred).mean()\n",
        "\n",
        "def acc_and_f1(y_true, y_pred, average='weighted'):\n",
        "    acc = simple_accuracy(y_true, y_pred)\n",
        "    f1 = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "def y_loss(y_true, y_pred, losses):\n",
        "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
        "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
        "    y = [y_true, y_pred]\n",
        "    loss = np.mean(losses)\n",
        "\n",
        "    return y, loss\n",
        "\n",
        "\n",
        "def eval_op(model, data_loader, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, total=len(data_loader), desc=\"Evaluation... \"):\n",
        "            \n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "            targets = dl['targets']\n",
        "\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            # calculate the batch loss\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            # accumulate all the losses\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(targets)\n",
        "    \n",
        "    eval_y, eval_loss = y_loss(y_true, y_pred, losses)\n",
        "    return eval_y, eval_loss\n",
        "\n",
        "\n",
        "def train_op(model, \n",
        "             data_loader, \n",
        "             loss_fn, \n",
        "             optimizer, \n",
        "             scheduler, \n",
        "             step=0, \n",
        "             print_every_step=100, \n",
        "             eval=False,\n",
        "             eval_cb=None,\n",
        "             eval_loss_min=np.Inf,\n",
        "             eval_data_loader=None, \n",
        "             clip=0.0):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    for dl in tqdm(data_loader, total=len(data_loader), desc=\"Training... \"):\n",
        "        step += 1\n",
        "\n",
        "        input_ids = dl['input_ids']\n",
        "        attention_mask = dl['attention_mask']\n",
        "        token_type_ids = dl['token_type_ids']\n",
        "        targets = dl['targets']\n",
        "\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        # convert output probabilities to predicted class\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "        # calculate the batch loss\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # accumulate all the losses\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        if clip > 0.0:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "        # perform optimization step\n",
        "        optimizer.step()\n",
        "\n",
        "        # perform scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(targets)\n",
        "\n",
        "        if eval:\n",
        "            train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "            train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "\n",
        "            if step % print_every_step == 0:\n",
        "                eval_y, eval_loss = eval_op(model, eval_data_loader, loss_fn)\n",
        "                eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "                if hasattr(eval_cb, '__call__'):\n",
        "                    eval_loss_min = eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min)\n",
        "\n",
        "    train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "\n",
        "    return train_y, train_loss, step, eval_loss_min\n",
        "\n",
        "def eval_callback(epoch, epochs, output_path):\n",
        "    def eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min):\n",
        "        statement = ''\n",
        "        statement += 'Epoch: {}/{}...'.format(epoch, epochs)\n",
        "        statement += 'Step: {}...'.format(step)\n",
        "        \n",
        "        statement += 'Train Loss: {:.6f}...'.format(train_loss)\n",
        "        statement += 'Train Acc: {:.3f}...'.format(train_score['acc'])\n",
        "\n",
        "        statement += 'Valid Loss: {:.6f}...'.format(eval_loss)\n",
        "        statement += 'Valid Acc: {:.3f}...'.format(eval_score['acc'])\n",
        "\n",
        "        print(statement)\n",
        "\n",
        "        if eval_loss <= eval_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                eval_loss_min,\n",
        "                eval_loss))\n",
        "            \n",
        "            torch.save(model.state_dict(), output_path)\n",
        "            eval_loss_min = eval_loss\n",
        "        \n",
        "        return eval_loss_min\n",
        "\n",
        "\n",
        "    return eval_cb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWrdialDAtN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b0fca36f0f2487eb91474c81d914e00",
            "45b1239eb7134b7f80c2108c403f47ae",
            "f027e8fabfe74716b80fdcd0d5c90db6",
            "6bf6f298cce34eb3a72c94ba6f58d23e",
            "f8ffa633a75e4769992840ed2a302518",
            "a2c75ac349344b469d5e0e9fee15ed6b",
            "509813d5b88c417f85e629c8190631b9",
            "e68e6534a9e745eca16b2d4f092c100e",
            "6ebb434a54114ceba5093dbc625c112c",
            "941644ffe7414b6280593d12ca24fc1f",
            "d4dd3b1ccfeb49458312ffb466daedca",
            "c9f040df6798460680a16b49ce6b6555",
            "f61b1f80ae90499980571c35542bad9d",
            "55503e53603c415ba31a461069700b8d",
            "78022da1346646939e560e9d28c96188",
            "dcc082ace32144a29ced2c55ed0bc8c4",
            "2ad876acb6ad42398dcc1b99737777c8",
            "0702ec60c1e144adbbb7032592636d7b",
            "0e79a1e059fb460a951f1bd536055552",
            "c16f20d4c13843c99f3cee82bf154517",
            "fdad540984bd436e86737a9a453d99fa",
            "fe1cd5002588468eaf7231380698d2d9",
            "b3bb60a715614eb2a32b4dca3f05432e",
            "f1fa0495486e441984096a4322ad556c",
            "5d0922aaab604b2783ed11b536434ea3",
            "90372806a7e94ac1868b214cc6f18e21",
            "34e4be60d32d4961ad75b4b9fbb066f9",
            "a4d5ff0be9a843d0a3d2d068a4e70407",
            "78df1e8b8ca342c285bc790311f485f4",
            "f9f1f0bd77284b8eb7122a7688f2a63c",
            "dfa20907f3e84a85967783349867185f",
            "e7d8a55ec2f44a9699cc8b0ccc0288f8",
            "ffc2a173162a4acd9aae6ca126ffc5d9",
            "06639a03f2ad49c697f8a7c1945feab6",
            "b3b8523efaf54d91bb46c35a463da680",
            "7ab847b62c284ebead52891890526f29",
            "253d606c6fb84763845a0ea7b3ca2a79",
            "481dabbd71884aa99b270b736096aa8e",
            "00f3fdd401c140459230ab688dc671d7",
            "6c36995cb447434eacc6324865a6277d",
            "6b14438627a64313bc293d104deaaf76",
            "b11692189a4a4df583fc54688c7fa1b0",
            "d2113c8428f54d0f8975912495340483",
            "522b05eec67c4be698bdb482f85508b4",
            "49ae5e3c4afc4d31868e163e158b9a55",
            "8a64a83973684292971c300d27712e58",
            "903f7b2fb0e14c678974c7dc3e567e1b",
            "8f6ff7acbcac454781102ef13debcecc",
            "e2466e0068bc4de89d3191afa1bb3d0c",
            "5e893a29dd5d42a486806ecab427bda9",
            "3bbcd407f3c3475faf0a3e46fb93cea1",
            "6d007e8ae647429487df6bbfa21f5f2c",
            "d21a2452e24a4cd8b72f4fc37f41c5fd",
            "2823181e79804f1a8cbd7db6094d9d03",
            "ce8c580baacc42b099ab50588e23740b",
            "9565940adbe740dbbb275c262cd197f0",
            "b25aa6b224ab4d159132989eac73c027",
            "73449a89ca6f4025be2b91d8bdd0596c",
            "d1ccd3afa4ce4e20bc8ec43cbee003a6",
            "e18c674d97c446a68b2a7dd4dae7d0b3",
            "12b251a9afd94693a43d9dbd3217cc3e",
            "191d2c10bdab4f3aaa02d560b0aaadf5",
            "9a27afe0218e4e628152c4b31d48c983",
            "fe9abeca49c241c4a00874319cea877a",
            "2a9fb3d6c20947a98af6f2cf3435a59b",
            "cb99f68b64674c2ea4bb9a7292f0b86e",
            "168e3736bc304901828a4ea9a777ad7c",
            "bced3d37726c42cc9dc890d9fb12b805",
            "c4d4375217c743ecb88c44890303a1d1",
            "f3e24b0c29b94625b4c4b5ffdfecfe63",
            "6691e31df3a742a69614b88e7aa807b4",
            "bbdf4c2230924ff69a50c2da126b5288",
            "0f9ae19427fa40b18a926029f46e7039",
            "5c22b38e47d34475a7c0c878360209d2",
            "43ca2475ab9d41ea837c1e9111087843",
            "a10551ed1f844e13b058900ad30de1e4",
            "40bc1802a45548438563165b9f5b4c34",
            "d24f86a9271246bebb85327bc755d514",
            "77278da01dd54f97b68c3fb4bfda3981",
            "3fec4307f18b4e1cb296bd58e87c0eeb",
            "19302633ed9c48149e3dba96b9c244d7",
            "1a0f7b85fdd0437d9ca0720154cc694d",
            "7e901b813fa445ee8acf7c323cfad1f1",
            "e42cf731e04a4388934e3da6ec6adb03",
            "767d6ac705eb4cea9fd42b6dcde83087",
            "33355f4877c74ffba73061a18836cf57",
            "0cb2f1ce8dc84882b5c21fbc0e01fde7",
            "3eba72c56e3e40f49a9b768ac42fcb85"
          ]
        },
        "outputId": "7eecc508-45de-4cde-da50-cfaa714c2be6"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "optimizer = optim.Adam(pt_model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "step = 0\n",
        "eval_loss_min = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(1, EPOCHS + 1), desc=\"Epochs... \"):\n",
        "    train_y, train_loss, step, eval_loss_min = train_op(\n",
        "        model=pt_model, \n",
        "        data_loader=train_data_loader, \n",
        "        loss_fn=loss_fn, \n",
        "        optimizer=optimizer, \n",
        "        scheduler=scheduler, \n",
        "        step=step, \n",
        "        print_every_step=EEVERY_EPOCH, \n",
        "        eval=True,\n",
        "        eval_cb=eval_callback(epoch, EPOCHS, OUTPUT_PATH),\n",
        "        eval_loss_min=eval_loss_min,\n",
        "        eval_data_loader=valid_data_loader, \n",
        "        clip=CLIP)\n",
        "    \n",
        "    train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "    \n",
        "    eval_y, eval_loss = eval_op(\n",
        "        model=pt_model, \n",
        "        data_loader=valid_data_loader, \n",
        "        loss_fn=loss_fn)\n",
        "    \n",
        "    eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "    \n",
        "    history['train_acc'].append(train_score['acc'])\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(eval_score['acc'])\n",
        "    history['val_loss'].append(eval_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b0fca36f0f2487eb91474c81d914e00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epochs... :   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9f040df6798460680a16b49ce6b6555",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training... :   0%|          | 0/3772 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3bb60a715614eb2a32b4dca3f05432e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/3...Step: 1000...Train Loss: 2.304766...Train Acc: 0.116...Valid Loss: 2.284853...Valid Acc: 0.136...\n",
            "Validation loss decreased (inf --> 2.284853).  Saving model ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06639a03f2ad49c697f8a7c1945feab6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06639a03f2ad49c697f8a7c1945feab6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3...Step: 2000...Train Loss: 2.289955...Train Acc: 0.135...Valid Loss: 2.268391...Valid Acc: 0.166...\n",
            "Validation loss decreased (2.284853 --> 2.268391).  Saving model ...\n",
            "Epoch: 1/3...Step: 2000...Train Loss: 2.289955...Train Acc: 0.135...Valid Loss: 2.268391...Valid Acc: 0.166...\n",
            "Validation loss decreased (2.284853 --> 2.268391).  Saving model ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49ae5e3c4afc4d31868e163e158b9a55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49ae5e3c4afc4d31868e163e158b9a55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3...Step: 3000...Train Loss: 2.280431...Train Acc: 0.146...Valid Loss: 2.254539...Valid Acc: 0.180...\n",
            "Validation loss decreased (2.268391 --> 2.254539).  Saving model ...\n",
            "Epoch: 1/3...Step: 3000...Train Loss: 2.280431...Train Acc: 0.146...Valid Loss: 2.254539...Valid Acc: 0.180...\n",
            "Validation loss decreased (2.268391 --> 2.254539).  Saving model ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9565940adbe740dbbb275c262cd197f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9565940adbe740dbbb275c262cd197f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/3772 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "168e3736bc304901828a4ea9a777ad7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/3772 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "168e3736bc304901828a4ea9a777ad7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d24f86a9271246bebb85327bc755d514"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation... :   0%|          | 0/943 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d24f86a9271246bebb85327bc755d514"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/3...Step: 4000...Train Loss: 2.256819...Train Acc: 0.159...Valid Loss: 2.244747...Valid Acc: 0.181...\n",
            "Validation loss decreased (2.254539 --> 2.244747).  Saving model ...\n",
            "Epoch: 2/3...Step: 4000...Train Loss: 2.256819...Train Acc: 0.159...Valid Loss: 2.244747...Valid Acc: 0.181...\n",
            "Validation loss decreased (2.254539 --> 2.244747).  Saving model ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-0b4ca49d6733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epochs... \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     train_y, train_loss, step, eval_loss_min = train_op(\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpt_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-173-258aea082cc8>\u001b[0m in \u001b[0;36mtrain_op\u001b[0;34m(model, data_loader, loss_fn, optimizer, scheduler, step, print_every_step, eval, eval_cb, eval_loss_min, eval_data_loader, clip)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-825bda7ec37f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         pooled_output = self.bert(\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         )\n\u001b[0;32m-> 1019\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    607\u001b[0m                 )\n\u001b[1;32m    608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    610\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-0b4ca49d6733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epochs... \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     train_y, train_loss, step, eval_loss_min = train_op(\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpt_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-173-258aea082cc8>\u001b[0m in \u001b[0;36mtrain_op\u001b[0;34m(model, data_loader, loss_fn, optimizer, scheduler, step, print_every_step, eval, eval_cb, eval_loss_min, eval_data_loader, clip)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-825bda7ec37f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         pooled_output = self.bert(\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         )\n\u001b[0;32m-> 1019\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    607\u001b[0m                 )\n\u001b[1;32m    608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    610\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZvVuRsoYRK"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlpDbg0wDqKP"
      },
      "source": [
        "def predict(model, comments, tokenizer, max_len=128, batch_size=32):\n",
        "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size, None)\n",
        "    \n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, position=0):\n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            \n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(F.softmax(outputs, dim=1))\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu().detach().numpy()\n",
        "\n",
        "    return predictions, prediction_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRpWTfwdoWoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ed41d53c9c2d4293847d6cba92678bc6",
            "b4c0de9cad2c4c51b99e7312af80f309",
            "01e9320dfc554ce4962e307bd46f719d",
            "bc5e097111d942e3ba5e8d5b3e1fecdf",
            "03c2c140d77d4e5b8682d993d5b0bf27",
            "36f5270be00d4316a4761c01b7df2c8e",
            "df6d404c345345548f615b8143ea3892",
            "66d4b5c390204095a6f3177a1d198041",
            "dab64da309014ca1a57bade6d1c55e5e",
            "293931024d0c4dd7a48720fafe0ce7c2",
            "8158df6c3dc3421592b6b248040a3fa5"
          ]
        },
        "outputId": "9fb11768-a77c-4159-c48d-46325a57d33d"
      },
      "source": [
        "test_poems = test['poem'].to_numpy()\n",
        "preds, probs = predict(pt_model, test_poems, tokenizer, max_len=128)\n",
        "\n",
        "print(preds.shape, probs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/590 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed41d53c9c2d4293847d6cba92678bc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18860,) (18860, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNlmNh7jazk7",
        "outputId": "12e6e1b1-1d6b-4075-954d-5b5faa01dea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 5, 5, ..., 3, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_label = [id2label[t] for t in preds]\n",
        "preds_label[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD-if3dzbK69",
        "outputId": "7d779734-a6e7-4093-b57a-b716aa31cafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['parvin', 'hafez', 'hafez', 'asad', 'asadi']"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##F1 Score and report"
      ],
      "metadata": {
        "id": "Vzor4JVfYv38"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRL2bgDDpUG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f223cd-44e4-4e80-bcf0-8cd66fb03fd3"
      },
      "source": [
        "y_test, y_pred = test['poet'].values, preds\n",
        "\n",
        "print(f'F1: {f1_score(y_test, y_pred, average=\"weighted\")}')\n",
        "print(\"--------------classification_report---------------\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 0.18183054145230343\n",
            "--------------classification_report---------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      khajoo       0.19      0.06      0.09      1886\n",
            "        asad       0.17      0.23      0.19      1886\n",
            "       bahar       0.18      0.21      0.19      1886\n",
            "        feyz       0.20      0.20      0.20      1886\n",
            "       asadi       0.28      0.41      0.33      1886\n",
            "       hafez       0.18      0.26      0.21      1886\n",
            "        jami       0.15      0.17      0.16      1886\n",
            "       kamal       0.16      0.12      0.14      1886\n",
            "     moulavi       0.22      0.09      0.13      1886\n",
            "      parvin       0.18      0.17      0.17      1886\n",
            "\n",
            "    accuracy                           0.19     18860\n",
            "   macro avg       0.19      0.19      0.18     18860\n",
            "weighted avg       0.19      0.19      0.18     18860\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "id": "d7ZQQDSDd1Iu",
        "outputId": "aa8903c4-4907-43c1-f369-635dd62886c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[108 230 135 240 211 368 175 178 102 139]\n",
            " [ 42 427 178 172 363 210 164 122  41 167]\n",
            " [ 28 186 396 131 281 199 247 122  90 206]\n",
            " [ 61 231 157 370  91 361 230 155  83 147]\n",
            " [ 23 258 233  63 769  90 154 103  29 164]\n",
            " [ 79 231 181 217 104 495 202 149  80 148]\n",
            " [ 52 200 255 146 294 210 317 132  70 210]\n",
            " [ 74 261 182 222 209 282 201 229  86 140]\n",
            " [ 34 281 270 161 189 241 237 149 178 146]\n",
            " [ 53 242 263 138 199 292 202 131  48 318]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+qA50syJMyJQS6hyJFYLI",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}